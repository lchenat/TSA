{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from deep_rl.reacher.env import MultiGoalReacherEnv, DiscretizeActionEnv\n",
    "from deep_rl.network import *\n",
    "from deep_rl.utils import *\n",
    "from sklearn.decomposition import NMF\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def set_seed(t, r=None, p=None, c=None):\n",
    "    if r is None:\n",
    "        r = t\n",
    "    if p is None:\n",
    "        p = r\n",
    "    torch.manual_seed(t)\n",
    "    random.seed(r)\n",
    "    np.random.seed(p)\n",
    "    if c is not None:\n",
    "        torch.cuda.manual_seed(c)\n",
    "\n",
    "class GridDrawer:                           \n",
    "    def __init__(self, color_list):\n",
    "        self.color_list = np.asarray(color_list)\n",
    "\n",
    "    # input: a 2-d index matrix\n",
    "    # output: a 2-d rgb matrix\n",
    "    def draw(self, indices, repeat=16):\n",
    "        return np.uint8(255 * np.array(self.color_list[indices, :]).repeat(repeat, 0).repeat(repeat, 1))\n",
    "    \n",
    "# this is my color list\n",
    "color_map = dict([\n",
    "    #*[('grey-{}'.format(v), plt.cm.Greys(0.1 * v)) for v in range(1, 20)],\n",
    "    *[('purple-{}'.format(v), plt.cm.Purples(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('blue-{}'.format(v), plt.cm.Blues(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('green-{}'.format(v), plt.cm.Greens(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('orange-{}'.format(v), plt.cm.Oranges(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('red-{}'.format(v), plt.cm.Reds(0.05 * v)) for v in range(1, 20)],\n",
    "])\n",
    "\n",
    "def imshow(img):\n",
    "    display(Image.fromarray(np.asarray(img)))\n",
    "\n",
    "color_list = list(color_map.values())\n",
    "shuffle(color_list)\n",
    "color_list = [plt.cm.Greys(0.9)] + [plt.cm.Greys(0.5)] + color_list\n",
    "drawer = GridDrawer(color_list)\n",
    "\n",
    "# multitask NMF from: https://ieeexplore.ieee.org/document/6939673\n",
    "class MTNMF:\n",
    "    def __init__(self, n_components, l1_ratio=0.0, max_iter=200, tol=0.0001):\n",
    "        self.n_components = n_components\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "\n",
    "    def loss(self, X, A, S):\n",
    "        return 0.5 * ((X - np.matmul(A, S)) ** 2).sum() + self.l1_ratio * S.sum()\n",
    "        \n",
    "    # input: a stack of observed data X_1, ..., X_K\n",
    "    # output: S, A_1, ..., A_K\n",
    "    def fit(self, X):\n",
    "        K, N, M = X.shape\n",
    "        A = np.random.rand(K, N, self.n_components)\n",
    "        S = np.random.rand(self.n_components, M)\n",
    "        prev_loss = np.inf\n",
    "        cur_loss = None\n",
    "        for i in range(self.max_iter):\n",
    "            A_T = A.transpose(0, 2, 1)\n",
    "            new_S = S * (np.matmul(A_T, X).sum(0)) / (np.matmul(np.matmul(A_T, A), S).sum(0) + K * self.l1_ratio * np.ones((self.n_components, M)))\n",
    "            S = new_S\n",
    "            new_A = A * np.matmul(X, S.T) / np.matmul(np.matmul(A, S), S.T)\n",
    "            A = new_A\n",
    "            cur_loss = self.loss(X, A, S)\n",
    "            if i % 100 == 0: print('NMF loss:', cur_loss)\n",
    "            if abs(cur_loss - prev_loss) < self.tol: break\n",
    "            prev_loss = cur_loss # update loss\n",
    "        return A, S, {'loss': cur_loss, 'iter': i}\n",
    "    \n",
    "def rollout(env, policy, horizon):\n",
    "    states = []\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    info = dict(task_id=[0])\n",
    "    for _ in range(horizon):\n",
    "        states.append(state)\n",
    "        action = policy([state], info)['a'][0].cpu().detach().numpy()\n",
    "        state, _, _, _ = env.step(action) # note that info is not used\n",
    "    return states\n",
    "\n",
    "def get_expert(weight_path, state_dim, action_dim):\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        4,\n",
    "        state_dim,\n",
    "        action_dim.prod(),\n",
    "        FCBody(\n",
    "            state_dim, \n",
    "            hidden_units=(16,)\n",
    "        ),\n",
    "        SplitBody(\n",
    "            MultiLinear(16, action_dim.sum(), 4, key='task_id', w_scale=1e-3),\n",
    "            2,\n",
    "        ),\n",
    "    )\n",
    "    # load weight\n",
    "    weight_dict = expert.state_dict()\n",
    "    loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "        weight_path,\n",
    "        map_location=lambda storage, loc: storage)['network'].items()\n",
    "        if k in weight_dict}\n",
    "    weight_dict.update(loaded_weight_dict)\n",
    "    expert.load_state_dict(weight_dict)\n",
    "    return expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiTask NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "states shape: (3000, 8)\n",
      "NMF loss: 1618.4161562174281\n",
      "NMF loss: 46.15118515020248\n",
      "NMF loss: 44.16828206966061\n",
      "NMF loss: 43.49719374736195\n",
      "NMF loss: 42.72628189505001\n",
      "NMF loss: 30.225020891803197\n",
      "NMF loss: 26.31385787331907\n",
      "NMF loss: 26.00633484883688\n",
      "NMF loss: 25.924223088309507\n",
      "NMF loss: 25.88703847222584\n",
      "NMF loss: 25.864470733219466\n",
      "NMF loss: 25.850487852977526\n",
      "NMF loss: 25.8394486937315\n"
     ]
    }
   ],
   "source": [
    "n_abs = 6\n",
    "l1_ratio=0.0 # this is currently not working... since alpha is not set\n",
    "state_dim = 8\n",
    "action_dim = np.array((5, 5))\n",
    "horizon = 100\n",
    "n_trajs = 10\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "expert_dict = {\n",
    "    #1: '../log/reacher.1_corner/fc_discrete.baseline/split/0.190315-202731/models/step-704000-mean--6.36',\n",
    "    #2: '../log/reacher.2_corner/fc_discrete.baseline/split/0.190315-203310/models/step-704000-mean--17.16',\n",
    "    #3: '../log/reacher.3_corner/fc_discrete.baseline/split/0.190315-203532/models/step-704000-mean--11.25',\n",
    "    1: '../log/reacher.ng.1_corner/fc_discrete.baseline/ng/0.190316-161504/models/step-704000-mean--6.08',\n",
    "    2: '../log/reacher.ng.2_corner/fc_discrete.baseline/ng/0.190316-161535/models/step-704000-mean--26.97',\n",
    "    3: '../log/reacher.ng.3_corner/fc_discrete.baseline/ng/0.190316-162113/models/step-704000-mean--16.12',\n",
    "}\n",
    "\n",
    "envs = [DiscretizeActionEnv(\n",
    "    MultiGoalReacherEnv(\n",
    "        [\n",
    "            [0.15, 0.0],\n",
    "            [-0.15, 0.0],\n",
    "            [0.0, 0.15],\n",
    "            [0.0, -0.15],\n",
    "        ],\n",
    "        sample_indices=[i],\n",
    "        with_goal_pos=False,\n",
    "    ),\n",
    "    n_bins=[5, 5],\n",
    ") for i in range(3)]\n",
    "decomposer = MTNMF(n_abs, max_iter=5000, tol=0.0001)\n",
    "\n",
    "states = []\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    experts[goal_idx] = get_expert(weight_path, state_dim, action_dim)\n",
    "    for _ in range(n_trajs):\n",
    "        states.append(rollout(envs[goal_idx-1], experts[goal_idx], horizon=horizon))\n",
    "states = np.concatenate(states)\n",
    "print('states shape:', states.shape)\n",
    "    \n",
    "pvs = []\n",
    "infos = {'task_id': [0] * len(states)}\n",
    "    \n",
    "for goal_idx in expert_dict:\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, infos), dim=-1).cpu().detach().numpy()\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.stack(pvs, 0)\n",
    "A, S, info = MTNMF(n_abs, max_iter=5000, l1_ratio=l1_ratio).fit(pvs.transpose(0, 2, 1))\n",
    "\n",
    "fsave(\n",
    "    dict(\n",
    "        abs=S.T,\n",
    "        policies=list(pvs.reshape(pvs.shape[0], pvs.shape[1], 2, -1)),\n",
    "        states=[states for _ in range(len(pvs))],\n",
    "        infos=list([[{'task_id': i} for _ in range(len(states))] for i in range(3)]),\n",
    "    ),\n",
    "    '../data/nmf_sample/reacher/split.ng.{}'.format(n_abs),\n",
    "    'pkl',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.0\n",
      "()\n",
      "tensor([[[ 0.2894,  0.3199,  0.3907],\n",
      "         [ 0.2584,  0.3156,  0.4260]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "a = np.array(3)\n",
    "print(a.shape)\n",
    "\n",
    "# (1, 2, 3)\n",
    "probs = torch.Tensor([[[0.2, 0.3, 0.5], [0.1, 0.3, 0.6]]])\n",
    "print(torch.nn.functional.softmax(probs, dim=2))\n",
    "# probs = torch.Tensor([[0.2, 0.3, 0.5]])\n",
    "# print(probs.shape[0])\n",
    "# log_probs = torch.log(probs)\n",
    "# print(log_probs)\n",
    "# dist = torch.distributions.Categorical(logits=log_probs)\n",
    "# action = dist.sample()\n",
    "# print(action)\n",
    "# log_prob = dist.log_prob(action)\n",
    "# print(log_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
