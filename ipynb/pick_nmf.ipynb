{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from deep_rl.gridworld import ReachGridWorld, PickGridWorld, PORGBEnv, GoalManager, ScaleObsEnv\n",
    "from deep_rl.network import *\n",
    "from deep_rl.utils import *\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import dill\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from collections import Counter, namedtuple\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "def set_seed(s):\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "    torch.manual_seed(s)\n",
    "\n",
    "set_seed(0) # set seed \n",
    "\n",
    "class GridDrawer:                           \n",
    "    def __init__(self, color_list):\n",
    "        self.color_list = np.asarray(color_list)\n",
    "\n",
    "    # input: a 2-d index matrix\n",
    "    # output: a 2-d rgb matrix\n",
    "    def draw(self, indices, repeat=16):\n",
    "        return np.uint8(255 * np.array(self.color_list[indices, :]).repeat(repeat, 0).repeat(repeat, 1))\n",
    "    \n",
    "# this is my color list\n",
    "color_map = dict([\n",
    "    #*[('grey-{}'.format(v), plt.cm.Greys(0.1 * v)) for v in range(1, 20)],\n",
    "    *[('purple-{}'.format(v), plt.cm.Purples(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('blue-{}'.format(v), plt.cm.Blues(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('green-{}'.format(v), plt.cm.Greens(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('orange-{}'.format(v), plt.cm.Oranges(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('red-{}'.format(v), plt.cm.Reds(0.05 * v)) for v in range(1, 20)],\n",
    "])\n",
    "\n",
    "color_list = list(color_map.values())\n",
    "shuffle(color_list)\n",
    "color_list = [plt.cm.Greys(0.9)] + [plt.cm.Greys(0.5)] + color_list\n",
    "drawer = GridDrawer(color_list)\n",
    "\n",
    "visualization_map = dict([\n",
    "    ('G', 0), # goal\n",
    "    ('#', 1),\n",
    "    *[(str(i), i + 2) for i in range(0, 100)],\n",
    "])\n",
    "\n",
    "def imshow(img):\n",
    "    display(Image.fromarray(np.asarray(img).astype(np.uint8)))\n",
    "\n",
    "def fload(fn, ftype):\n",
    "    if ftype == 'json':\n",
    "        with open(fn) as f:\n",
    "            return json.load(f)\n",
    "    elif ftype == 'pkl':\n",
    "        with open(fn, 'rb') as f:\n",
    "            return dill.load(f)\n",
    "    elif ftype == 'png':\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        raise Exception('cannot read this data type: {}'.format(ftype))\n",
    "    \n",
    "def fsave(data, fn, ftype):\n",
    "    dirname = os.path.dirname(fn)\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    if ftype == 'json':\n",
    "        with open(fn, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "    elif ftype == 'pkl':\n",
    "        with open(fn, 'wb') as f:\n",
    "            dill.dump(data, f)    \n",
    "    elif ftype == 'png':\n",
    "        Image.fromarray(data).save(fn)\n",
    "    else:\n",
    "        raise Exception('unsupported file type: {}'.format(ftype))\n",
    "        \n",
    "GoalConfig = namedtuple('GoalConfig', ['map_name', 'n_goal', 'min_dis'])  \n",
    "\n",
    "# multitask NMF from: https://ieeexplore.ieee.org/document/6939673\n",
    "class MTNMF:\n",
    "    def __init__(self, n_components, l1_ratio=0.0, max_iter=200, tol=0.0001):\n",
    "        self.n_components = n_components\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "\n",
    "    def loss(self, X, A, S):\n",
    "        return 0.5 * ((X - np.matmul(A, S)) ** 2).sum() + self.l1_ratio * S.sum()\n",
    "        \n",
    "    # input: a stack of observed data X_1, ..., X_K\n",
    "    # output: S, A_1, ..., A_K\n",
    "    def fit(self, X):\n",
    "        K, N, M = X.shape\n",
    "        A = np.random.rand(K, N, self.n_components)\n",
    "        S = np.random.rand(self.n_components, M)\n",
    "        prev_loss = np.inf\n",
    "        cur_loss = None\n",
    "        for i in range(self.max_iter):\n",
    "            A_T = A.transpose(0, 2, 1)\n",
    "            new_S = S * (np.matmul(A_T, X).sum(0)) / (np.matmul(np.matmul(A_T, A), S).sum(0) + K * self.l1_ratio * np.ones((self.n_components, M)))\n",
    "            S = new_S\n",
    "            new_A = A * np.matmul(X, S.T) / np.matmul(np.matmul(A, S), S.T)\n",
    "            A = new_A\n",
    "            cur_loss = self.loss(X, A, S)\n",
    "            if i % 100 == 0: print('NMF loss:', cur_loss)\n",
    "            if abs(cur_loss - prev_loss) < self.tol: break\n",
    "            prev_loss = cur_loss # update loss\n",
    "        return A, S, {'loss': cur_loss, 'iter': i}\n",
    "    \n",
    "def rollout(env, idx, policy=None, horizon=100, epsilon=0.1):\n",
    "    states = []\n",
    "    returns = 0.0\n",
    "    done = False\n",
    "    #normalizer = ImageNormalizer()\n",
    "    state = env.reset(sample_obj_pos=False) # very important!\n",
    "    info = dict(task_id=[idx])\n",
    "    for _ in range(horizon):\n",
    "        states.append(state)\n",
    "        if policy is None:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = policy([state], info)['a'][0].cpu().detach().numpy()\n",
    "        state, r, done, _ = env.step(action) # note that info is not used\n",
    "        returns += r\n",
    "        if done: break\n",
    "    return states, returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTNMF (Nineroom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "\n",
    "def get_img(env, abs_list):\n",
    "    size = (env.unwrapped.row, env.unwrapped.col)\n",
    "    indices = np.zeros(size, dtype=np.int64)\n",
    "    k = 0\n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            if (i, j) in env.unwrapped.default_obj_pos[0]: # object position\n",
    "                indices[i, j] = 0\n",
    "            elif env.unwrapped.m[i][j] == '#':\n",
    "                indices[i, j] = 1\n",
    "            else:\n",
    "                indices[i, j] = visualization_map[str(2 + abs_list[k])]\n",
    "                k += 1\n",
    "\n",
    "    img = drawer.draw(indices)\n",
    "    return img\n",
    "\n",
    "def get_visualization_env():\n",
    "    with open('../data/env_configs/pick/nineroom/nineroom.8', 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    print(env_config)\n",
    "    env = ScaleObsEnv(\n",
    "        PickGridWorld(\n",
    "            **env_config,\n",
    "            min_dis=1,\n",
    "            window=1,\n",
    "            task_length=1,\n",
    "            seed=0,\n",
    "        ),\n",
    "        2,\n",
    "    )\n",
    "    env.reset(sample_obj_pos=False)\n",
    "    positions = env.unwrapped.pos_candidates\n",
    "    states = []\n",
    "    for pos in positions:\n",
    "        o, _, _, _ = env.teleport(*pos)\n",
    "        states.append(o)\n",
    "    print('states shape:', len(states))\n",
    "    return env, states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize all states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 8)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 8)]\n",
      "test: [(0, 0)]\n",
      "states shape: 152\n",
      "(152, 5)\n",
      "(152, 5)\n",
      "(152, 5)\n",
      "(152, 5)\n",
      "(152, 5)\n",
      "(152, 5)\n",
      "(152, 5)\n",
      "(152, 5)\n",
      "NMF loss: 380.73001675753534\n",
      "NMF loss: 125.53161921374533\n",
      "NMF loss: 125.20671967664967\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAYAAABccqhmAAAF8UlEQVR4nO3dMWtVdwDG4ZuQrUgHFdwiDpZK62KgiyCdRJJJooiDrWARP4Ghg0OHYul8CEFByRBEL5kU6SSCSyFdrFjsIGYT1EGKq+l38BUO4X2e/T3nhBt+nOX+78wwDDsToNLs2A8AjEcAoJgAQDEBgGICAMUEAIoJABQTACgmAFBMAKCYAEAxAYBiAgDFBACKCQAUm0sv8GB24XM8B5/o62+mo97/7vk70X5lZSXavzz6Ktr/82w52qfSz+/Q04PR3hsAFBMAKCYAUEwAoJgAQDEBgGICAMUEAIoJABQTACgmAFBMAKCYAEAxAYBiAgDF4vMA0u8zp9/Hvn36SLRP3ZuuR/szyxei/c21k9E+dXYjvMDTbP774R+i/dKzD9kDhNL//0OTrWjvDQCKCQAUEwAoJgBQTACgmABAMQGAYgIAxQQAigkAFBMAKCYAUEwAoJgAQDEBgGLxeQCpsb/PT2bvo/A8gr0vovn1tdfZ/ffvieZ//5p9n//bn7PzNFLeAKCYAEAxAYBiAgDFBACKCQAUEwAoJgBQTACgmABAMQGAYgIAxQQAigkAFBMAKBafB5D+vvmx89l5AGc3zkX7q4evRfuxXbr83aj3v7n256j3Tx1/81+2/+lWtH8SrXPeAKCYAEAxAYBiAgDFBACKCQAUEwAoJgBQTACgmABAMQGAYgIAxQQAigkAFBMAKDYzDMNOcoEHswvRAyx+3Ir2ZHx+43p59FW0P/T0YLT3BgDFBACKCQAUEwAoJgBQTACgmABAMQGAYgIAxQQAigkAFBMAKCYAUEwAoJgAQLG59AK3Tx+J9jfXst9nf/f9H9H+6uFr0f7edD3aX1k+Ee1TV8L90ua45wmk5xkcf5P9/63euBjtz26ci/YpbwBQTACgmABAMQGAYgIAxQQAigkAFBMAKCYAUEwAoJgAQDEBgGICAMUEAIoJABSbGYZhJ7lA+vvmu136++xnli9E+32T7Wg/ttXp42ifngeQSs8TSM+zSP//vAFAMQGAYgIAxQQAigkAFBMAKCYAUEwAoJgAQDEBgGICAMUEAIoJABQTACgmAFBsbuwHIPN2Mh/td/t5Arvd3kcnwwu8iObeAKCYAEAxAYBiAgDFBACKCQAUEwAoJgBQTACgmABAMQGAYgIAxQQAigkAFBMAKBafB3D3/J1of3bjXPoIu9pv//4S7a8evvaZnuTTzC+civbbWw+j/ZVoPZksbX4Ir7C7eQOAYgIAxQQAigkAFBMAKCYAUEwAoJgAQDEBgGICAMUEAIoJABQTACgmAFBMAKDYzDAMO8kF3r/7KnqAL8PfN293ZflEtF+dPv5MT8KnGPvz8wYAxQQAigkAFBMAKCYAUEwAoJgAQDEBgGICAMUEAIoJABQTACgmAFBMAKCYAECxufQCK5cPhFdI95m3k/lof2+6Hu3T8xSur72O9pcuX4j2+ybb0T79Pnv6ffrU0uaHaP8+/Py+3BvNvQFAMwGAYgIAxQQAigkAFBMAKCYAUEwAoJgAQDEBgGICAMUEAIoJABQTACgmAFAsPg9gbOn3sSeT59F6Mbz7k/17ov3t00fCJ8jML5yK9isrK5/pScZx//QX0X5pM7v/4sds7w0AigkAFBMAKCYAUEwAoJgAQDEBgGICAMUEAIoJABQTACgmAFBMAKCYAEAxAYBiM8Mw7CQXSH/ffuXygWifSs8TWPy4Fe0fzC5E+9TY5wncm65H+zPLF6L9sYXs79/eehjtU6vTx9HeGwAUEwAoJgBQTACgmABAMQGAYgIAxQQAigkAFBMAKCYAUEwAoJgAQDEBgGICAMXm0gus3rgYXuFW+giR++F5BKvT8P7x78tn5xn8uPk82qcWR737ZPLXVvb3vw3vv2+yHV4h4w0AigkAFBMAKCYAUEwAoJgAQDEBgGICAMUEAIoJABQTACgmAFBMAKCYAEAxAYBiM8Mw7Iz9EMA4vAFAMQGAYgIAxQQAigkAFBMAKCYAUEwAoJgAQDEBgGICAMUEAIoJABQTACgmAFDsf7H/vw3ADRrWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=256x256 at 0x7F8D4C327AC8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pdb on\n",
    "n_abs = 5\n",
    "l1_ratio = 0.0 # this is currently not working... since alpha is not set\n",
    "feat_dim = 512\n",
    "action_dim = 5\n",
    "horizon = 100\n",
    "n_trajs = 10 #30\n",
    "scale = 2\n",
    "n_objs = 9\n",
    "epsilon = 0.0\n",
    "\n",
    "def get_expert(weight_path, action_dim):\n",
    "    visual_body = TSAMiniConvBody(\n",
    "        2 + n_objs, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale,\n",
    "        #gate=F.softplus,\n",
    "    )\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        n_objs,\n",
    "        0, # state_dim\n",
    "        action_dim,\n",
    "        visual_body,\n",
    "    )\n",
    "    # load weight\n",
    "    weight_dict = expert.state_dict()\n",
    "    loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "        weight_path,\n",
    "        map_location=lambda storage, loc: storage)['network'].items()\n",
    "        if k in weight_dict}\n",
    "    weight_dict.update(loaded_weight_dict)\n",
    "    expert.load_state_dict(weight_dict)\n",
    "    return expert\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "expert_dict = {\n",
    "    0: '../log/pick.mask.nineroom.0.min_dis-1/tsa.baseline.n_abs-512/relu/0.190327-232308/models/step-491520-mean-10.70',\n",
    "    1: '../log/pick.mask.nineroom.1.min_dis-1/tsa.baseline.n_abs-512/relu/1.190327-235057/models/step-491520-mean-10.84',\n",
    "    2: '../log/pick.mask.nineroom.2.min_dis-1/tsa.baseline.n_abs-512/relu/1.190328-000958/models/step-491520-mean-10.86',\n",
    "    3: '../log/pick.mask.nineroom.3.min_dis-1/tsa.baseline.n_abs-512/relu/2.190328-003751/models/step-491520-mean-10.71',\n",
    "    4: '../log/pick.mask.nineroom.4.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-005600/models/step-491520-mean-10.81',\n",
    "    5: '../log/pick.mask.nineroom.5.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-011456/models/step-491520-mean-10.78',\n",
    "    6: '../log/pick.mask.nineroom.6.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-014223/models/step-491520-mean-10.82',\n",
    "    7: '../log/pick.mask.nineroom.7.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-020127/models/step-491520-mean-10.84',\n",
    "}\n",
    "\n",
    "env, states = get_visualization_env()\n",
    "\n",
    "decomposer = MTNMF(n_abs, max_iter=5000, tol=0.0001)\n",
    "\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    experts[goal_idx] = get_expert(weight_path, action_dim)\n",
    "\n",
    "pvs = []\n",
    "\n",
    "for goal_idx in expert_dict:\n",
    "    cur_infos = {'task_id': [goal_idx] * len(states)}\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, cur_infos), dim=-1).cpu().detach().numpy()\n",
    "    print(pv.shape)\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.stack(pvs, 0)\n",
    "A, S, info = MTNMF(n_abs, max_iter=5000, l1_ratio=l1_ratio).fit(pvs.transpose(0, 2, 1))\n",
    "\n",
    "abs_list = S.T.argmax(1)\n",
    "img = get_img(env, abs_list)\n",
    "imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate from sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 0)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 0)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 1)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 1)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 2)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 2)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 3)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 3)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 4)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 4)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 5)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 5)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 6)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 6)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 7)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 7)]\n",
      "test: [(0, 0)]\n",
      "goal: 0, mean return: 9.5525\n",
      "goal: 1, mean return: 10.8375\n",
      "goal: 2, mean return: 10.758\n",
      "goal: 3, mean return: 9.660499999999999\n",
      "goal: 4, mean return: 10.805000000000001\n",
      "goal: 5, mean return: 9.7075\n",
      "goal: 6, mean return: 9.732999999999999\n",
      "goal: 7, mean return: 10.756499999999999\n",
      "states shape: (3831, 11, 32, 32)\n",
      "(3831, 5)\n",
      "(3831, 5)\n",
      "(3831, 5)\n",
      "(3831, 5)\n",
      "(3831, 5)\n",
      "(3831, 5)\n",
      "(3831, 5)\n",
      "(3831, 5)\n",
      "NMF loss: 9197.164076747533\n",
      "NMF loss: 808.5793479891188\n",
      "NMF loss: 769.228318313529\n",
      "NMF loss: 757.1503584182356\n",
      "NMF loss: 747.2813202130321\n",
      "NMF loss: 725.565418096906\n",
      "NMF loss: 707.7245160289555\n",
      "NMF loss: 699.5464510798621\n",
      "NMF loss: 695.8218282061705\n",
      "NMF loss: 691.2797160941743\n",
      "NMF loss: 686.887616139198\n",
      "NMF loss: 675.967209777322\n",
      "NMF loss: 662.8619107216007\n",
      "NMF loss: 658.4993255243531\n",
      "NMF loss: 657.0433578766715\n",
      "NMF loss: 656.4941305882934\n",
      "NMF loss: 655.75023651771\n",
      "NMF loss: 655.2388400440261\n",
      "NMF loss: 654.8807665461395\n",
      "NMF loss: 654.6930310504289\n",
      "NMF loss: 654.287598328861\n",
      "NMF loss: 653.8047660068418\n",
      "NMF loss: 653.2143206638142\n",
      "NMF loss: 652.7508810964302\n",
      "NMF loss: 650.8837782658866\n",
      "NMF loss: 649.8888751190499\n",
      "NMF loss: 648.339261153965\n",
      "NMF loss: 647.6127727028721\n",
      "NMF loss: 647.4689584775832\n",
      "NMF loss: 647.3033710974453\n",
      "NMF loss: 646.9492468805009\n",
      "NMF loss: 646.5777245673088\n",
      "NMF loss: 646.238608060936\n",
      "NMF loss: 646.0134491617822\n",
      "NMF loss: 645.8146820298382\n",
      "NMF loss: 645.6177276961254\n",
      "NMF loss: 644.3820364666593\n",
      "NMF loss: 644.2393422575848\n",
      "NMF loss: 643.927407213535\n",
      "NMF loss: 642.7398614749986\n",
      "NMF loss: 642.3763243370241\n",
      "NMF loss: 642.2514631071297\n",
      "NMF loss: 642.1597527036703\n",
      "NMF loss: 642.021453521002\n",
      "NMF loss: 641.923629989542\n",
      "NMF loss: 641.2922165583324\n",
      "NMF loss: 641.2694377285962\n",
      "(8, 3831, 5)\n",
      "save: ../data/nmf_sample/pick/nineroom/split.20-0.2-20\n",
      "[[3.99367948e-211 1.79981139e-001 0.00000000e+000 ... 4.94065646e-324\n",
      "  0.00000000e+000 5.32770145e-002]\n",
      " [2.68387276e-003 1.89234174e-001 0.00000000e+000 ... 4.94065646e-324\n",
      "  0.00000000e+000 1.84521641e-003]\n",
      " [1.96234588e-003 1.83374318e-001 2.12569288e-133 ... 4.94065646e-324\n",
      "  0.00000000e+000 3.66060593e-042]\n",
      " ...\n",
      " [4.94065646e-324 1.81930067e-001 1.65322237e-003 ... 7.56945159e-002\n",
      "  0.00000000e+000 2.20108978e-013]\n",
      " [2.68837069e-003 1.89204902e-001 0.00000000e+000 ... 4.94065646e-324\n",
      "  0.00000000e+000 1.71541185e-003]\n",
      " [5.42302181e-004 1.90748589e-001 1.03585550e-003 ... 4.94065646e-324\n",
      "  0.00000000e+000 8.54273489e-004]]\n"
     ]
    }
   ],
   "source": [
    "%pdb on\n",
    "n_abs = 20\n",
    "l1_ratio = 0.0 # this is currently not working... since alpha is not set\n",
    "feat_dim = 512\n",
    "action_dim = 5\n",
    "horizon = 100\n",
    "n_trajs = 20 #30\n",
    "scale = 2\n",
    "n_objs = 9\n",
    "epsilon = 0.2\n",
    "\n",
    "# eps: 10: 341 - xxx, 20: 641 - 3831\n",
    "# mix: 10: 549 - 3317\n",
    "\n",
    "def get_expert(weight_path, action_dim):\n",
    "    visual_body = TSAMiniConvBody(\n",
    "        2 + n_objs, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale,\n",
    "        #gate=F.softplus,\n",
    "    )\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        n_objs,\n",
    "        0, # state_dim\n",
    "        action_dim,\n",
    "        visual_body,\n",
    "    )\n",
    "    # load weight\n",
    "    weight_dict = expert.state_dict()\n",
    "    loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "        weight_path,\n",
    "        map_location=lambda storage, loc: storage)['network'].items()\n",
    "        if k in weight_dict}\n",
    "    weight_dict.update(loaded_weight_dict)\n",
    "    expert.load_state_dict(weight_dict)\n",
    "    return expert\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "expert_dict = {\n",
    "    0: '../log/pick.mask.nineroom.0.min_dis-1/tsa.baseline.n_abs-512/relu/0.190327-232308/models/step-491520-mean-10.70',\n",
    "    1: '../log/pick.mask.nineroom.1.min_dis-1/tsa.baseline.n_abs-512/relu/1.190327-235057/models/step-491520-mean-10.84',\n",
    "    2: '../log/pick.mask.nineroom.2.min_dis-1/tsa.baseline.n_abs-512/relu/1.190328-000958/models/step-491520-mean-10.86',\n",
    "    3: '../log/pick.mask.nineroom.3.min_dis-1/tsa.baseline.n_abs-512/relu/2.190328-003751/models/step-491520-mean-10.71',\n",
    "    4: '../log/pick.mask.nineroom.4.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-005600/models/step-491520-mean-10.81',\n",
    "    5: '../log/pick.mask.nineroom.5.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-011456/models/step-491520-mean-10.78',\n",
    "    6: '../log/pick.mask.nineroom.6.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-014223/models/step-491520-mean-10.82',\n",
    "    7: '../log/pick.mask.nineroom.7.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-020127/models/step-491520-mean-10.84',\n",
    "}\n",
    "\n",
    "envs = dict()\n",
    "for i in range(8):\n",
    "    with open('../data/env_configs/pick/nineroom/nineroom.{}'.format(i), 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    print(env_config)\n",
    "    envs[i] = ScaleObsEnv(\n",
    "        PickGridWorld(\n",
    "            **env_config,\n",
    "            min_dis=1,\n",
    "            window=1,\n",
    "            task_length=1,\n",
    "            seed=0,\n",
    "        ),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "decomposer = MTNMF(n_abs, max_iter=5000, tol=0.0001)\n",
    "\n",
    "states = []\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    returns = []\n",
    "    experts[goal_idx] = get_expert(weight_path, action_dim)\n",
    "    for _ in range(n_trajs):\n",
    "        rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, \n",
    "                                                  experts[goal_idx], horizon=horizon, epsilon=epsilon)\n",
    "        states.append(rollout_states)\n",
    "        returns.append(rollout_returns)\n",
    "#     for _ in range(n_trajs // 2):\n",
    "#         rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, \n",
    "#                                                   experts[goal_idx], horizon=horizon)\n",
    "#         states.append(rollout_states)\n",
    "#         returns.append(rollout_returns)\n",
    "#     for _ in range(n_trajs - (n_trajs // 2)):\n",
    "#         rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, \n",
    "#                                                   None, horizon=horizon)\n",
    "#         states.append(rollout_states)\n",
    "    if returns: print('goal: {}, mean return: {}'.format(goal_idx, np.mean(returns)))\n",
    "states = np.concatenate(states)\n",
    "print('states shape:', states.shape)\n",
    "\n",
    "pvs = []\n",
    "\n",
    "for goal_idx in expert_dict:\n",
    "    cur_infos = {'task_id': [goal_idx] * len(states)}\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, cur_infos), dim=-1).cpu().detach().numpy()\n",
    "    print(pv.shape)\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.stack(pvs, 0)\n",
    "A, S, info = MTNMF(n_abs, max_iter=5000, l1_ratio=l1_ratio).fit(pvs.transpose(0, 2, 1))\n",
    "print(pvs.shape)\n",
    "save_path = '../data/nmf_sample/pick/nineroom/split.{}-{}-{}'.format(n_trajs, epsilon, n_abs)\n",
    "print('save: {}'.format(save_path))\n",
    "\n",
    "print(S.T)\n",
    "\n",
    "# fsave(\n",
    "#     dict(\n",
    "#         abs=S.T,\n",
    "#         policies=list(pvs),\n",
    "#         states=[states for _ in range(len(pvs))],\n",
    "#         infos=list([[{'task_id': i} for _ in range(len(states))] for i in experts.keys()]),\n",
    "#     ),\n",
    "#     save_path,\n",
    "#     'pkl',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTNMF (Fourroom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dim = 5\n",
    "scale=2\n",
    "n_objs = 4\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "def get_img(env, abs_list):\n",
    "    size = (env.unwrapped.row, env.unwrapped.col)\n",
    "    indices = np.zeros(size, dtype=np.int64)\n",
    "    k = 0\n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            if (i, j) in env.unwrapped.default_obj_pos[0]: # object position\n",
    "                indices[i, j] = 0\n",
    "            elif env.unwrapped.m[i][j] == '#':\n",
    "                indices[i, j] = 1\n",
    "            else:\n",
    "                indices[i, j] = visualization_map[str(2 + abs_list[k])]\n",
    "                k += 1\n",
    "\n",
    "    img = drawer.draw(indices)\n",
    "    return img\n",
    "\n",
    "def get_expert(weight_path, action_dim, feat_dim=512):\n",
    "    visual_body = TSAMiniMiniConvBody(\n",
    "        2 + n_objs, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale,\n",
    "        gate=F.softplus,\n",
    "    )\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        n_objs,\n",
    "        0, # state_dim\n",
    "        action_dim,\n",
    "        visual_body,\n",
    "    )\n",
    "    # load weight\n",
    "    #weight_dict = expert.state_dict()\n",
    "    #loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "    #    weight_path,\n",
    "    #    map_location=lambda storage, loc: storage)['network'].items()\n",
    "    #    if k in weight_dict}\n",
    "    #weight_dict.update(loaded_weight_dict)\n",
    "    #expert.load_state_dict(weight_dict)\n",
    "    expert.load_state_dict(torch.load(weight_path, map_location=lambda storage, loc: storage)['network'])\n",
    "    return expert\n",
    "\n",
    "def get_visualization_env():\n",
    "    with open('../data/env_configs/pick/fourroom/fourroom.3', 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    print(env_config)\n",
    "    env = ScaleObsEnv(\n",
    "        PickGridWorld(\n",
    "            **env_config,\n",
    "            min_dis=1,\n",
    "            window=1,\n",
    "            task_length=1,\n",
    "            seed=0,\n",
    "        ),\n",
    "        2,\n",
    "    )\n",
    "    env.reset(sample_obj_pos=False)\n",
    "    positions = env.unwrapped.pos_candidates\n",
    "    states = []\n",
    "    for pos in positions:\n",
    "        o, _, _, _ = env.teleport(*pos)\n",
    "        states.append(o)\n",
    "    print('states shape:', len(states))\n",
    "    return env, states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize for all states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "{'map_names': ['fourroom'], 'train_combos': [(0, 3)], 'test_combos': [(0, 3)], 'num_obj_types': 4, 'obj_pos': [[(1, 1), (9, 1), (1, 9), (9, 9)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'fourroom')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',))]\n",
      "train: [(0, 3)]\n",
      "test: [(0, 3)]\n",
      "states shape: 68\n",
      "(68, 5)\n",
      "(68, 5)\n",
      "(68, 5)\n",
      "NMF loss: 16.69140775941129\n",
      "NMF loss: 2.2600365846322408\n",
      "NMF loss: 2.2028002359008827\n",
      "NMF loss: 2.1205691250175107\n",
      "NMF loss: 2.0806840197212173\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALAAAACwCAYAAACvt+ReAAADNklEQVR4nO3csYqVVxSA0aukE0khATvFwqCQqXwBK5GxklGsgp1PELykSBnmBS5ipxY2DlMlWIpgaaWDkka0s7GwsI15h7sHfj6yVr/nnOH/ONXmnthsNt9XEHVy6QvAhIBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBk/bD9A/s7++P5m8/vTOaP/Pi2mh+6scz/4zmv375+Zhusp31vbOj+XNXrs/OX69H815g0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmLTxPvCn18+P4x5b+231eNHzVwvvI0/tP/w8mp9+/wcHL0fzXmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYtPE+8P/d9PeBP+x8HM0v/fvINw6/jeZ3h+d7gUkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSxvvA033Qv26eml6BgVc/nV76CiNeYNIETJqASRMwaQImTcCkCZg0AZMmYNIETJqASRMwaQImTcCkCZi08T7w7r+vR/M3Dq8Mzz8/ml/a+6O90fylqwezCwzPX5oXmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZtvA/898nZPu/Uh52Pi55/4c350fx0n3o1PH+1M9snnv7/U15g0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmLTxPvCjm5dH83cP302vkDbdZ75/8Y/juciW7h7Nvt90H9oLTJqASRMwaQImTcCkCZg0AZMmYNIETJqASRMwaQImTcCkCZg0AZM23geu7/OO92kvHs892I4XmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZtvA/89s+90fwvvx+M5t8fzc6f7vM+O3gymr+19+vsAgubfv/d9Xo07wUmTcCkCZg0AZMmYNIETJqASRMwaQImTcCkCZg0AZMmYNIETJqASTux2Wy+L30J2JYXmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAibtP7tWUB8emWrcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=176x176 at 0x7F047C54F9E8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pdb on\n",
    "n_abs = 5\n",
    "l1_ratio = 0.0 # this is currently not working... since alpha is not set\n",
    "horizon = 100\n",
    "n_trajs = 10\n",
    "save_abs = False\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "expert_dict = {\n",
    "    0: '../log/pick.mask.fourroom.0.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172629/models/step-92160-mean-10.86',\n",
    "    1: '../log/pick.mask.fourroom.1.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172739/models/step-92160-mean-10.74',\n",
    "    2: '../log/pick.mask.fourroom.2.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172847/models/step-92160-mean-10.81',\n",
    "    #3: '../log/pick.mask.fourroom.3.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172956/models/step-92160-mean-10.87'\n",
    "}\n",
    "\n",
    "env, states = get_visualization_env()\n",
    "    \n",
    "decomposer = MTNMF(n_abs, max_iter=5000, tol=0.0001)\n",
    "\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    experts[goal_idx] = get_expert(weight_path, action_dim)\n",
    "\n",
    "pvs = []\n",
    "\n",
    "for goal_idx in expert_dict:\n",
    "    cur_infos = {'task_id': [goal_idx] * len(states)}\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, cur_infos), dim=-1).cpu().detach().numpy()\n",
    "    print(pv.shape)\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.stack(pvs, 0)\n",
    "A, S, info = MTNMF(n_abs, max_iter=5000, l1_ratio=l1_ratio).fit(pvs.transpose(0, 2, 1))\n",
    "\n",
    "abs_list = S.T.argmax(1)\n",
    "img = get_img(env, abs_list)\n",
    "imshow(img)\n",
    "\n",
    "if save_abs:\n",
    "    save_path = '../data/nmf_sample/pick/fourroom/split.full.{}'.format(n_abs)\n",
    "    print('save: {}'.format(save_path))\n",
    "    fsave(\n",
    "        dict(\n",
    "            abs=S.T,\n",
    "            policies=list(pvs),\n",
    "            states=[states for _ in range(len(pvs))],\n",
    "            infos=list([[{'task_id': i} for _ in range(len(states))] for i in experts.keys()]),\n",
    "        ),\n",
    "        save_path,\n",
    "        'pkl',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize distilled states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map_names': ['fourroom'], 'train_combos': [(0, 3)], 'test_combos': [(0, 3)], 'num_obj_types': 4, 'obj_pos': [[(1, 1), (9, 1), (1, 9), (9, 9)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'fourroom')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',))]\n",
      "train: [(0, 3)]\n",
      "test: [(0, 3)]\n",
      "states shape: 68\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALAAAACwCAYAAACvt+ReAAADkUlEQVR4nO3cz6vlcxzH8XM1ykhN+bHQTYaMsrFyU1OsrCaNBQtGs3EtDBtlMWfBCnU3VuOUxbWaMCkLmiwpapSbkmIyU9xJEskfYMr1P9y3uj3zeOxf934Xzz6rd2dttVrtLSDqhoP+AJgQMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSDk3/wNbW1mh/7duvpp8w8uva7aP9Jx+8O9qffGZztP/5+99G+6lnTz062i+Xy9HeC0yagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTNr4Hfu/9L0b7S0/eNdof/+iX0X5978/RfnrPO3XTU4+M9l/eMbsnfvnIaD7mBSZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJG98D75y5b7R/ePbzvAdu+vvAZ55+YrS/8/wbo/3i9Kuz/dDOcO8FJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkb3wOfWP/nv/iOfXvum60D/f8biwdG++n3by8eGu1v/PqH0X7s4vnR3AtMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkza+B/7s5Nuj/fHHT4/2G8N70oN29q3VaP/8Ky+N9n98OrtnfvPEbD/lBSZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJG98DT+95D91yZbTfOXZ5tJ/auDq7h53eU29cHc0XO8dm99SXLroHhn0TMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSxvfAv699Ptrf8/dj009Im94zb+8eGe1fuH7zaL84em00f2f37tHeC0yagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTNr4HfvHCudH+48310f62w4dH+6mfHtwd7bcvz+55/++8wKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBp43vg6+d+nP2Bzdn8r9fuH+1vff3KaH/vd0dH+7PDe+KD9uGpC6P9crkc7b3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGlrq9Vq76A/AvbLC0yagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGT9i+OuWAElFZCvAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=176x176 at 0x7F3620611F98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_abs = 50\n",
    "l1_ratio = 0.0\n",
    "\n",
    "weight_dict = {\n",
    "    20: '../log/pick.split.mix.10-20/nmf_sample.baseline.n_abs-20/20/0.190325-224016/models/step-720000-acc-10.71',\n",
    "    50: '../log/pick.split.mix.10-50/nmf_sample.baseline.n_abs-50/50/0.190325-230619/models/step-1200000-acc-10.76',\n",
    "    5: '../log/pick.split.mix.10-5/nmf_sample.baseline.n_abs-5/5/0.190325-230625/models/step-220800-acc-7.96',\n",
    "}\n",
    "\n",
    "env, states = get_visualization_env()\n",
    "decomposer = MTNMF(n_abs, max_iter=5000, tol=0.0001)\n",
    "expert = get_expert(weight_dict[n_abs], action_dim, feat_dim=n_abs)\n",
    "\n",
    "abs_s = expert.network.phi_body(tensor(states))\n",
    "abs_list = abs_s.argmax(1).detach().cpu().numpy()\n",
    "img = get_img(env, abs_list)\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate from sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "{'map_names': ['fourroom'], 'train_combos': [(0, 1)], 'test_combos': [(0, 1)], 'num_obj_types': 4, 'obj_pos': [[(1, 1), (9, 1), (1, 9), (9, 9)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'fourroom')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',))]\n",
      "train: [(0, 1)]\n",
      "test: [(0, 1)]\n",
      "{'map_names': ['fourroom'], 'train_combos': [(0, 2)], 'test_combos': [(0, 2)], 'num_obj_types': 4, 'obj_pos': [[(1, 1), (9, 1), (1, 9), (9, 9)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'fourroom')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',))]\n",
      "train: [(0, 2)]\n",
      "test: [(0, 2)]\n",
      "{'map_names': ['fourroom'], 'train_combos': [(0, 3)], 'test_combos': [(0, 3)], 'num_obj_types': 4, 'obj_pos': [[(1, 1), (9, 1), (1, 9), (9, 9)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'fourroom')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',))]\n",
      "train: [(0, 3)]\n",
      "test: [(0, 3)]\n",
      "goal: 1, mean return: 10.83\n",
      "goal: 2, mean return: 10.788\n",
      "goal: 3, mean return: 10.852\n",
      "states shape: (1390, 6, 22, 22)\n",
      "(1390, 5)\n",
      "(1390, 5)\n",
      "(1390, 5)\n",
      "NMF loss: 403.0791689993032\n",
      "NMF loss: 0.9083178689316164\n",
      "NMF loss: 0.1833785277840069\n",
      "NMF loss: 0.08424294700908147\n",
      "NMF loss: 0.05707008591040772\n",
      "NMF loss: 0.043816133746081974\n",
      "(3, 1390, 5)\n",
      "save: ../data/nmf_sample/pick/fourroom/split.eps.10-50\n",
      "[[3.17076701e-03 1.21451934e-02 6.76322830e-03 ... 2.91484656e-03\n",
      "  2.91627201e-04 6.74416065e-03]\n",
      " [2.76161165e-03 3.74905709e-03 1.17925083e-02 ... 8.71576700e-03\n",
      "  6.29194110e-10 3.48401855e-04]\n",
      " [3.80832874e-03 5.80063261e-03 1.37451145e-02 ... 1.89567354e-02\n",
      "  9.24289715e-08 4.20442802e-04]\n",
      " ...\n",
      " [1.07971043e-03 1.56822360e-03 2.44832979e-02 ... 1.89230209e-02\n",
      "  1.35653148e-04 1.23879293e-02]\n",
      " [8.17931044e-04 2.81270236e-03 5.07261848e-02 ... 1.00906067e-03\n",
      "  3.33825365e-16 5.74738404e-03]\n",
      " [1.46102419e-03 3.15276841e-02 1.29689834e-02 ... 2.63907911e-04\n",
      "  2.46954015e-08 1.36652164e-03]]\n",
      "1.9302870129908417e-148 0.20257465767263735 0.007834264667362758\n"
     ]
    }
   ],
   "source": [
    "%pdb on\n",
    "n_abs = 50\n",
    "l1_ratio = 0.0 # this is currently not working... since alpha is not set\n",
    "feat_dim = 512\n",
    "action_dim = 5\n",
    "horizon = 100\n",
    "n_trajs = 10 # 30\n",
    "scale=2\n",
    "n_objs = 4\n",
    "\n",
    "def get_expert(weight_path, action_dim):\n",
    "    visual_body = TSAMiniMiniConvBody(\n",
    "        2 + n_objs, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale,\n",
    "        gate=F.softplus,\n",
    "    )\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        n_objs,\n",
    "        0, # state_dim\n",
    "        action_dim,\n",
    "        visual_body,\n",
    "    )\n",
    "    # load weight\n",
    "    weight_dict = expert.state_dict()\n",
    "    loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "        weight_path,\n",
    "        map_location=lambda storage, loc: storage)['network'].items()\n",
    "        if k in weight_dict}\n",
    "    weight_dict.update(loaded_weight_dict)\n",
    "    expert.load_state_dict(weight_dict)\n",
    "    return expert\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "expert_dict = {\n",
    "    #0: '../log/pick.mask.fourroom.0.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172629/models/step-92160-mean-10.86',\n",
    "    1: '../log/pick.mask.fourroom.1.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172739/models/step-92160-mean-10.74',\n",
    "    2: '../log/pick.mask.fourroom.2.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172847/models/step-92160-mean-10.81',\n",
    "    3: '../log/pick.mask.fourroom.3.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172956/models/step-92160-mean-10.87'\n",
    "}\n",
    "\n",
    "envs = dict()\n",
    "for i in range(1, 4):\n",
    "    with open('../data/env_configs/pick/fourroom/fourroom.{}'.format(i), 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    print(env_config)\n",
    "    envs[i] = ScaleObsEnv(\n",
    "        PickGridWorld(\n",
    "            **env_config,\n",
    "            min_dis=1,\n",
    "            window=1,\n",
    "            task_length=1,\n",
    "            seed=0,\n",
    "        ),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "decomposer = MTNMF(n_abs, max_iter=5000, tol=0.0001)\n",
    "\n",
    "states = []\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    returns = []\n",
    "    experts[goal_idx] = get_expert(weight_path, action_dim)\n",
    "#     for _ in range(n_trajs):\n",
    "#         rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, experts[goal_idx], horizon=horizon)\n",
    "#         states.append(rollout_states)\n",
    "#         returns.append(rollout_returns)\n",
    "    for _ in range(n_trajs // 2):\n",
    "        rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, experts[goal_idx], horizon=horizon)\n",
    "        states.append(rollout_states)\n",
    "        returns.append(rollout_returns)\n",
    "    for _ in range(n_trajs - (n_trajs // 2)):\n",
    "        rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, None, horizon=horizon)\n",
    "        states.append(rollout_states)\n",
    "    if returns: print('goal: {}, mean return: {}'.format(goal_idx, np.mean(returns)))\n",
    "states = np.concatenate(states)\n",
    "print('states shape:', states.shape)\n",
    "\n",
    "pvs = []\n",
    "\n",
    "for goal_idx in expert_dict:\n",
    "    cur_infos = {'task_id': [goal_idx] * len(states)}\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, cur_infos), dim=-1).cpu().detach().numpy()\n",
    "    print(pv.shape)\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.stack(pvs, 0)\n",
    "A, S, info = MTNMF(n_abs, max_iter=5000, l1_ratio=l1_ratio).fit(pvs.transpose(0, 2, 1))\n",
    "print(pvs.shape)\n",
    "save_path = '../data/nmf_sample/pick/fourroom/split.eps.{}-{}'.format(n_trajs, n_abs)\n",
    "print('save: {}'.format(save_path))\n",
    "\n",
    "print(S.T)\n",
    "print(S.min(), S.max(), S.mean())\n",
    "\n",
    "# fsave(\n",
    "#     dict(\n",
    "#         abs=S.T,\n",
    "#         policies=list(pvs),\n",
    "#         states=[states for _ in range(len(pvs))],\n",
    "#         infos=list([[{'task_id': i} for _ in range(len(states))] for i in experts.keys()]),\n",
    "#     ),\n",
    "#     save_path,\n",
    "#     'pkl',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTNMF (16x16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 1)], 'test_combos': [(0, 0)], 'num_obj_types': 5, 'obj_pos': [[(13, 6), (4, 13), (12, 2), (7, 4), (10, 14)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',))]\n",
      "train: [(0, 1)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 2)], 'test_combos': [(0, 0)], 'num_obj_types': 5, 'obj_pos': [[(13, 6), (4, 13), (12, 2), (7, 4), (10, 14)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',))]\n",
      "train: [(0, 2)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 3)], 'test_combos': [(0, 0)], 'num_obj_types': 5, 'obj_pos': [[(13, 6), (4, 13), (12, 2), (7, 4), (10, 14)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',))]\n",
      "train: [(0, 3)]\n",
      "test: [(0, 0)]\n",
      "goal: 1, mean return: 10.825\n",
      "goal: 2, mean return: 10.729\n",
      "goal: 3, mean return: 10.750499999999999\n",
      "states shape: (1386, 7, 32, 32)\n",
      "(1386, 5)\n",
      "(1386, 5)\n",
      "(1386, 5)\n",
      "NMF loss: 1104.8571246345532\n",
      "NMF loss: 23.12595219799843\n",
      "NMF loss: 22.184904303321844\n",
      "NMF loss: 21.32048805388361\n",
      "NMF loss: 19.76810116572497\n",
      "NMF loss: 16.648377347860286\n",
      "NMF loss: 7.78037957804346\n",
      "NMF loss: 7.5439797820258425\n",
      "NMF loss: 7.460257348741382\n",
      "NMF loss: 7.420814346402271\n",
      "NMF loss: 7.395461485713542\n",
      "NMF loss: 7.346009176010723\n",
      "NMF loss: 7.270553708720518\n",
      "NMF loss: 7.258510736870807\n",
      "(3, 1386, 5)\n"
     ]
    }
   ],
   "source": [
    "%pdb on\n",
    "n_abs = 20\n",
    "l1_ratio = 0.0 # this is currently not working... since alpha is not set\n",
    "feat_dim = 512\n",
    "action_dim = 5\n",
    "horizon = 100\n",
    "n_trajs = 20\n",
    "scale=2\n",
    "\n",
    "def get_expert(weight_path, action_dim):\n",
    "    visual_body = TSAMiniConvBody(\n",
    "        7, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale)\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        5,\n",
    "        0, # state_dim\n",
    "        action_dim,\n",
    "        visual_body,\n",
    "    )\n",
    "    # load weight\n",
    "    weight_dict = expert.state_dict()\n",
    "    loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "        weight_path,\n",
    "        map_location=lambda storage, loc: storage)['network'].items()\n",
    "        if k in weight_dict}\n",
    "    weight_dict.update(loaded_weight_dict)\n",
    "    expert.load_state_dict(weight_dict)\n",
    "    return expert\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "expert_dict = {\n",
    "    1: '../log/pick.mask.map49.5-1.min_dis-1/tsa.baseline.n_abs-512/_/0.190323-000115/models/step-1945600-mean-10.81',\n",
    "    2: '../log/pick.mask.map49.5-2.min_dis-1/tsa.baseline.n_abs-512/_/0.190323-002744/models/step-1945600-mean-10.72',\n",
    "    3: '../log/pick.mask.map49.5-3.min_dis-1/tsa.baseline.n_abs-512/_/0.190323-005347/models/step-1945600-mean-10.78',\n",
    "}\n",
    "\n",
    "envs = dict()\n",
    "for i in range(1, 4):\n",
    "    with open('../data/env_configs/pick/nmf/map49.5-{}'.format(i), 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    print(env_config)\n",
    "    envs[i] = ScaleObsEnv(\n",
    "        PickGridWorld(\n",
    "            **env_config,\n",
    "            min_dis=1,\n",
    "            window=1,\n",
    "            task_length=1,\n",
    "            seed=0,\n",
    "        ),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "decomposer = MTNMF(n_abs, max_iter=5000, tol=0.0001)\n",
    "\n",
    "states = []\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    returns = []\n",
    "    experts[goal_idx] = get_expert(weight_path, action_dim)\n",
    "    for _ in range(n_trajs):\n",
    "        rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, experts[goal_idx], horizon=horizon)\n",
    "        states.append(rollout_states)\n",
    "        returns.append(rollout_returns)\n",
    "    #for _ in range(n_trajs // 2):\n",
    "    #    states.append(rollout(envs[goal_idx], experts[goal_idx], horizon=horizon))\n",
    "    #for _ in range(n_trajs - (n_trajs // 2)):\n",
    "    #    states.append(rollout(envs[goal_idx-1], None, horizon=horizon))\n",
    "    print('goal: {}, mean return: {}'.format(goal_idx, np.mean(returns)))\n",
    "states = np.concatenate(states)\n",
    "print('states shape:', states.shape)\n",
    "\n",
    "pvs = []\n",
    "\n",
    "for goal_idx in expert_dict:\n",
    "    cur_infos = {'task_id': [goal_idx] * len(states)}\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, cur_infos), dim=-1).cpu().detach().numpy()\n",
    "    print(pv.shape)\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.stack(pvs, 0)\n",
    "A, S, info = MTNMF(n_abs, max_iter=5000, l1_ratio=l1_ratio).fit(pvs.transpose(0, 2, 1))\n",
    "print(pvs.shape)\n",
    "\n",
    "fsave(\n",
    "    dict(\n",
    "        abs=S.T,\n",
    "        policies=list(pvs),\n",
    "        states=[states for _ in range(len(pvs))],\n",
    "        infos=list([[{'task_id': i} for _ in range(len(states))] for i in experts.keys()]),\n",
    "    ),\n",
    "    '../data/nmf_sample/pick/split.{}'.format(n_abs),\n",
    "    'pkl',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "for i in range(9):\n",
    "    base_dir = '../log/pick.mask.nineroom.{}.min_dis-1/tsa.baseline.n_abs-512'.format(i)\n",
    "    os.rename(Path(base_dir, '_'), Path(base_dir, 'relu'))\n",
    "    os.rename(Path(base_dir, '20'), Path(base_dir, '20_relu'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
