{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from deep_rl.gridworld import ReachGridWorld, PickGridWorld, PORGBEnv, GoalManager, ScaleObsEnv\n",
    "from deep_rl.network import *\n",
    "from deep_rl.utils import *\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import dill\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from collections import Counter, namedtuple\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "def set_seed(s):\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "    torch.manual_seed(s)\n",
    "\n",
    "set_seed(0) # set seed \n",
    "\n",
    "class GridDrawer:                           \n",
    "    def __init__(self, color_list):\n",
    "        self.color_list = np.asarray(color_list)\n",
    "\n",
    "    # input: a 2-d index matrix\n",
    "    # output: a 2-d rgb matrix\n",
    "    def draw(self, indices, repeat=16):\n",
    "        return np.uint8(255 * np.array(self.color_list[indices, :]).repeat(repeat, 0).repeat(repeat, 1))\n",
    "    \n",
    "# this is my color list\n",
    "color_map = dict([\n",
    "    #*[('grey-{}'.format(v), plt.cm.Greys(0.1 * v)) for v in range(1, 20)],\n",
    "    *[('purple-{}'.format(v), plt.cm.Purples(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('blue-{}'.format(v), plt.cm.Blues(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('green-{}'.format(v), plt.cm.Greens(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('orange-{}'.format(v), plt.cm.Oranges(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('red-{}'.format(v), plt.cm.Reds(0.05 * v)) for v in range(1, 20)],\n",
    "])\n",
    "\n",
    "color_list = list(color_map.values())\n",
    "shuffle(color_list)\n",
    "color_list = [plt.cm.Greys(0.9)] + [plt.cm.Greys(0.5)] + color_list\n",
    "drawer = GridDrawer(color_list)\n",
    "\n",
    "visualization_map = dict([\n",
    "    ('G', 0), # goal\n",
    "    ('#', 1),\n",
    "    *[(str(i), i + 2) for i in range(0, 100)],\n",
    "])\n",
    "\n",
    "def imshow(img):\n",
    "    display(Image.fromarray(np.asarray(img).astype(np.uint8)))\n",
    "\n",
    "def fload(fn, ftype):\n",
    "    if ftype == 'json':\n",
    "        with open(fn) as f:\n",
    "            return json.load(f)\n",
    "    elif ftype == 'pkl':\n",
    "        with open(fn, 'rb') as f:\n",
    "            return dill.load(f)\n",
    "    elif ftype == 'png':\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        raise Exception('cannot read this data type: {}'.format(ftype))\n",
    "    \n",
    "def fsave(data, fn, ftype):\n",
    "    dirname = os.path.dirname(fn)\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    if ftype == 'json':\n",
    "        with open(fn, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "    elif ftype == 'pkl':\n",
    "        with open(fn, 'wb') as f:\n",
    "            dill.dump(data, f)    \n",
    "    elif ftype == 'png':\n",
    "        Image.fromarray(data).save(fn)\n",
    "    else:\n",
    "        raise Exception('unsupported file type: {}'.format(ftype))\n",
    "        \n",
    "GoalConfig = namedtuple('GoalConfig', ['map_name', 'n_goal', 'min_dis'])  \n",
    "\n",
    "# multitask NMF from: https://ieeexplore.ieee.org/document/6939673\n",
    "class MTNMF:\n",
    "    def __init__(\n",
    "        self, \n",
    "        n_components, \n",
    "        l1_ratio=0.0, \n",
    "        max_iter=200, \n",
    "        tol=0.0001, \n",
    "        normalize=False,\n",
    "        normalize_axis=0,\n",
    "    ):\n",
    "        self.n_components = n_components\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.normalize = normalize\n",
    "        self.normalize_axis = normalize_axis\n",
    "\n",
    "    def loss(self, X, A, S):\n",
    "        return 0.5 * ((X - np.matmul(A, S)) ** 2).sum() + self.l1_ratio * S.sum()\n",
    "        \n",
    "    # input: a stack of observed data X_1, ..., X_K\n",
    "    # output: S, A_1, ..., A_K\n",
    "    def fit(self, X):\n",
    "        K, N, M = X.shape\n",
    "        A = np.random.rand(K, N, self.n_components)\n",
    "        S = np.random.rand(self.n_components, M)\n",
    "        prev_loss = np.inf\n",
    "        cur_loss = None\n",
    "        for i in range(self.max_iter):\n",
    "            A_T = A.transpose(0, 2, 1)\n",
    "            new_S = S * (np.matmul(A_T, X).sum(0)) / (np.matmul(np.matmul(A_T, A), S).sum(0) + K * self.l1_ratio * np.ones((self.n_components, M)))\n",
    "            if self.normalize: \n",
    "                new_S = new_S / new_S.sum(self.normalize_axis, keepdims=True)\n",
    "            S = new_S\n",
    "            new_A = A * np.matmul(X, S.T) / np.matmul(np.matmul(A, S), S.T)\n",
    "            if self.normalize: \n",
    "                new_A = new_A / new_A.sum(self.normalize_axis + 1, keepdims=True)\n",
    "            A = new_A\n",
    "            cur_loss = self.loss(X, A, S)\n",
    "            if i % 100 == 0: print('NMF loss:', cur_loss)\n",
    "            if abs(cur_loss - prev_loss) < self.tol: break\n",
    "            prev_loss = cur_loss # update loss\n",
    "        return A, S, {'loss': cur_loss, 'iter': i}\n",
    "\n",
    "def rollout(env, idx, policy=None, horizon=100, epsilon=0.1):\n",
    "    states = []\n",
    "    returns = 0.0\n",
    "    done = False\n",
    "    #normalizer = ImageNormalizer()\n",
    "    state = env.reset(sample_obj_pos=False) # very important!\n",
    "    info = dict(task_id=[idx])\n",
    "    for _ in range(horizon):\n",
    "        states.append(state)\n",
    "        if policy is None:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = policy([state], info)['a'][0].cpu().detach().numpy()\n",
    "        state, r, done, _ = env.step(action) # note that info is not used\n",
    "        returns += r\n",
    "        if done: break\n",
    "    return states, returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTNMF (Nineroom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "\n",
    "def get_img(env, abs_list):\n",
    "    size = (env.unwrapped.row, env.unwrapped.col)\n",
    "    indices = np.zeros(size, dtype=np.int64)\n",
    "    k = 0\n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            if (i, j) in env.unwrapped.default_obj_pos[0]: # object position\n",
    "                indices[i, j] = 0\n",
    "            elif env.unwrapped.m[i][j] == '#':\n",
    "                indices[i, j] = 1\n",
    "            else:\n",
    "                indices[i, j] = visualization_map[str(2 + abs_list[k])]\n",
    "                k += 1\n",
    "\n",
    "    img = drawer.draw(indices)\n",
    "    return img\n",
    "\n",
    "def get_visualization_env():\n",
    "    with open('../data/env_configs/pick/nineroom/nineroom.8', 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    print(env_config)\n",
    "    env = ScaleObsEnv(\n",
    "        PickGridWorld(\n",
    "            **env_config,\n",
    "            min_dis=1,\n",
    "            window=1,\n",
    "            task_length=1,\n",
    "            seed=0,\n",
    "        ),\n",
    "        2,\n",
    "    )\n",
    "    env.reset(sample_obj_pos=False)\n",
    "    positions = env.unwrapped.pos_candidates\n",
    "    states = []\n",
    "    for pos in positions:\n",
    "        o, _, _, _ = env.teleport(*pos)\n",
    "        states.append(o)\n",
    "    print('states shape:', len(states))\n",
    "    return env, states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize all states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 8)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 8)]\n",
      "test: [(0, 0)]\n",
      "states shape: 152\n",
      "(152, 5)\n",
      "(152, 5)\n",
      "(152, 5)\n",
      "(152, 5)\n",
      "(152, 5)\n",
      "(152, 5)\n",
      "(152, 5)\n",
      "(152, 5)\n",
      "NMF loss: 380.10323753334484\n",
      "NMF loss: 362.0106982444329\n",
      "NMF loss: 326.07816764513706\n",
      "NMF loss: 281.82365402940786\n",
      "NMF loss: 252.51345863153045\n",
      "NMF loss: 237.37210325605147\n",
      "NMF loss: 228.416060336711\n",
      "NMF loss: 221.70443899916273\n",
      "NMF loss: 215.729999477217\n",
      "NMF loss: 209.7427206654534\n",
      "NMF loss: 203.01807388445232\n",
      "NMF loss: 194.92349715893192\n",
      "NMF loss: 185.20274526262904\n",
      "NMF loss: 174.19613970768037\n",
      "NMF loss: 163.35431791137583\n",
      "NMF loss: 154.55378650442108\n",
      "NMF loss: 148.4407680344284\n",
      "NMF loss: 144.48503316143785\n",
      "NMF loss: 141.93402130887398\n",
      "NMF loss: 140.26820602021783\n",
      "NMF loss: 139.12442782809933\n",
      "NMF loss: 138.26365572828473\n",
      "NMF loss: 137.5894409916237\n",
      "NMF loss: 137.06196281555123\n",
      "NMF loss: 136.66417591708924\n",
      "NMF loss: 136.3568194451043\n",
      "NMF loss: 136.09988287774405\n",
      "NMF loss: 135.87387567340824\n",
      "NMF loss: 135.67533018121497\n",
      "NMF loss: 135.49649734910003\n",
      "NMF loss: 135.31929776787197\n",
      "NMF loss: 135.13689484311612\n",
      "NMF loss: 134.9629398907545\n",
      "NMF loss: 134.8141901182866\n",
      "NMF loss: 134.69278421007655\n",
      "NMF loss: 134.5920577502866\n",
      "NMF loss: 134.50548433098558\n",
      "NMF loss: 134.42815228956928\n",
      "NMF loss: 134.35622842956872\n",
      "NMF loss: 134.28661040580454\n",
      "NMF loss: 134.21699337838567\n",
      "NMF loss: 134.14642807031433\n",
      "NMF loss: 134.0758005901791\n",
      "NMF loss: 134.00759310984847\n",
      "NMF loss: 133.94485999887306\n",
      "NMF loss: 133.88984316433167\n",
      "NMF loss: 133.84310018593712\n",
      "NMF loss: 133.80374938946818\n",
      "NMF loss: 133.77033714045325\n",
      "NMF loss: 133.7414940151765\n",
      "NMF loss: 133.71615060387632\n",
      "NMF loss: 133.69351142194492\n",
      "NMF loss: 133.67297452556164\n",
      "NMF loss: 133.65406591608024\n",
      "NMF loss: 133.63639535253364\n",
      "NMF loss: 133.619625656118\n",
      "NMF loss: 133.60345085941495\n",
      "NMF loss: 133.58758490494665\n",
      "NMF loss: 133.57176537451465\n",
      "NMF loss: 133.55577411926336\n",
      "NMF loss: 133.53947127960544\n",
      "NMF loss: 133.52283317259162\n",
      "NMF loss: 133.50597788948602\n",
      "NMF loss: 133.48915869736499\n",
      "NMF loss: 133.47271307488666\n",
      "NMF loss: 133.45697785361835\n",
      "NMF loss: 133.44220511569\n",
      "NMF loss: 133.42851658168496\n",
      "NMF loss: 133.41591030144258\n",
      "NMF loss: 133.40430348744547\n",
      "NMF loss: 133.39358318930172\n",
      "NMF loss: 133.38364442623137\n",
      "NMF loss: 133.37440944610262\n",
      "NMF loss: 133.36583094841978\n",
      "NMF loss: 133.35788507060764\n",
      "NMF loss: 133.3505598398324\n",
      "NMF loss: 133.34384389230883\n",
      "NMF loss: 133.3377189552209\n",
      "NMF loss: 133.33215773188022\n",
      "NMF loss: 133.32712676057852\n",
      "NMF loss: 133.32259223406524\n",
      "NMF loss: 133.31852611378253\n",
      "NMF loss: 133.31491004295887\n",
      "NMF loss: 133.31173518840416\n",
      "NMF loss: 133.3089970744802\n",
      "NMF loss: 133.30668592040175\n",
      "NMF loss: 133.30477507659828\n",
      "NMF loss: 133.3032121822313\n",
      "NMF loss: 133.30191795094055\n",
      "NMF loss: 133.30079462925008\n",
      "NMF loss: 133.29974111325583\n",
      "NMF loss: 133.29866809299892\n",
      "NMF loss: 133.29750766961934\n",
      "NMF loss: 133.29621668932856\n",
      "NMF loss: 133.29477675335585\n",
      "NMF loss: 133.29319304053155\n",
      "NMF loss: 133.29149059195197\n",
      "NMF loss: 133.2897053338409\n",
      "NMF loss: 133.2878700503482\n",
      "NMF loss: 133.28600041891843\n",
      "NMF loss: 133.28408850249147\n",
      "NMF loss: 133.28210773156073\n",
      "NMF loss: 133.280026298197\n",
      "NMF loss: 133.27782104162117\n",
      "NMF loss: 133.27548526671757\n",
      "NMF loss: 133.27302918456292\n",
      "NMF loss: 133.27047577516998\n",
      "NMF loss: 133.26785560874623\n",
      "NMF loss: 133.2652027234555\n",
      "NMF loss: 133.26255204234042\n",
      "NMF loss: 133.2599380640017\n",
      "NMF loss: 133.25739483143235\n",
      "NMF loss: 133.25495845709824\n",
      "NMF loss: 133.25267618616908\n",
      "NMF loss: 133.25063069292372\n",
      "NMF loss: 133.24898891893798\n",
      "NMF loss: 133.24803251351784\n",
      "NMF loss: 133.24792266069852\n",
      "NMF loss: 133.24812360046278\n",
      "NMF loss: 133.24778001811777\n",
      "NMF loss: 133.2467992245431\n",
      "NMF loss: 133.24554941006147\n",
      "NMF loss: 133.24429901376686\n",
      "NMF loss: 133.24316349847288\n",
      "NMF loss: 133.24218297390343\n",
      "NMF loss: 133.2413706033305\n",
      "NMF loss: 133.24073264226627\n",
      "NMF loss: 133.24027497644198\n",
      "NMF loss: 133.24000347601412\n",
      "NMF loss: 133.23992094741345\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=256x256 at 0x7FA0A1FD0E80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pdb on\n",
    "n_abs = 5\n",
    "l1_ratio = 0.0 # this is currently not working... since alpha is not set\n",
    "feat_dim = 512\n",
    "action_dim = 5\n",
    "horizon = 100\n",
    "n_trajs = 10 #30\n",
    "scale = 2\n",
    "n_objs = 9\n",
    "epsilon = 0.0\n",
    "normalize = True\n",
    "\n",
    "def get_expert(weight_path, action_dim):\n",
    "    visual_body = TSAMiniConvBody(\n",
    "        2 + n_objs, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale,\n",
    "        #gate=F.softplus,\n",
    "    )\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        n_objs,\n",
    "        0, # state_dim\n",
    "        action_dim,\n",
    "        visual_body,\n",
    "    )\n",
    "    # load weight\n",
    "    weight_dict = expert.state_dict()\n",
    "    loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "        weight_path,\n",
    "        map_location=lambda storage, loc: storage)['network'].items()\n",
    "        if k in weight_dict}\n",
    "    weight_dict.update(loaded_weight_dict)\n",
    "    expert.load_state_dict(weight_dict)\n",
    "    return expert\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "expert_dict = {\n",
    "    0: '../log/pick.mask.nineroom.0.min_dis-1/tsa.baseline.n_abs-512/relu/0.190327-232308/models/step-491520-mean-10.70',\n",
    "    1: '../log/pick.mask.nineroom.1.min_dis-1/tsa.baseline.n_abs-512/relu/1.190327-235057/models/step-491520-mean-10.84',\n",
    "    2: '../log/pick.mask.nineroom.2.min_dis-1/tsa.baseline.n_abs-512/relu/1.190328-000958/models/step-491520-mean-10.86',\n",
    "    3: '../log/pick.mask.nineroom.3.min_dis-1/tsa.baseline.n_abs-512/relu/2.190328-003751/models/step-491520-mean-10.71',\n",
    "    4: '../log/pick.mask.nineroom.4.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-005600/models/step-491520-mean-10.81',\n",
    "    5: '../log/pick.mask.nineroom.5.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-011456/models/step-491520-mean-10.78',\n",
    "    6: '../log/pick.mask.nineroom.6.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-014223/models/step-491520-mean-10.82',\n",
    "    7: '../log/pick.mask.nineroom.7.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-020127/models/step-491520-mean-10.84',\n",
    "}\n",
    "\n",
    "env, states = get_visualization_env()\n",
    "\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    experts[goal_idx] = get_expert(weight_path, action_dim)\n",
    "\n",
    "pvs = []\n",
    "\n",
    "for goal_idx in expert_dict:\n",
    "    cur_infos = {'task_id': [goal_idx] * len(states)}\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, cur_infos), dim=-1).cpu().detach().numpy()\n",
    "    print(pv.shape)\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.stack(pvs, 0)\n",
    "A, S, info = MTNMF(n_abs, max_iter=5000, l1_ratio=l1_ratio, normalize=normalize).fit(pvs.transpose(0, 2, 1))\n",
    "\n",
    "abs_list = S.T.argmax(1)\n",
    "img = get_img(env, abs_list)\n",
    "imshow(img)\n",
    "\n",
    "#print((S.T).sum(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate from sampling (C5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb on\n",
    "n_abs = 20\n",
    "l1_ratio = 0.0 # this is currently not working... since alpha is not set\n",
    "feat_dim = 512\n",
    "action_dim = 5\n",
    "horizon = 100\n",
    "n_trajs = 20 #30\n",
    "scale = 2\n",
    "n_objs = 9\n",
    "epsilon = 0.2\n",
    "normalize = False\n",
    "\n",
    "# eps: 10: 341 - xxx, 20: 641 - 3831\n",
    "# mix: 10: 549 - 3317\n",
    "\n",
    "def get_expert(weight_path, action_dim):\n",
    "    visual_body = TSAMiniConvBody(\n",
    "        2 + n_objs, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale,\n",
    "        #gate=F.softplus,\n",
    "    )\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        n_objs,\n",
    "        0, # state_dim\n",
    "        action_dim,\n",
    "        visual_body,\n",
    "    )\n",
    "    # load weight\n",
    "    weight_dict = expert.state_dict()\n",
    "    loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "        weight_path,\n",
    "        map_location=lambda storage, loc: storage)['network'].items()\n",
    "        if k in weight_dict}\n",
    "    weight_dict.update(loaded_weight_dict)\n",
    "    expert.load_state_dict(weight_dict)\n",
    "    return expert\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "expert_dict = {\n",
    "    0: '../log/pick.mask.nineroom.0.min_dis-1/tsa.baseline.n_abs-512/relu/0.190327-232308/models/step-491520-mean-10.70',\n",
    "    1: '../log/pick.mask.nineroom.1.min_dis-1/tsa.baseline.n_abs-512/relu/1.190327-235057/models/step-491520-mean-10.84',\n",
    "    2: '../log/pick.mask.nineroom.2.min_dis-1/tsa.baseline.n_abs-512/relu/1.190328-000958/models/step-491520-mean-10.86',\n",
    "    3: '../log/pick.mask.nineroom.3.min_dis-1/tsa.baseline.n_abs-512/relu/2.190328-003751/models/step-491520-mean-10.71',\n",
    "    4: '../log/pick.mask.nineroom.4.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-005600/models/step-491520-mean-10.81',\n",
    "    5: '../log/pick.mask.nineroom.5.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-011456/models/step-491520-mean-10.78',\n",
    "    6: '../log/pick.mask.nineroom.6.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-014223/models/step-491520-mean-10.82',\n",
    "    7: '../log/pick.mask.nineroom.7.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-020127/models/step-491520-mean-10.84',\n",
    "}\n",
    "\n",
    "envs = dict()\n",
    "for i in range(8):\n",
    "    with open('../data/env_configs/pick/nineroom/nineroom.{}'.format(i), 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    print(env_config)\n",
    "    envs[i] = ScaleObsEnv(\n",
    "        PickGridWorld(\n",
    "            **env_config,\n",
    "            min_dis=1,\n",
    "            window=1,\n",
    "            task_length=1,\n",
    "            seed=0,\n",
    "        ),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "states = []\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    returns = []\n",
    "    experts[goal_idx] = get_expert(weight_path, action_dim)\n",
    "    for _ in range(n_trajs):\n",
    "        rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, \n",
    "                                                  experts[goal_idx], horizon=horizon, epsilon=epsilon)\n",
    "        states.append(rollout_states)\n",
    "        returns.append(rollout_returns)\n",
    "#     for _ in range(n_trajs // 2):\n",
    "#         rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, \n",
    "#                                                   experts[goal_idx], horizon=horizon)\n",
    "#         states.append(rollout_states)\n",
    "#         returns.append(rollout_returns)\n",
    "#     for _ in range(n_trajs - (n_trajs // 2)):\n",
    "#         rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, \n",
    "#                                                   None, horizon=horizon)\n",
    "#         states.append(rollout_states)\n",
    "    if returns: print('goal: {}, mean return: {}'.format(goal_idx, np.mean(returns)))\n",
    "states = np.concatenate(states)\n",
    "print('states shape:', states.shape)\n",
    "\n",
    "pvs = []\n",
    "\n",
    "for goal_idx in expert_dict:\n",
    "    cur_infos = {'task_id': [goal_idx] * len(states)}\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, cur_infos), dim=-1).cpu().detach().numpy()\n",
    "    print(pv.shape)\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.stack(pvs, 0)\n",
    "A, S, info = MTNMF(n_abs, max_iter=5000, l1_ratio=l1_ratio, normalize=normalize).fit(pvs.transpose(0, 2, 1))\n",
    "print(pvs.shape)\n",
    "save_path = '../data/nmf_sample/pick/nineroom/split.n.{}-{}-{}'.format(n_trajs, epsilon, n_abs)\n",
    "print('save: {}'.format(save_path))\n",
    "\n",
    "print(S.T)\n",
    "\n",
    "# fsave(\n",
    "#     dict(\n",
    "#         abs=S.T,\n",
    "#         policies=list(pvs),\n",
    "#         states=[states for _ in range(len(pvs))],\n",
    "#         infos=list([[{'task_id': i} for _ in range(len(states))] for i in experts.keys()]),\n",
    "#     ),\n",
    "#     save_path,\n",
    "#     'pkl',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate from sampling (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 0)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 0)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 1)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 1)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 2)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 2)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 3)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 3)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 4)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 4)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 5)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 5)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 6)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 6)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 7)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 7)]\n",
      "test: [(0, 0)]\n",
      "goal: 0, mean return: 10.687999999999999\n",
      "goal: 1, mean return: 10.862\n",
      "goal: 2, mean return: 10.772\n",
      "goal: 3, mean return: 10.732\n",
      "goal: 4, mean return: 10.835999999999999\n",
      "goal: 5, mean return: 10.784\n",
      "goal: 6, mean return: 10.808000000000002\n",
      "goal: 7, mean return: 10.818000000000001\n",
      "states shape: (3317, 11, 32, 32)\n",
      "(3317, 5)\n",
      "(3317, 5)\n",
      "(3317, 5)\n",
      "(3317, 5)\n",
      "(3317, 5)\n",
      "(3317, 5)\n",
      "(3317, 5)\n",
      "(3317, 5)\n",
      "NMF loss: 8180.019178724851\n",
      "NMF loss: 674.8850210049445\n",
      "NMF loss: 601.7551295420795\n",
      "NMF loss: 579.4472517840088\n",
      "NMF loss: 572.6091212588749\n",
      "NMF loss: 568.6671027822882\n",
      "NMF loss: 561.4521146930209\n",
      "NMF loss: 558.186913440556\n",
      "NMF loss: 555.7930116437335\n",
      "NMF loss: 553.242091845269\n",
      "NMF loss: 552.6290301327151\n",
      "NMF loss: 551.2283614688279\n",
      "NMF loss: 550.8683105020348\n",
      "NMF loss: 550.7052342649116\n",
      "NMF loss: 550.5163537862784\n",
      "NMF loss: 550.3164578436621\n",
      "NMF loss: 550.2099258904055\n",
      "NMF loss: 550.1370929807227\n",
      "NMF loss: 550.0575777524695\n",
      "NMF loss: 549.9933881120355\n",
      "NMF loss: 549.9734972580889\n",
      "NMF loss: 549.9509565339123\n",
      "NMF loss: 549.9306571461082\n",
      "NMF loss: 549.9102381099491\n",
      "NMF loss: 549.8927226607038\n",
      "NMF loss: 549.8562578679778\n",
      "NMF loss: 549.7865114965019\n",
      "NMF loss: 549.7736428562525\n",
      "NMF loss: 549.769383165069\n",
      "NMF loss: 549.7650969946615\n",
      "NMF loss: 549.7609266555543\n",
      "NMF loss: 549.7571628405349\n",
      "NMF loss: 549.7537018618016\n",
      "NMF loss: 549.7502447947764\n",
      "NMF loss: 549.7466784552312\n",
      "NMF loss: 549.7424964772081\n",
      "NMF loss: 549.7337606359805\n",
      "NMF loss: 549.7273516525242\n",
      "NMF loss: 549.722645747467\n",
      "NMF loss: 549.7176654783042\n",
      "NMF loss: 549.7120695270473\n",
      "NMF loss: 549.7057303592504\n",
      "NMF loss: 549.695760523014\n",
      "NMF loss: 549.6788575757905\n",
      "NMF loss: 549.6612473408665\n",
      "NMF loss: 549.6455002311058\n",
      "NMF loss: 549.6292529302765\n",
      "NMF loss: 549.6165182980994\n",
      "NMF loss: 549.6076649984859\n",
      "NMF loss: 549.6044159713625\n",
      "(8, 3317, 5)\n",
      "save: ../data/nmf_sample/pick/nineroom/split.new.10-0.0-20\n",
      "[[4.94065646e-324 0.00000000e+000 9.88131292e-324 ... 9.88131292e-324\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [4.94065646e-324 0.00000000e+000 6.32359561e-263 ... 2.47032823e-323\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [4.94065646e-324 0.00000000e+000 1.48219694e-323 ... 5.16525848e-004\n",
      "  0.00000000e+000 1.48219694e-323]\n",
      " ...\n",
      " [1.48219694e-323 4.00768989e-003 0.00000000e+000 ... 0.00000000e+000\n",
      "  1.60905779e-001 0.00000000e+000]\n",
      " [9.88131292e-324 4.94065646e-324 0.00000000e+000 ... 4.94065646e-324\n",
      "  1.48219694e-323 1.30119659e-271]\n",
      " [9.88131292e-324 4.94065646e-324 0.00000000e+000 ... 4.94065646e-324\n",
      "  1.48219694e-323 5.82284834e-272]]\n"
     ]
    }
   ],
   "source": [
    "%pdb on\n",
    "n_abs = 20\n",
    "l1_ratio = 0.0 # this is currently not working... since alpha is not set\n",
    "feat_dim = 512\n",
    "action_dim = 5\n",
    "horizon = 100\n",
    "n_trajs = 10 #30\n",
    "scale = 2\n",
    "n_objs = 9\n",
    "epsilon = 0.0\n",
    "normalize = False\n",
    "\n",
    "# eps: 10: 341 - xxx, 20: 641 - 3831\n",
    "# mix: 10: 549 - 3317\n",
    "\n",
    "def get_expert(weight_path, action_dim):\n",
    "    visual_body = TSAMiniConvBody(\n",
    "        2 + n_objs, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale,\n",
    "        #gate=F.softplus,\n",
    "    )\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        n_objs,\n",
    "        0, # state_dim\n",
    "        action_dim,\n",
    "        visual_body,\n",
    "    )\n",
    "    # load weight\n",
    "    weight_dict = expert.state_dict()\n",
    "    loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "        weight_path,\n",
    "        map_location=lambda storage, loc: storage)['network'].items()\n",
    "        if k in weight_dict}\n",
    "    weight_dict.update(loaded_weight_dict)\n",
    "    expert.load_state_dict(weight_dict)\n",
    "    return expert\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "expert_dict = {\n",
    "    0: '../log/pick.mask.nineroom.0.min_dis-1/tsa.baseline.n_abs-512/relu/0.190327-232308/models/step-491520-mean-10.70',\n",
    "    1: '../log/pick.mask.nineroom.1.min_dis-1/tsa.baseline.n_abs-512/relu/1.190327-235057/models/step-491520-mean-10.84',\n",
    "    2: '../log/pick.mask.nineroom.2.min_dis-1/tsa.baseline.n_abs-512/relu/1.190328-000958/models/step-491520-mean-10.86',\n",
    "    3: '../log/pick.mask.nineroom.3.min_dis-1/tsa.baseline.n_abs-512/relu/2.190328-003751/models/step-491520-mean-10.71',\n",
    "    4: '../log/pick.mask.nineroom.4.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-005600/models/step-491520-mean-10.81',\n",
    "    5: '../log/pick.mask.nineroom.5.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-011456/models/step-491520-mean-10.78',\n",
    "    6: '../log/pick.mask.nineroom.6.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-014223/models/step-491520-mean-10.82',\n",
    "    7: '../log/pick.mask.nineroom.7.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-020127/models/step-491520-mean-10.84',\n",
    "}\n",
    "\n",
    "envs = dict()\n",
    "for i in range(8):\n",
    "    with open('../data/env_configs/pick/nineroom/nineroom.{}'.format(i), 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    print(env_config)\n",
    "    envs[i] = ScaleObsEnv(\n",
    "        PickGridWorld(\n",
    "            **env_config,\n",
    "            min_dis=1,\n",
    "            window=1,\n",
    "            task_length=1,\n",
    "            seed=0,\n",
    "        ),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "states = []\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    returns = []\n",
    "    experts[goal_idx] = get_expert(weight_path, action_dim)\n",
    "#     for _ in range(n_trajs):\n",
    "#         rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, \n",
    "#                                                   experts[goal_idx], horizon=horizon, epsilon=epsilon)\n",
    "#         states.append(rollout_states)\n",
    "#         returns.append(rollout_returns)\n",
    "    for _ in range(n_trajs // 2):\n",
    "        rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, \n",
    "                                                  experts[goal_idx], horizon=horizon)\n",
    "        states.append(rollout_states)\n",
    "        returns.append(rollout_returns)\n",
    "    for _ in range(n_trajs - (n_trajs // 2)):\n",
    "        rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, \n",
    "                                                  None, horizon=horizon)\n",
    "        states.append(rollout_states)\n",
    "    if returns: print('goal: {}, mean return: {}'.format(goal_idx, np.mean(returns)))\n",
    "states = np.concatenate(states)\n",
    "print('states shape:', states.shape)\n",
    "\n",
    "pvs = []\n",
    "\n",
    "for goal_idx in expert_dict:\n",
    "    cur_infos = {'task_id': [goal_idx] * len(states)}\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, cur_infos), dim=-1).cpu().detach().numpy()\n",
    "    print(pv.shape)\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.stack(pvs, 0)\n",
    "A, S, info = MTNMF(n_abs, max_iter=5000, tol=1e-5, l1_ratio=l1_ratio, normalize=normalize).fit(pvs.transpose(0, 2, 1))\n",
    "print(pvs.shape)\n",
    "save_path = '../data/nmf_sample/pick/nineroom/split.new.{}-{}-{}'.format(n_trajs, epsilon, n_abs)\n",
    "print('save: {}'.format(save_path))\n",
    "\n",
    "print(S.T)\n",
    "\n",
    "# fsave(\n",
    "#     dict(\n",
    "#         abs=S.T,\n",
    "#         policies=list(pvs),\n",
    "#         actors=list(A),\n",
    "#         states=[states for _ in range(len(pvs))],\n",
    "#         infos=list([[{'task_id': i} for _ in range(len(states))] for i in experts.keys()]),\n",
    "#     ),\n",
    "#     save_path,\n",
    "#     'pkl',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate from sampling (KL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 0)]\n",
      "test: [(0, 0)]\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 1)]\n",
      "test: [(0, 0)]\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 2)]\n",
      "test: [(0, 0)]\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 3)]\n",
      "test: [(0, 0)]\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 4)]\n",
      "test: [(0, 0)]\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 5)]\n",
      "test: [(0, 0)]\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 6)]\n",
      "test: [(0, 0)]\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 7)]\n",
      "test: [(0, 0)]\n",
      "goal: 0, mean return: 10.684000000000001\n",
      "goal: 1, mean return: 10.862\n",
      "goal: 2, mean return: 10.802000000000001\n",
      "goal: 3, mean return: 10.720000000000002\n",
      "goal: 4, mean return: 10.834\n",
      "goal: 5, mean return: 10.77\n",
      "goal: 6, mean return: 10.794\n",
      "goal: 7, mean return: 10.818000000000001\n",
      "states shape: (3462, 11, 32, 32)\n",
      "Epoch 10 reached after 0.059 seconds, error: 101.648755\n",
      "Epoch 20 reached after 0.101 seconds, error: 97.362054\n",
      "Epoch 30 reached after 0.125 seconds, error: 96.792467\n",
      "Epoch 40 reached after 0.149 seconds, error: 96.468883\n",
      "Epoch 50 reached after 0.173 seconds, error: 95.270659\n",
      "Epoch 60 reached after 0.199 seconds, error: 95.151055\n",
      "Epoch 70 reached after 0.223 seconds, error: 94.959504\n",
      "Epoch 80 reached after 0.247 seconds, error: 94.900024\n",
      "Epoch 90 reached after 0.274 seconds, error: 94.747569\n",
      "Epoch 100 reached after 0.298 seconds, error: 94.644230\n",
      "Epoch 110 reached after 0.322 seconds, error: 94.576503\n",
      "Epoch 120 reached after 0.345 seconds, error: 94.547708\n",
      "Epoch 130 reached after 0.369 seconds, error: 94.542419\n",
      "original shape of A: (20, 40)\n",
      "number of elements in A: 8 shape of each element: (20, 5)\n",
      "number of elements in pvs: 8 shape of each element: (3462, 5)\n",
      "(3462, 20)\n",
      "[[2.00996112e-04 3.14584404e-01 0.00000000e+00 ... 0.00000000e+00\n",
      "  1.94855160e-04 0.00000000e+00]\n",
      " [3.08904330e-04 2.74935516e-01 1.51644991e-35 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.82292324e-36 2.65480107e-01 2.83549934e-20 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.65895056e-01 0.00000000e+00 0.00000000e+00 ... 1.87182154e-01\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.68972892e-02 0.00000000e+00 0.00000000e+00 ... 1.05793308e-01\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.65895056e-01 0.00000000e+00 0.00000000e+00 ... 1.87182154e-01\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "save: ../data/nmf_sample/pick/nineroom/split.kl.10-0.0-20\n"
     ]
    }
   ],
   "source": [
    "%pdb on\n",
    "from sklearn.decomposition import NMF\n",
    "n_abs = 20\n",
    "l1_ratio = 0.0\n",
    "feat_dim = 512\n",
    "action_dim = 5\n",
    "horizon = 100\n",
    "n_trajs = 10 #30\n",
    "scale = 2\n",
    "n_objs = 9\n",
    "epsilon = 0.0\n",
    "\n",
    "def get_expert(weight_path, action_dim):\n",
    "    visual_body = TSAMiniConvBody(\n",
    "        2 + n_objs, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale,\n",
    "    )\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        n_objs,\n",
    "        0, # state_dim\n",
    "        action_dim,\n",
    "        visual_body,\n",
    "    )\n",
    "    # load weight\n",
    "    weight_dict = expert.state_dict()\n",
    "    loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "        weight_path,\n",
    "        map_location=lambda storage, loc: storage)['network'].items()\n",
    "        if k in weight_dict}\n",
    "    weight_dict.update(loaded_weight_dict)\n",
    "    expert.load_state_dict(weight_dict)\n",
    "    return expert\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "expert_dict = {\n",
    "    0: '../log/pick.mask.nineroom.0.min_dis-1/tsa.baseline.n_abs-512/relu/0.190327-232308/models/step-491520-mean-10.70',\n",
    "    1: '../log/pick.mask.nineroom.1.min_dis-1/tsa.baseline.n_abs-512/relu/1.190327-235057/models/step-491520-mean-10.84',\n",
    "    2: '../log/pick.mask.nineroom.2.min_dis-1/tsa.baseline.n_abs-512/relu/1.190328-000958/models/step-491520-mean-10.86',\n",
    "    3: '../log/pick.mask.nineroom.3.min_dis-1/tsa.baseline.n_abs-512/relu/2.190328-003751/models/step-491520-mean-10.71',\n",
    "    4: '../log/pick.mask.nineroom.4.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-005600/models/step-491520-mean-10.81',\n",
    "    5: '../log/pick.mask.nineroom.5.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-011456/models/step-491520-mean-10.78',\n",
    "    6: '../log/pick.mask.nineroom.6.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-014223/models/step-491520-mean-10.82',\n",
    "    7: '../log/pick.mask.nineroom.7.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-020127/models/step-491520-mean-10.84',\n",
    "}\n",
    "\n",
    "envs = dict()\n",
    "for i in range(8):\n",
    "    with open('../data/env_configs/pick/nineroom/nineroom.{}'.format(i), 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    #print(env_config)\n",
    "    envs[i] = ScaleObsEnv(\n",
    "        PickGridWorld(\n",
    "            **env_config,\n",
    "            min_dis=1,\n",
    "            window=1,\n",
    "            task_length=1,\n",
    "            seed=0,\n",
    "        ),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "states = []\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    returns = []\n",
    "    experts[goal_idx] = get_expert(weight_path, action_dim)\n",
    "#     for _ in range(n_trajs):\n",
    "#         rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, \n",
    "#                                                   experts[goal_idx], horizon=horizon, epsilon=epsilon)\n",
    "#         states.append(rollout_states)\n",
    "#         returns.append(rollout_returns)\n",
    "    for _ in range(n_trajs // 2):\n",
    "        rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, \n",
    "                                                  experts[goal_idx], horizon=horizon)\n",
    "        states.append(rollout_states)\n",
    "        returns.append(rollout_returns)\n",
    "    for _ in range(n_trajs - (n_trajs // 2)):\n",
    "        rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, \n",
    "                                                  None, horizon=horizon)\n",
    "        states.append(rollout_states)\n",
    "    if returns: print('goal: {}, mean return: {}'.format(goal_idx, np.mean(returns)))\n",
    "states = np.concatenate(states)\n",
    "print('states shape:', states.shape)\n",
    "\n",
    "pvs = []\n",
    "\n",
    "for goal_idx in expert_dict:\n",
    "    cur_infos = {'task_id': [goal_idx] * len(states)}\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, cur_infos), dim=-1).cpu().detach().numpy()\n",
    "    #print(pv.shape)\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.concatenate(pvs, axis=1)\n",
    "#A, S, info = MTNMF(n_abs, max_iter=5000, tol=1e-5, l1_ratio=l1_ratio, normalize=normalize).fit(pvs.transpose(0, 2, 1))\n",
    "decomposer = NMF(n_abs, solver='mu', max_iter=5000, beta_loss='kullback-leibler', verbose=True, random_state=0)\n",
    "S = decomposer.fit_transform(pvs)\n",
    "A = decomposer.components_\n",
    "print('original shape of A:', A.shape)\n",
    "pvs = [pvs[:,i:i+action_dim] for i in range(0, pvs.shape[1], action_dim)]\n",
    "A = [A[:,i:i+action_dim] for i in range(0, A.shape[1], action_dim)]\n",
    "print('number of elements in A:', len(A), 'shape of each element:', A[0].shape)\n",
    "print('number of elements in pvs:', len(pvs), 'shape of each element:', pvs[0].shape)\n",
    "print(S.shape)\n",
    "print(S)\n",
    "save_path = '../data/nmf_sample/pick/nineroom/split.kl.{}-{}-{}'.format(n_trajs, epsilon, n_abs)\n",
    "print('save: {}'.format(save_path))\n",
    "\n",
    "fsave(\n",
    "    dict(\n",
    "        abs=S,\n",
    "        policies=list(pvs),\n",
    "        actors=list(A),\n",
    "        states=[states for _ in range(len(pvs))],\n",
    "        infos=list([[{'task_id': i} for _ in range(len(states))] for i in experts.keys()]),\n",
    "    ),\n",
    "    save_path,\n",
    "    'pkl',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 0)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 0)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 1)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 1)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 2)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 2)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 3)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 3)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 4)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 4)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 5)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 5)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 6)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 6)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 7)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 7)]\n",
      "test: [(0, 0)]\n",
      "goal: 0, mean return: 7.490500000000002\n",
      "goal: 1, mean return: 10.836500000000001\n",
      "goal: 2, mean return: 10.761\n",
      "goal: 3, mean return: 8.616000000000001\n",
      "goal: 4, mean return: 8.726499999999998\n",
      "goal: 5, mean return: 10.746999999999998\n",
      "goal: 6, mean return: 10.775\n",
      "goal: 7, mean return: 10.770500000000002\n",
      "states shape: (3720, 11, 32, 32)\n",
      "(3720, 5)\n",
      "(3720, 5)\n",
      "(3720, 5)\n",
      "(3720, 5)\n",
      "(3720, 5)\n",
      "(3720, 5)\n",
      "(3720, 5)\n",
      "(3720, 5)\n",
      "NMF loss: 13508.570147590292\n",
      "(8, 3720, 5)\n",
      "save: ../data/nmf_sample/pick/nineroom/split.n.20-0.2-8\n",
      "[[1.0e-26 6.3e-19 1.0e+00 3.7e-94 2.2e-03]\n",
      " [9.8e-01 2.3e-28 2.6e-40 1.7e-02 3.1e-04]\n",
      " [2.4e-02 1.7e-04 1.6e-91 9.7e-01 7.0e-04]\n",
      " [3.6e-20 9.2e-01 8.1e-02 2.0e-17 9.3e-14]\n",
      " [1.6e-25 2.4e-07 2.6e-01 7.4e-01 3.3e-03]\n",
      " [1.0e+00 3.6e-46 3.7e-47 8.7e-08 2.4e-04]\n",
      " [2.8e-01 1.2e-23 7.2e-01 8.2e-35 1.0e-04]\n",
      " [9.2e-10 9.5e-01 5.8e-23 5.1e-02 1.1e-03]]\n"
     ]
    }
   ],
   "source": [
    "%pdb on\n",
    "n_abs = 8\n",
    "l1_ratio = 0.0 # this is currently not working... since alpha is not set\n",
    "feat_dim = 512\n",
    "action_dim = 5\n",
    "horizon = 100\n",
    "n_trajs = 20 #30\n",
    "scale = 2\n",
    "n_objs = 9\n",
    "epsilon = 0.2\n",
    "normalize = True\n",
    "\n",
    "# eps: 10: 341 - xxx, 20: 641 - 3831\n",
    "# mix: 10: 549 - 3317\n",
    "\n",
    "def get_expert(weight_path, action_dim):\n",
    "    visual_body = TSAMiniConvBody(\n",
    "        2 + n_objs, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale,\n",
    "        #gate=F.softplus,\n",
    "    )\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        n_objs,\n",
    "        0, # state_dim\n",
    "        action_dim,\n",
    "        visual_body,\n",
    "    )\n",
    "    # load weight\n",
    "    weight_dict = expert.state_dict()\n",
    "    loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "        weight_path,\n",
    "        map_location=lambda storage, loc: storage)['network'].items()\n",
    "        if k in weight_dict}\n",
    "    weight_dict.update(loaded_weight_dict)\n",
    "    expert.load_state_dict(weight_dict)\n",
    "    return expert\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "expert_dict = {\n",
    "    0: '../log/pick.mask.nineroom.0.min_dis-1/tsa.baseline.n_abs-512/relu/0.190327-232308/models/step-491520-mean-10.70',\n",
    "    1: '../log/pick.mask.nineroom.1.min_dis-1/tsa.baseline.n_abs-512/relu/1.190327-235057/models/step-491520-mean-10.84',\n",
    "    2: '../log/pick.mask.nineroom.2.min_dis-1/tsa.baseline.n_abs-512/relu/1.190328-000958/models/step-491520-mean-10.86',\n",
    "    3: '../log/pick.mask.nineroom.3.min_dis-1/tsa.baseline.n_abs-512/relu/2.190328-003751/models/step-491520-mean-10.71',\n",
    "    4: '../log/pick.mask.nineroom.4.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-005600/models/step-491520-mean-10.81',\n",
    "    5: '../log/pick.mask.nineroom.5.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-011456/models/step-491520-mean-10.78',\n",
    "    6: '../log/pick.mask.nineroom.6.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-014223/models/step-491520-mean-10.82',\n",
    "    7: '../log/pick.mask.nineroom.7.min_dis-1/tsa.baseline.n_abs-512/relu/0.190328-020127/models/step-491520-mean-10.84',\n",
    "}\n",
    "\n",
    "envs = dict()\n",
    "for i in range(8):\n",
    "    with open('../data/env_configs/pick/nineroom/nineroom.{}'.format(i), 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    print(env_config)\n",
    "    envs[i] = ScaleObsEnv(\n",
    "        PickGridWorld(\n",
    "            **env_config,\n",
    "            min_dis=1,\n",
    "            window=1,\n",
    "            task_length=1,\n",
    "            seed=0,\n",
    "        ),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "states = []\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    returns = []\n",
    "    experts[goal_idx] = get_expert(weight_path, action_dim)\n",
    "    for _ in range(n_trajs):\n",
    "        rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, \n",
    "                                                  experts[goal_idx], horizon=horizon, epsilon=epsilon)\n",
    "        states.append(rollout_states)\n",
    "        returns.append(rollout_returns)\n",
    "#     for _ in range(n_trajs // 2):\n",
    "#         rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, \n",
    "#                                                   experts[goal_idx], horizon=horizon)\n",
    "#         states.append(rollout_states)\n",
    "#         returns.append(rollout_returns)\n",
    "#     for _ in range(n_trajs - (n_trajs // 2)):\n",
    "#         rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, \n",
    "#                                                   None, horizon=horizon)\n",
    "#         states.append(rollout_states)\n",
    "    if returns: print('goal: {}, mean return: {}'.format(goal_idx, np.mean(returns)))\n",
    "states = np.concatenate(states)\n",
    "print('states shape:', states.shape)\n",
    "\n",
    "pvs = []\n",
    "\n",
    "for goal_idx in expert_dict:\n",
    "    cur_infos = {'task_id': [goal_idx] * len(states)}\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, cur_infos), dim=-1).cpu().detach().numpy()\n",
    "    print(pv.shape)\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.stack(pvs, 0)\n",
    "S, D, info = MTNMF(n_abs, max_iter=5000, l1_ratio=l1_ratio, normalize=normalize, normalize_axis=1).fit(pvs)\n",
    "print(pvs.shape)\n",
    "save_path = '../data/nmf_sample/pick/nineroom/split.n.{}-{}-{}'.format(n_trajs, epsilon, n_abs)\n",
    "print('save: {}'.format(save_path))\n",
    "\n",
    "print(D)\n",
    "\n",
    "# fsave(\n",
    "#     dict(\n",
    "#         abs=S.T,\n",
    "#         policies=list(pvs),\n",
    "#         states=[states for _ in range(len(pvs))],\n",
    "#         infos=list([[{'task_id': i} for _ in range(len(states))] for i in experts.keys()]),\n",
    "#     ),\n",
    "#     save_path,\n",
    "#     'pkl',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTNMF (Fourroom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dim = 5\n",
    "scale=2\n",
    "n_objs = 4\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "def get_img(env, abs_list):\n",
    "    size = (env.unwrapped.row, env.unwrapped.col)\n",
    "    indices = np.zeros(size, dtype=np.int64)\n",
    "    k = 0\n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            if (i, j) in env.unwrapped.default_obj_pos[0]: # object position\n",
    "                indices[i, j] = 0\n",
    "            elif env.unwrapped.m[i][j] == '#':\n",
    "                indices[i, j] = 1\n",
    "            else:\n",
    "                indices[i, j] = visualization_map[str(2 + abs_list[k])]\n",
    "                k += 1\n",
    "\n",
    "    img = drawer.draw(indices)\n",
    "    return img\n",
    "\n",
    "def get_expert(weight_path, action_dim, feat_dim=512):\n",
    "    visual_body = TSAMiniMiniConvBody(\n",
    "        2 + n_objs, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale,\n",
    "        gate=F.softplus,\n",
    "    )\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        n_objs,\n",
    "        0, # state_dim\n",
    "        action_dim,\n",
    "        visual_body,\n",
    "    )\n",
    "    # load weight\n",
    "    #weight_dict = expert.state_dict()\n",
    "    #loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "    #    weight_path,\n",
    "    #    map_location=lambda storage, loc: storage)['network'].items()\n",
    "    #    if k in weight_dict}\n",
    "    #weight_dict.update(loaded_weight_dict)\n",
    "    #expert.load_state_dict(weight_dict)\n",
    "    expert.load_state_dict(torch.load(weight_path, map_location=lambda storage, loc: storage)['network'])\n",
    "    return expert\n",
    "\n",
    "def get_visualization_env():\n",
    "    with open('../data/env_configs/pick/fourroom/fourroom.3', 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    print(env_config)\n",
    "    env = ScaleObsEnv(\n",
    "        PickGridWorld(\n",
    "            **env_config,\n",
    "            min_dis=1,\n",
    "            window=1,\n",
    "            task_length=1,\n",
    "            seed=0,\n",
    "        ),\n",
    "        2,\n",
    "    )\n",
    "    env.reset(sample_obj_pos=False)\n",
    "    positions = env.unwrapped.pos_candidates\n",
    "    states = []\n",
    "    for pos in positions:\n",
    "        o, _, _, _ = env.teleport(*pos)\n",
    "        states.append(o)\n",
    "    print('states shape:', len(states))\n",
    "    return env, states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize for all states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "{'map_names': ['fourroom'], 'train_combos': [(0, 3)], 'test_combos': [(0, 3)], 'num_obj_types': 4, 'obj_pos': [[(1, 1), (9, 1), (1, 9), (9, 9)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'fourroom')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',))]\n",
      "train: [(0, 3)]\n",
      "test: [(0, 3)]\n",
      "states shape: 68\n",
      "(68, 5)\n",
      "(68, 5)\n",
      "(68, 5)\n",
      "NMF loss: 16.69140775941129\n",
      "NMF loss: 2.2600365846322408\n",
      "NMF loss: 2.2028002359008827\n",
      "NMF loss: 2.1205691250175107\n",
      "NMF loss: 2.0806840197212173\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALAAAACwCAYAAACvt+ReAAADNklEQVR4nO3csYqVVxSA0aukE0khATvFwqCQqXwBK5GxklGsgp1PELykSBnmBS5ipxY2DlMlWIpgaaWDkka0s7GwsI15h7sHfj6yVr/nnOH/ONXmnthsNt9XEHVy6QvAhIBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBk/bD9A/s7++P5m8/vTOaP/Pi2mh+6scz/4zmv375+Zhusp31vbOj+XNXrs/OX69H815g0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmLTxPvCn18+P4x5b+231eNHzVwvvI0/tP/w8mp9+/wcHL0fzXmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYtPE+8P/d9PeBP+x8HM0v/fvINw6/jeZ3h+d7gUkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSxvvA033Qv26eml6BgVc/nV76CiNeYNIETJqASRMwaQImTcCkCZg0AZMmYNIETJqASRMwaQImTcCkCZi08T7w7r+vR/M3Dq8Mzz8/ml/a+6O90fylqwezCwzPX5oXmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZtvA/898nZPu/Uh52Pi55/4c350fx0n3o1PH+1M9snnv7/U15g0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmLTxPvCjm5dH83cP302vkDbdZ75/8Y/juciW7h7Nvt90H9oLTJqASRMwaQImTcCkCZg0AZMmYNIETJqASRMwaQImTcCkCZg0AZM23geu7/OO92kvHs892I4XmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZtvA/89s+90fwvvx+M5t8fzc6f7vM+O3gymr+19+vsAgubfv/d9Xo07wUmTcCkCZg0AZMmYNIETJqASRMwaQImTcCkCZg0AZMmYNIETJqASTux2Wy+L30J2JYXmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAibtP7tWUB8emWrcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=176x176 at 0x7F047C54F9E8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pdb on\n",
    "n_abs = 5\n",
    "l1_ratio = 0.0 # this is currently not working... since alpha is not set\n",
    "horizon = 100\n",
    "n_trajs = 10\n",
    "save_abs = False\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "expert_dict = {\n",
    "    0: '../log/pick.mask.fourroom.0.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172629/models/step-92160-mean-10.86',\n",
    "    1: '../log/pick.mask.fourroom.1.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172739/models/step-92160-mean-10.74',\n",
    "    2: '../log/pick.mask.fourroom.2.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172847/models/step-92160-mean-10.81',\n",
    "    #3: '../log/pick.mask.fourroom.3.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172956/models/step-92160-mean-10.87'\n",
    "}\n",
    "\n",
    "env, states = get_visualization_env()\n",
    "    \n",
    "decomposer = MTNMF(n_abs, max_iter=5000, tol=0.0001)\n",
    "\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    experts[goal_idx] = get_expert(weight_path, action_dim)\n",
    "\n",
    "pvs = []\n",
    "\n",
    "for goal_idx in expert_dict:\n",
    "    cur_infos = {'task_id': [goal_idx] * len(states)}\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, cur_infos), dim=-1).cpu().detach().numpy()\n",
    "    print(pv.shape)\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.stack(pvs, 0)\n",
    "A, S, info = MTNMF(n_abs, max_iter=5000, l1_ratio=l1_ratio).fit(pvs.transpose(0, 2, 1))\n",
    "\n",
    "abs_list = S.T.argmax(1)\n",
    "img = get_img(env, abs_list)\n",
    "imshow(img)\n",
    "\n",
    "if save_abs:\n",
    "    save_path = '../data/nmf_sample/pick/fourroom/split.full.{}'.format(n_abs)\n",
    "    print('save: {}'.format(save_path))\n",
    "    fsave(\n",
    "        dict(\n",
    "            abs=S.T,\n",
    "            policies=list(pvs),\n",
    "            states=[states for _ in range(len(pvs))],\n",
    "            infos=list([[{'task_id': i} for _ in range(len(states))] for i in experts.keys()]),\n",
    "        ),\n",
    "        save_path,\n",
    "        'pkl',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize distilled states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map_names': ['fourroom'], 'train_combos': [(0, 3)], 'test_combos': [(0, 3)], 'num_obj_types': 4, 'obj_pos': [[(1, 1), (9, 1), (1, 9), (9, 9)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'fourroom')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',))]\n",
      "train: [(0, 3)]\n",
      "test: [(0, 3)]\n",
      "states shape: 68\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALAAAACwCAYAAACvt+ReAAADkUlEQVR4nO3cz6vlcxzH8XM1ykhN+bHQTYaMsrFyU1OsrCaNBQtGs3EtDBtlMWfBCnU3VuOUxbWaMCkLmiwpapSbkmIyU9xJEskfYMr1P9y3uj3zeOxf934Xzz6rd2dttVrtLSDqhoP+AJgQMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSDk3/wNbW1mh/7duvpp8w8uva7aP9Jx+8O9qffGZztP/5+99G+6lnTz062i+Xy9HeC0yagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTNr4Hfu/9L0b7S0/eNdof/+iX0X5978/RfnrPO3XTU4+M9l/eMbsnfvnIaD7mBSZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJG98D75y5b7R/ePbzvAdu+vvAZ55+YrS/8/wbo/3i9Kuz/dDOcO8FJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkb3wOfWP/nv/iOfXvum60D/f8biwdG++n3by8eGu1v/PqH0X7s4vnR3AtMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkza+B/7s5Nuj/fHHT4/2G8N70oN29q3VaP/8Ky+N9n98OrtnfvPEbD/lBSZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJG98DT+95D91yZbTfOXZ5tJ/auDq7h53eU29cHc0XO8dm99SXLroHhn0TMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSxvfAv699Ptrf8/dj009Im94zb+8eGe1fuH7zaL84em00f2f37tHeC0yagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTNr4HfvHCudH+48310f62w4dH+6mfHtwd7bcvz+55/++8wKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBp43vg6+d+nP2Bzdn8r9fuH+1vff3KaH/vd0dH+7PDe+KD9uGpC6P9crkc7b3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGlrq9Vq76A/AvbLC0yagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGT9i+OuWAElFZCvAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=176x176 at 0x7F3620611F98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_abs = 50\n",
    "l1_ratio = 0.0\n",
    "\n",
    "weight_dict = {\n",
    "    20: '../log/pick.split.mix.10-20/nmf_sample.baseline.n_abs-20/20/0.190325-224016/models/step-720000-acc-10.71',\n",
    "    50: '../log/pick.split.mix.10-50/nmf_sample.baseline.n_abs-50/50/0.190325-230619/models/step-1200000-acc-10.76',\n",
    "    5: '../log/pick.split.mix.10-5/nmf_sample.baseline.n_abs-5/5/0.190325-230625/models/step-220800-acc-7.96',\n",
    "}\n",
    "\n",
    "env, states = get_visualization_env()\n",
    "decomposer = MTNMF(n_abs, max_iter=5000, tol=0.0001)\n",
    "expert = get_expert(weight_dict[n_abs], action_dim, feat_dim=n_abs)\n",
    "\n",
    "abs_s = expert.network.phi_body(tensor(states))\n",
    "abs_list = abs_s.argmax(1).detach().cpu().numpy()\n",
    "img = get_img(env, abs_list)\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate from sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "{'map_names': ['fourroom'], 'train_combos': [(0, 1)], 'test_combos': [(0, 1)], 'num_obj_types': 4, 'obj_pos': [[(1, 1), (9, 1), (1, 9), (9, 9)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'fourroom')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',))]\n",
      "train: [(0, 1)]\n",
      "test: [(0, 1)]\n",
      "{'map_names': ['fourroom'], 'train_combos': [(0, 2)], 'test_combos': [(0, 2)], 'num_obj_types': 4, 'obj_pos': [[(1, 1), (9, 1), (1, 9), (9, 9)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'fourroom')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',))]\n",
      "train: [(0, 2)]\n",
      "test: [(0, 2)]\n",
      "{'map_names': ['fourroom'], 'train_combos': [(0, 3)], 'test_combos': [(0, 3)], 'num_obj_types': 4, 'obj_pos': [[(1, 1), (9, 1), (1, 9), (9, 9)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'fourroom')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',))]\n",
      "train: [(0, 3)]\n",
      "test: [(0, 3)]\n",
      "goal: 1, mean return: 10.83\n",
      "goal: 2, mean return: 10.788\n",
      "goal: 3, mean return: 10.852\n",
      "states shape: (1390, 6, 22, 22)\n",
      "(1390, 5)\n",
      "(1390, 5)\n",
      "(1390, 5)\n",
      "NMF loss: 403.0791689993032\n",
      "NMF loss: 0.9083178689316164\n",
      "NMF loss: 0.1833785277840069\n",
      "NMF loss: 0.08424294700908147\n",
      "NMF loss: 0.05707008591040772\n",
      "NMF loss: 0.043816133746081974\n",
      "(3, 1390, 5)\n",
      "save: ../data/nmf_sample/pick/fourroom/split.eps.10-50\n",
      "[[3.17076701e-03 1.21451934e-02 6.76322830e-03 ... 2.91484656e-03\n",
      "  2.91627201e-04 6.74416065e-03]\n",
      " [2.76161165e-03 3.74905709e-03 1.17925083e-02 ... 8.71576700e-03\n",
      "  6.29194110e-10 3.48401855e-04]\n",
      " [3.80832874e-03 5.80063261e-03 1.37451145e-02 ... 1.89567354e-02\n",
      "  9.24289715e-08 4.20442802e-04]\n",
      " ...\n",
      " [1.07971043e-03 1.56822360e-03 2.44832979e-02 ... 1.89230209e-02\n",
      "  1.35653148e-04 1.23879293e-02]\n",
      " [8.17931044e-04 2.81270236e-03 5.07261848e-02 ... 1.00906067e-03\n",
      "  3.33825365e-16 5.74738404e-03]\n",
      " [1.46102419e-03 3.15276841e-02 1.29689834e-02 ... 2.63907911e-04\n",
      "  2.46954015e-08 1.36652164e-03]]\n",
      "1.9302870129908417e-148 0.20257465767263735 0.007834264667362758\n"
     ]
    }
   ],
   "source": [
    "%pdb on\n",
    "n_abs = 50\n",
    "l1_ratio = 0.0 # this is currently not working... since alpha is not set\n",
    "feat_dim = 512\n",
    "action_dim = 5\n",
    "horizon = 100\n",
    "n_trajs = 10 # 30\n",
    "scale=2\n",
    "n_objs = 4\n",
    "\n",
    "def get_expert(weight_path, action_dim):\n",
    "    visual_body = TSAMiniMiniConvBody(\n",
    "        2 + n_objs, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale,\n",
    "        gate=F.softplus,\n",
    "    )\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        n_objs,\n",
    "        0, # state_dim\n",
    "        action_dim,\n",
    "        visual_body,\n",
    "    )\n",
    "    # load weight\n",
    "    weight_dict = expert.state_dict()\n",
    "    loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "        weight_path,\n",
    "        map_location=lambda storage, loc: storage)['network'].items()\n",
    "        if k in weight_dict}\n",
    "    weight_dict.update(loaded_weight_dict)\n",
    "    expert.load_state_dict(weight_dict)\n",
    "    return expert\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "expert_dict = {\n",
    "    #0: '../log/pick.mask.fourroom.0.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172629/models/step-92160-mean-10.86',\n",
    "    1: '../log/pick.mask.fourroom.1.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172739/models/step-92160-mean-10.74',\n",
    "    2: '../log/pick.mask.fourroom.2.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172847/models/step-92160-mean-10.81',\n",
    "    3: '../log/pick.mask.fourroom.3.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172956/models/step-92160-mean-10.87'\n",
    "}\n",
    "\n",
    "envs = dict()\n",
    "for i in range(1, 4):\n",
    "    with open('../data/env_configs/pick/fourroom/fourroom.{}'.format(i), 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    print(env_config)\n",
    "    envs[i] = ScaleObsEnv(\n",
    "        PickGridWorld(\n",
    "            **env_config,\n",
    "            min_dis=1,\n",
    "            window=1,\n",
    "            task_length=1,\n",
    "            seed=0,\n",
    "        ),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "states = []\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    returns = []\n",
    "    experts[goal_idx] = get_expert(weight_path, action_dim)\n",
    "#     for _ in range(n_trajs):\n",
    "#         rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, experts[goal_idx], horizon=horizon)\n",
    "#         states.append(rollout_states)\n",
    "#         returns.append(rollout_returns)\n",
    "    for _ in range(n_trajs // 2):\n",
    "        rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, experts[goal_idx], horizon=horizon)\n",
    "        states.append(rollout_states)\n",
    "        returns.append(rollout_returns)\n",
    "    for _ in range(n_trajs - (n_trajs // 2)):\n",
    "        rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, None, horizon=horizon)\n",
    "        states.append(rollout_states)\n",
    "    if returns: print('goal: {}, mean return: {}'.format(goal_idx, np.mean(returns)))\n",
    "states = np.concatenate(states)\n",
    "print('states shape:', states.shape)\n",
    "\n",
    "pvs = []\n",
    "\n",
    "for goal_idx in expert_dict:\n",
    "    cur_infos = {'task_id': [goal_idx] * len(states)}\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, cur_infos), dim=-1).cpu().detach().numpy()\n",
    "    print(pv.shape)\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.stack(pvs, 0)\n",
    "A, S, info = MTNMF(n_abs, max_iter=5000, l1_ratio=l1_ratio).fit(pvs.transpose(0, 2, 1))\n",
    "print(pvs.shape)\n",
    "save_path = '../data/nmf_sample/pick/fourroom/split.eps.{}-{}'.format(n_trajs, n_abs)\n",
    "print('save: {}'.format(save_path))\n",
    "\n",
    "print(S.T)\n",
    "print(S.min(), S.max(), S.mean())\n",
    "\n",
    "# fsave(\n",
    "#     dict(\n",
    "#         abs=S.T,\n",
    "#         policies=list(pvs),\n",
    "#         states=[states for _ in range(len(pvs))],\n",
    "#         infos=list([[{'task_id': i} for _ in range(len(states))] for i in experts.keys()]),\n",
    "#     ),\n",
    "#     save_path,\n",
    "#     'pkl',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTNMF (16x16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 1)], 'test_combos': [(0, 0)], 'num_obj_types': 5, 'obj_pos': [[(13, 6), (4, 13), (12, 2), (7, 4), (10, 14)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',))]\n",
      "train: [(0, 1)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 2)], 'test_combos': [(0, 0)], 'num_obj_types': 5, 'obj_pos': [[(13, 6), (4, 13), (12, 2), (7, 4), (10, 14)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',))]\n",
      "train: [(0, 2)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 3)], 'test_combos': [(0, 0)], 'num_obj_types': 5, 'obj_pos': [[(13, 6), (4, 13), (12, 2), (7, 4), (10, 14)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',))]\n",
      "train: [(0, 3)]\n",
      "test: [(0, 0)]\n",
      "goal: 1, mean return: 10.825\n",
      "goal: 2, mean return: 10.729\n",
      "goal: 3, mean return: 10.750499999999999\n",
      "states shape: (1386, 7, 32, 32)\n",
      "(1386, 5)\n",
      "(1386, 5)\n",
      "(1386, 5)\n",
      "NMF loss: 1104.8571246345532\n",
      "NMF loss: 23.12595219799843\n",
      "NMF loss: 22.184904303321844\n",
      "NMF loss: 21.32048805388361\n",
      "NMF loss: 19.76810116572497\n",
      "NMF loss: 16.648377347860286\n",
      "NMF loss: 7.78037957804346\n",
      "NMF loss: 7.5439797820258425\n",
      "NMF loss: 7.460257348741382\n",
      "NMF loss: 7.420814346402271\n",
      "NMF loss: 7.395461485713542\n",
      "NMF loss: 7.346009176010723\n",
      "NMF loss: 7.270553708720518\n",
      "NMF loss: 7.258510736870807\n",
      "(3, 1386, 5)\n"
     ]
    }
   ],
   "source": [
    "%pdb on\n",
    "n_abs = 20\n",
    "l1_ratio = 0.0 # this is currently not working... since alpha is not set\n",
    "feat_dim = 512\n",
    "action_dim = 5\n",
    "horizon = 100\n",
    "n_trajs = 20\n",
    "scale=2\n",
    "\n",
    "def get_expert(weight_path, action_dim):\n",
    "    visual_body = TSAMiniConvBody(\n",
    "        7, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale)\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        5,\n",
    "        0, # state_dim\n",
    "        action_dim,\n",
    "        visual_body,\n",
    "    )\n",
    "    # load weight\n",
    "    weight_dict = expert.state_dict()\n",
    "    loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "        weight_path,\n",
    "        map_location=lambda storage, loc: storage)['network'].items()\n",
    "        if k in weight_dict}\n",
    "    weight_dict.update(loaded_weight_dict)\n",
    "    expert.load_state_dict(weight_dict)\n",
    "    return expert\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "expert_dict = {\n",
    "    1: '../log/pick.mask.map49.5-1.min_dis-1/tsa.baseline.n_abs-512/_/0.190323-000115/models/step-1945600-mean-10.81',\n",
    "    2: '../log/pick.mask.map49.5-2.min_dis-1/tsa.baseline.n_abs-512/_/0.190323-002744/models/step-1945600-mean-10.72',\n",
    "    3: '../log/pick.mask.map49.5-3.min_dis-1/tsa.baseline.n_abs-512/_/0.190323-005347/models/step-1945600-mean-10.78',\n",
    "}\n",
    "\n",
    "envs = dict()\n",
    "for i in range(1, 4):\n",
    "    with open('../data/env_configs/pick/nmf/map49.5-{}'.format(i), 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    print(env_config)\n",
    "    envs[i] = ScaleObsEnv(\n",
    "        PickGridWorld(\n",
    "            **env_config,\n",
    "            min_dis=1,\n",
    "            window=1,\n",
    "            task_length=1,\n",
    "            seed=0,\n",
    "        ),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "decomposer = MTNMF(n_abs, max_iter=5000, tol=0.0001)\n",
    "\n",
    "states = []\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    returns = []\n",
    "    experts[goal_idx] = get_expert(weight_path, action_dim)\n",
    "    for _ in range(n_trajs):\n",
    "        rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, experts[goal_idx], horizon=horizon)\n",
    "        states.append(rollout_states)\n",
    "        returns.append(rollout_returns)\n",
    "    #for _ in range(n_trajs // 2):\n",
    "    #    states.append(rollout(envs[goal_idx], experts[goal_idx], horizon=horizon))\n",
    "    #for _ in range(n_trajs - (n_trajs // 2)):\n",
    "    #    states.append(rollout(envs[goal_idx-1], None, horizon=horizon))\n",
    "    print('goal: {}, mean return: {}'.format(goal_idx, np.mean(returns)))\n",
    "states = np.concatenate(states)\n",
    "print('states shape:', states.shape)\n",
    "\n",
    "pvs = []\n",
    "\n",
    "for goal_idx in expert_dict:\n",
    "    cur_infos = {'task_id': [goal_idx] * len(states)}\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, cur_infos), dim=-1).cpu().detach().numpy()\n",
    "    print(pv.shape)\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.stack(pvs, 0)\n",
    "A, S, info = MTNMF(n_abs, max_iter=5000, l1_ratio=l1_ratio).fit(pvs.transpose(0, 2, 1))\n",
    "print(pvs.shape)\n",
    "\n",
    "fsave(\n",
    "    dict(\n",
    "        abs=S.T,\n",
    "        policies=list(pvs),\n",
    "        states=[states for _ in range(len(pvs))],\n",
    "        infos=list([[{'task_id': i} for _ in range(len(states))] for i in experts.keys()]),\n",
    "    ),\n",
    "    '../data/nmf_sample/pick/split.{}'.format(n_abs),\n",
    "    'pkl',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def projection_simplex_sort(v, z=1):\n",
    "    n_features = v.shape[0]\n",
    "    u = torch.sort(v, descending=True)[0]\n",
    "    cssv = torch.cumsum(u, 0) - z \n",
    "    ind = torch.Tensor(np.arange(n_features) + 1)\n",
    "    cond = u - cssv / ind > 0 \n",
    "    rho = ind[cond][-1]\n",
    "    theta = cssv[cond][-1] / rho.float()\n",
    "    w = F.relu(v - theta)\n",
    "    return w\n",
    "\n",
    "def update_v(X, U, V): \n",
    "    K = U.shape[1]\n",
    "    Y = X - torch.matmul(U, V) + torch.ger(U[:, 0], V[0, :]) # Y_1\n",
    "    for k in range(K):\n",
    "        #Y = X - torch.matmul(U, V) + torch.ger(U[:, k], V[k, :])\n",
    "        V[k, :] = projection_simplex_sort(torch.matmul(Y.t(), U[:, k]) / torch.dot(U[:, k], U[:, k]))\n",
    "        if k < K-1:\n",
    "            Y = Y - torch.ger(U[:, k], V[k, :]) + torch.ger(U[:, k+1], V[k+1, :]) \n",
    "        #print(V, new_v)\n",
    "        \n",
    "# print(projection_simplex_sort(torch.Tensor([3, 3, 3])))\n",
    "\n",
    "def loss(X, U, V):\n",
    "    return F.mse_loss(torch.matmul(U, V), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: tensor(1.00000e-03 *\n",
      "       8.7897)\n",
      "after: tensor(1.00000e-03 *\n",
      "       2.3522)\n",
      "after: tensor(1.00000e-04 *\n",
      "       9.1203)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "U = torch.rand(5, 3)\n",
    "U /= U.sum(1, keepdim=True)\n",
    "V_gt = torch.rand(3, 4)\n",
    "V_gt /= V_gt.sum(1, keepdim=True)\n",
    "X = torch.matmul(U, V_gt)\n",
    "V = torch.rand(3, 4)\n",
    "V /= V.sum(1, keepdim=True)\n",
    "print('original:', loss(X, U, V))\n",
    "update_v(X, U, V)\n",
    "print('after:', loss(X, U, V))\n",
    "update_v(X, U, V)\n",
    "print('after:', loss(X, U, V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7423,  0.5263,  0.2437,  0.5846],\n",
      "        [ 0.0332,  0.1387,  0.2422,  0.8155],\n",
      "        [ 0.7932,  0.2783,  0.4820,  0.8198]])\n",
      "tensor([ 0.9971,  0.6984,  0.5675,  0.8352])\n",
      "tensor([[ 0.7423,  0.5263,  0.2437,  0.5846],\n",
      "        [ 0.9971,  0.6984,  0.5675,  0.8352],\n",
      "        [ 0.7932,  0.2783,  0.4820,  0.8198]])\n",
      "tensor([[ 0.7423,  0.5263,  0.2437,  0.5846],\n",
      "        [ 0.9971,  0.6984,  0.5675,  0.8352],\n",
      "        [ 0.7932,  0.2783,  0.4820,  0.8198]])\n",
      "tensor([ 2.0000,  0.6984,  0.5675,  0.8352])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3, 4)\n",
    "b = torch.rand(4)\n",
    "print(a)\n",
    "print(b)\n",
    "a[1, :] = b\n",
    "print(a)\n",
    "b[0] = 2.0\n",
    "print(a)\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
