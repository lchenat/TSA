{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from deep_rl.gridworld import ReachGridWorld, PickGridWorld, PORGBEnv, GoalManager, ScaleObsEnv\n",
    "from deep_rl.network import *\n",
    "from deep_rl.utils import *\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import dill\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from collections import Counter, namedtuple\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "def set_seed(s):\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "    torch.manual_seed(s)\n",
    "\n",
    "set_seed(0) # set seed \n",
    "\n",
    "class GridDrawer:                           \n",
    "    def __init__(self, color_list):\n",
    "        self.color_list = np.asarray(color_list)\n",
    "\n",
    "    # input: a 2-d index matrix\n",
    "    # output: a 2-d rgb matrix\n",
    "    def draw(self, indices, repeat=16):\n",
    "        return np.uint8(255 * np.array(self.color_list[indices, :]).repeat(repeat, 0).repeat(repeat, 1))\n",
    "    \n",
    "# this is my color list\n",
    "color_map = dict([\n",
    "    #*[('grey-{}'.format(v), plt.cm.Greys(0.1 * v)) for v in range(1, 20)],\n",
    "    *[('purple-{}'.format(v), plt.cm.Purples(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('blue-{}'.format(v), plt.cm.Blues(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('green-{}'.format(v), plt.cm.Greens(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('orange-{}'.format(v), plt.cm.Oranges(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('red-{}'.format(v), plt.cm.Reds(0.05 * v)) for v in range(1, 20)],\n",
    "])\n",
    "\n",
    "color_list = list(color_map.values())\n",
    "shuffle(color_list)\n",
    "color_list = [plt.cm.Greys(0.9)] + [plt.cm.Greys(0.5)] + color_list\n",
    "drawer = GridDrawer(color_list)\n",
    "\n",
    "visualization_map = dict([\n",
    "    ('G', 0), # goal\n",
    "    ('#', 1),\n",
    "    *[(str(i), i + 2) for i in range(0, 100)],\n",
    "])\n",
    "\n",
    "def imshow(img):\n",
    "    display(Image.fromarray(np.asarray(img).astype(np.uint8)))\n",
    "\n",
    "def fload(fn, ftype):\n",
    "    if ftype == 'json':\n",
    "        with open(fn) as f:\n",
    "            return json.load(f)\n",
    "    elif ftype == 'pkl':\n",
    "        with open(fn, 'rb') as f:\n",
    "            return dill.load(f)\n",
    "    elif ftype == 'png':\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        raise Exception('cannot read this data type: {}'.format(ftype))\n",
    "    \n",
    "def fsave(data, fn, ftype):\n",
    "    dirname = os.path.dirname(fn)\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    if ftype == 'json':\n",
    "        with open(fn, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "    elif ftype == 'pkl':\n",
    "        with open(fn, 'wb') as f:\n",
    "            dill.dump(data, f)    \n",
    "    elif ftype == 'png':\n",
    "        Image.fromarray(data).save(fn)\n",
    "    else:\n",
    "        raise Exception('unsupported file type: {}'.format(ftype))\n",
    "        \n",
    "GoalConfig = namedtuple('GoalConfig', ['map_name', 'n_goal', 'min_dis'])  \n",
    "\n",
    "# multitask NMF from: https://ieeexplore.ieee.org/document/6939673\n",
    "class MTNMF:\n",
    "    def __init__(self, n_components, l1_ratio=0.0, max_iter=200, tol=0.0001):\n",
    "        self.n_components = n_components\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "\n",
    "    def loss(self, X, A, S):\n",
    "        return 0.5 * ((X - np.matmul(A, S)) ** 2).sum() + self.l1_ratio * S.sum()\n",
    "        \n",
    "    # input: a stack of observed data X_1, ..., X_K\n",
    "    # output: S, A_1, ..., A_K\n",
    "    def fit(self, X):\n",
    "        K, N, M = X.shape\n",
    "        A = np.random.rand(K, N, self.n_components)\n",
    "        S = np.random.rand(self.n_components, M)\n",
    "        prev_loss = np.inf\n",
    "        cur_loss = None\n",
    "        for i in range(self.max_iter):\n",
    "            A_T = A.transpose(0, 2, 1)\n",
    "            new_S = S * (np.matmul(A_T, X).sum(0)) / (np.matmul(np.matmul(A_T, A), S).sum(0) + K * self.l1_ratio * np.ones((self.n_components, M)))\n",
    "            S = new_S\n",
    "            new_A = A * np.matmul(X, S.T) / np.matmul(np.matmul(A, S), S.T)\n",
    "            A = new_A\n",
    "            cur_loss = self.loss(X, A, S)\n",
    "            if i % 100 == 0: print('NMF loss:', cur_loss)\n",
    "            if abs(cur_loss - prev_loss) < self.tol: break\n",
    "            prev_loss = cur_loss # update loss\n",
    "        return A, S, {'loss': cur_loss, 'iter': i}\n",
    "    \n",
    "def rollout(env, idx, policy=None, horizon=100, epsilon=0.1):\n",
    "    states = []\n",
    "    returns = 0.0\n",
    "    done = False\n",
    "    #normalizer = ImageNormalizer()\n",
    "    state = env.reset(sample_obj_pos=False) # very important!\n",
    "    info = dict(task_id=[idx])\n",
    "    for _ in range(horizon):\n",
    "        states.append(state)\n",
    "        if policy is None:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = policy([state], info)['a'][0].cpu().detach().numpy()\n",
    "        state, r, done, _ = env.step(action) # note that info is not used\n",
    "        returns += r\n",
    "        if done: break\n",
    "    return states, returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTNMF (Nineroom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 0)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 0)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 1)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 1)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 2)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 2)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 3)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 3)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 4)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 4)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 5)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 5)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 6)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 6)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 7)], 'test_combos': [(0, 0)], 'num_obj_types': 9, 'obj_pos': [[(14, 1), (9, 9), (3, 13), (9, 1), (1, 9), (4, 2), (12, 9), (13, 12), (6, 13)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',))]\n",
      "train: [(0, 7)]\n",
      "test: [(0, 0)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'gate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-733e10e424f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgoal_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexpert_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mreturns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mexperts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgoal_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_expert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;31m#     for _ in range(n_trajs):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m#         rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, experts[goal_idx], horizon=horizon)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-733e10e424f3>\u001b[0m in \u001b[0;36mget_expert\u001b[0;34m(weight_path, action_dim)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mfeature_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeat_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mgate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftplus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m     expert = CategoricalActorCriticNet(\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'gate'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-67-733e10e424f3>\u001b[0m(17)\u001b[0;36mget_expert\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     15 \u001b[0;31m        \u001b[0mfeature_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeat_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m        \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 17 \u001b[0;31m        \u001b[0mgate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftplus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m    )\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m    expert = CategoricalActorCriticNet(\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%pdb on\n",
    "n_abs = 20\n",
    "l1_ratio = 0.0 # this is currently not working... since alpha is not set\n",
    "feat_dim = 512\n",
    "action_dim = 5\n",
    "horizon = 100\n",
    "n_trajs = 10 #30\n",
    "scale = 2\n",
    "n_objs = 9\n",
    "epsilon = 0.0\n",
    "\n",
    "def get_expert(weight_path, action_dim):\n",
    "    visual_body = TSAMiniConvBody(\n",
    "        2 + n_objs, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale,\n",
    "        gate=F.softplus,\n",
    "    )\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        n_objs,\n",
    "        0, # state_dim\n",
    "        action_dim,\n",
    "        visual_body,\n",
    "    )\n",
    "    # load weight\n",
    "    weight_dict = expert.state_dict()\n",
    "    loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "        weight_path,\n",
    "        map_location=lambda storage, loc: storage)['network'].items()\n",
    "        if k in weight_dict}\n",
    "    weight_dict.update(loaded_weight_dict)\n",
    "    expert.load_state_dict(weight_dict)\n",
    "    return expert\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "expert_dict = {\n",
    "    0: '../log/pick.mask.nineroom.0.min_dis-1/tsa.baseline.n_abs-512/_/0.190327-232308/models/step-491520-mean-10.70',\n",
    "    1: '../log/pick.mask.nineroom.1.min_dis-1/tsa.baseline.n_abs-512/_/1.190327-235057/models/step-491520-mean-10.84',\n",
    "    2: '../log/pick.mask.nineroom.2.min_dis-1/tsa.baseline.n_abs-512/_/1.190328-000958/models/step-491520-mean-10.86',\n",
    "    3: '../log/pick.mask.nineroom.3.min_dis-1/tsa.baseline.n_abs-512/_/2.190328-003751/models/step-491520-mean-10.71',\n",
    "    4: '../log/pick.mask.nineroom.4.min_dis-1/tsa.baseline.n_abs-512/_/0.190328-005600/models/step-491520-mean-10.81',\n",
    "    5: '../log/pick.mask.nineroom.5.min_dis-1/tsa.baseline.n_abs-512/_/0.190328-011456/models/step-491520-mean-10.78',\n",
    "    6: '../log/pick.mask.nineroom.6.min_dis-1/tsa.baseline.n_abs-512/_/0.190328-014223/models/step-491520-mean-10.82',\n",
    "    7: '../log/pick.mask.nineroom.7.min_dis-1/tsa.baseline.n_abs-512/_/0.190328-020127/models/step-491520-mean-10.84',\n",
    "}\n",
    "\n",
    "envs = dict()\n",
    "for i in range(8):\n",
    "    with open('../data/env_configs/pick/nineroom/nineroom.{}'.format(i), 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    print(env_config)\n",
    "    envs[i] = ScaleObsEnv(\n",
    "        PickGridWorld(\n",
    "            **env_config,\n",
    "            min_dis=1,\n",
    "            window=1,\n",
    "            task_length=1,\n",
    "            seed=0,\n",
    "        ),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "decomposer = MTNMF(n_abs, max_iter=5000, tol=0.0001)\n",
    "\n",
    "states = []\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    returns = []\n",
    "    experts[goal_idx] = get_expert(weight_path, action_dim)\n",
    "#     for _ in range(n_trajs):\n",
    "#         rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, experts[goal_idx], horizon=horizon)\n",
    "#         states.append(rollout_states)\n",
    "#         returns.append(rollout_returns)\n",
    "    for _ in range(n_trajs // 2):\n",
    "        rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, \n",
    "                                                  experts[goal_idx], horizon=horizon, epsilon=epsilon)\n",
    "        states.append(rollout_states)\n",
    "        returns.append(rollout_returns)\n",
    "    for _ in range(n_trajs - (n_trajs // 2)):\n",
    "        rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, \n",
    "                                                  None, horizon=horizon, epsilon=epsilon)\n",
    "        states.append(rollout_states)\n",
    "    if returns: print('goal: {}, mean return: {}'.format(goal_idx, np.mean(returns)))\n",
    "states = np.concatenate(states)\n",
    "print('states shape:', states.shape)\n",
    "\n",
    "pvs = []\n",
    "\n",
    "for goal_idx in expert_dict:\n",
    "    cur_infos = {'task_id': [goal_idx] * len(states)}\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, cur_infos), dim=-1).cpu().detach().numpy()\n",
    "    print(pv.shape)\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.stack(pvs, 0)\n",
    "A, S, info = MTNMF(n_abs, max_iter=5000, l1_ratio=l1_ratio).fit(pvs.transpose(0, 2, 1))\n",
    "print(pvs.shape)\n",
    "save_path = '../data/nmf_sample/pick/nineroom/split.{}-{}'.format(n_trajs, n_abs)\n",
    "print('save: {}'.format(save_path))\n",
    "\n",
    "fsave(\n",
    "    dict(\n",
    "        abs=S.T,\n",
    "        policies=list(pvs),\n",
    "        states=[states for _ in range(len(pvs))],\n",
    "        infos=list([[{'task_id': i} for _ in range(len(states))] for i in experts.keys()]),\n",
    "    ),\n",
    "    save_path,\n",
    "    'pkl',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTNMF (Fourroom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dim = 512\n",
    "action_dim = 5\n",
    "scale=2\n",
    "n_objs = 4\n",
    "\n",
    "def get_img(env, abs_list):\n",
    "    size = (env.unwrapped.row, env.unwrapped.col)\n",
    "    indices = np.zeros(size, dtype=np.int64)\n",
    "    k = 0\n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            if (i, j) in env.unwrapped.default_obj_pos[0]: # object position\n",
    "                indices[i, j] = 0\n",
    "            elif env.unwrapped.m[i][j] == '#':\n",
    "                indices[i, j] = 1\n",
    "            else:\n",
    "                indices[i, j] = visualization_map[str(2 + abs_list[k])]\n",
    "                k += 1\n",
    "\n",
    "    img = drawer.draw(indices)\n",
    "    return img\n",
    "\n",
    "def get_expert(weight_path, action_dim):\n",
    "    visual_body = TSAMiniMiniConvBody(\n",
    "        2 + n_objs, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale,\n",
    "        gate=F.softplus,\n",
    "    )\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        n_objs,\n",
    "        0, # state_dim\n",
    "        action_dim,\n",
    "        visual_body,\n",
    "    )\n",
    "    # load weight\n",
    "    weight_dict = expert.state_dict()\n",
    "    loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "        weight_path,\n",
    "        map_location=lambda storage, loc: storage)['network'].items()\n",
    "        if k in weight_dict}\n",
    "    weight_dict.update(loaded_weight_dict)\n",
    "    expert.load_state_dict(weight_dict)\n",
    "    return expert\n",
    "\n",
    "def get_visualization_env():\n",
    "    with open('../data/env_configs/pick/fourroom/fourroom.3', 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    print(env_config)\n",
    "    env = ScaleObsEnv(\n",
    "        PickGridWorld(\n",
    "            **env_config,\n",
    "            min_dis=1,\n",
    "            window=1,\n",
    "            task_length=1,\n",
    "            seed=0,\n",
    "        ),\n",
    "        2,\n",
    "    )\n",
    "    env.reset(sample_obj_pos=False)\n",
    "    positions = env.unwrapped.pos_candidates\n",
    "    states = []\n",
    "    for pos in positions:\n",
    "        o, _, _, _ = env.teleport(*pos)\n",
    "        states.append(o)\n",
    "    print('states shape:', len(states))\n",
    "    return env, states\n",
    "\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize for all states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "{'map_names': ['fourroom'], 'train_combos': [(0, 3)], 'test_combos': [(0, 3)], 'num_obj_types': 4, 'obj_pos': [[(1, 1), (9, 1), (1, 9), (9, 9)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'fourroom')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',))]\n",
      "train: [(0, 3)]\n",
      "test: [(0, 3)]\n",
      "states shape: 68\n",
      "(68, 5)\n",
      "(68, 5)\n",
      "(68, 5)\n",
      "NMF loss: 15.720289306437301\n",
      "NMF loss: 0.037323145914974445\n",
      "NMF loss: 0.01154928853479464\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALAAAACwCAYAAACvt+ReAAAD70lEQVR4nO3cvWvddRjG4RPfoFVwEAcHO/RlqF26iCIlUHTQDoJEayMoFnWQQlO00oNIhuIQh0gRslmTSZtgl0ZqQQpRQ3xrRIjQloqliwpBURBBBev/4D2EG69rv3N+w4fv9JCRmZmZ6wModcNGfwAkBEw1AVNNwFQTMNUETDUBU03AVBMw1QRMNQFTTcBUEzDVBEw1AVPtpvQPTE1NRftr33wW7fd8eDTaz++bi/Zn3jsZ7R8dfy7a/7hze7RPjd0yEu2Hw2G09wJTTcBUEzDVBEw1AVNNwFQTMNUETDUBU03AVBMw1QRMNQFTTcBUEzDV4nvgqxNbov0/s09G++WD89F+z9lno/38+Fy0P3Dyy2h/6uJ30X5h9NZof3r9rmj/VbT2AlNOwFQTMNUETDUBU03AVBMw1QRMNQFTTcBUEzDVBEw1AVNNwFQTMNXie+ArH61E+/XXvo/2TxzL/r/wYDAWrc/8lv1/4KVflqP9W6N7o/3qsQvR/s+rP0f72weXo70XmGoCppqAqSZgqgmYagKmmoCpJmCqCZhqAqaagKkmYKoJmGoCppqAqRbfAz//0MfR/u3Xt2YfcPdCNH9kf/b9gys7s31o4vAw2q+Nbss+INyvfOAemP8xAVNNwFQTMNUETDUBU03AVBMw1QRMNQFTTcBUEzDVBEw1AVNNwFSL74Gf2rwW7XccX4z2kxeuRfuNvue9dPTlaD+9OhftJ6L1xvMCU03AVBMw1QRMNQFTTcBUEzDVBEw1AVNNwFQTMNUETDUBU03AVBMw1eJ74NED90X7w0ubov0fO85F+9S94T3xJ6e+yH5/kP3+pkO7o/35I9k9c8oLTDUBU03AVBMw1QRMNQFTTcBUEzDVBEw1AVNNwFQTMNUETDUBU03AVIvvgW++f3+0f/HzhWg/vRrNB8NDZ6P9+SPZPe6DJ6aj/fZXxqP9yInHo/3m2Zei/eLeN6O9F5hqAqaagKkmYKoJmGoCppqAqSZgqgmYagKmmoCpJmCqCZhqAqaagKkW3wP/Hd7zbrnxnmj/7rnlaH/HO2PR/o2LP0T7ZyZPR/tff/8r2i8Ost+fGv862u/6aSnae4GpJmCqCZhqAqaagKkmYKoJmGoCppqAqSZgqgmYagKmmoCpJmCqCZhq8T3wvt2PRftv1y5H+/XJlWh/5/EHov3WbS9E+/cvHYz2qadvm432n776cLTfNRxGey8w1QRMNQFTTcBUEzDVBEw1AVNNwFQTMNUETDUBU03AVBMw1QRMNQFTbWRmZub6Rn8E/FdeYKoJmGoCppqAqSZgqgmYagKmmoCpJmCqCZhqAqaagKkmYKoJmGoCptq/l8B++a4u+WsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=176x176 at 0x7F9B2057A080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pdb on\n",
    "n_abs = 50\n",
    "l1_ratio = 0.0 # this is currently not working... since alpha is not set\n",
    "horizon = 100\n",
    "n_trajs = 10\n",
    "\n",
    "\n",
    "expert_dict = {\n",
    "    0: '../log/pick.mask.fourroom.0.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172629/models/step-92160-mean-10.86',\n",
    "    1: '../log/pick.mask.fourroom.1.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172739/models/step-92160-mean-10.74',\n",
    "    2: '../log/pick.mask.fourroom.2.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172847/models/step-92160-mean-10.81',\n",
    "    #3: '../log/pick.mask.fourroom.3.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172956/models/step-92160-mean-10.87'\n",
    "}\n",
    "\n",
    "env, states = get_visualization_env()\n",
    "    \n",
    "decomposer = MTNMF(n_abs, max_iter=5000, tol=0.0001)\n",
    "\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    experts[goal_idx] = get_expert(weight_path, action_dim)\n",
    "\n",
    "pvs = []\n",
    "\n",
    "for goal_idx in expert_dict:\n",
    "    cur_infos = {'task_id': [goal_idx] * len(states)}\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, cur_infos), dim=-1).cpu().detach().numpy()\n",
    "    print(pv.shape)\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.stack(pvs, 0)\n",
    "A, S, info = MTNMF(n_abs, max_iter=5000, l1_ratio=l1_ratio).fit(pvs.transpose(0, 2, 1))\n",
    "\n",
    "abs_list = S.T.argmax(1)\n",
    "img = get_img(env, abs_list)\n",
    "imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize distilled states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_abs = 5\n",
    "l1_ratio = 0.0\n",
    "weight_path = \n",
    "\n",
    "env, states = get_visualization_env()\n",
    "decomposer = MTNMF(n_abs, max_iter=5000, tol=0.0001)\n",
    "expert = get_expert(weight_path, action_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate from sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "{'map_names': ['fourroom'], 'train_combos': [(0, 1)], 'test_combos': [(0, 1)], 'num_obj_types': 4, 'obj_pos': [[(1, 1), (9, 1), (1, 9), (9, 9)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'fourroom')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',))]\n",
      "train: [(0, 1)]\n",
      "test: [(0, 1)]\n",
      "{'map_names': ['fourroom'], 'train_combos': [(0, 2)], 'test_combos': [(0, 2)], 'num_obj_types': 4, 'obj_pos': [[(1, 1), (9, 1), (1, 9), (9, 9)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'fourroom')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',))]\n",
      "train: [(0, 2)]\n",
      "test: [(0, 2)]\n",
      "{'map_names': ['fourroom'], 'train_combos': [(0, 3)], 'test_combos': [(0, 3)], 'num_obj_types': 4, 'obj_pos': [[(1, 1), (9, 1), (1, 9), (9, 9)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'fourroom')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',))]\n",
      "train: [(0, 3)]\n",
      "test: [(0, 3)]\n",
      "goal: 1, mean return: 10.68266666666667\n",
      "goal: 2, mean return: 10.796666666666665\n",
      "goal: 3, mean return: 10.896666666666667\n",
      "states shape: (3930, 6, 22, 22)\n",
      "(3930, 5)\n",
      "(3930, 5)\n",
      "(3930, 5)\n",
      "NMF loss: 1204.1149236876327\n",
      "NMF loss: 8.899675812067995\n",
      "NMF loss: 4.356590777221556\n",
      "NMF loss: 3.8003116099536225\n",
      "NMF loss: 3.5401902022372767\n",
      "NMF loss: 3.4175925273741123\n",
      "NMF loss: 3.345700220473506\n",
      "NMF loss: 3.292986837398205\n",
      "NMF loss: 3.253268852396235\n",
      "NMF loss: 3.2195423701747816\n",
      "NMF loss: 3.189108853453026\n",
      "NMF loss: 3.1605639964023187\n",
      "NMF loss: 3.132986819282721\n",
      "NMF loss: 3.1055898946287646\n",
      "NMF loss: 3.0776077395836823\n",
      "NMF loss: 3.0483028592470998\n",
      "NMF loss: 3.017166182473457\n",
      "NMF loss: 2.983562470912219\n",
      "NMF loss: 2.9460599528932008\n",
      "NMF loss: 2.9044784860986606\n",
      "NMF loss: 2.8580590882683596\n",
      "NMF loss: 2.8061361773887037\n",
      "NMF loss: 2.7485700890747355\n",
      "NMF loss: 2.68526383245376\n",
      "NMF loss: 2.615906496382611\n",
      "NMF loss: 2.5401509317956035\n",
      "NMF loss: 2.4576004816509807\n",
      "NMF loss: 2.3679533427118975\n",
      "NMF loss: 2.2699370474110396\n",
      "NMF loss: 2.1591367558942927\n",
      "NMF loss: 2.0209492774101565\n",
      "NMF loss: 1.8094222518014602\n",
      "NMF loss: 1.4258886927917778\n",
      "NMF loss: 1.002484164358725\n",
      "NMF loss: 0.8083768928230427\n",
      "NMF loss: 0.7159675931428884\n",
      "NMF loss: 0.6371884303138948\n",
      "NMF loss: 0.5900335590865721\n",
      "NMF loss: 0.5588911814928659\n",
      "NMF loss: 0.5335203314656015\n",
      "NMF loss: 0.513207961982059\n",
      "NMF loss: 0.49568800387263234\n",
      "NMF loss: 0.4799962919311342\n",
      "NMF loss: 0.46581148816796614\n",
      "NMF loss: 0.452576543082979\n",
      "NMF loss: 0.44012465236512965\n",
      "NMF loss: 0.4282119458879875\n",
      "NMF loss: 0.41667336320804943\n",
      "NMF loss: 0.40523862948456835\n",
      "NMF loss: 0.393782446037141\n",
      "(3, 3930, 5)\n",
      "save: ../data/nmf_sample/pick/fourroom/split.eps.30-20\n"
     ]
    }
   ],
   "source": [
    "%pdb on\n",
    "n_abs = 20\n",
    "l1_ratio = 0.0 # this is currently not working... since alpha is not set\n",
    "feat_dim = 512\n",
    "action_dim = 5\n",
    "horizon = 100\n",
    "n_trajs = 30 # 10\n",
    "scale=2\n",
    "n_objs = 4\n",
    "\n",
    "def get_expert(weight_path, action_dim):\n",
    "    visual_body = TSAMiniMiniConvBody(\n",
    "        2 + n_objs, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale,\n",
    "        gate=F.softplus,\n",
    "    )\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        n_objs,\n",
    "        0, # state_dim\n",
    "        action_dim,\n",
    "        visual_body,\n",
    "    )\n",
    "    # load weight\n",
    "    weight_dict = expert.state_dict()\n",
    "    loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "        weight_path,\n",
    "        map_location=lambda storage, loc: storage)['network'].items()\n",
    "        if k in weight_dict}\n",
    "    weight_dict.update(loaded_weight_dict)\n",
    "    expert.load_state_dict(weight_dict)\n",
    "    return expert\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "expert_dict = {\n",
    "    #0: '../log/pick.mask.fourroom.0.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172629/models/step-92160-mean-10.86',\n",
    "    1: '../log/pick.mask.fourroom.1.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172739/models/step-92160-mean-10.74',\n",
    "    2: '../log/pick.mask.fourroom.2.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172847/models/step-92160-mean-10.81',\n",
    "    3: '../log/pick.mask.fourroom.3.min_dis-1/tsa.baseline.n_abs-512/_/0.190325-172956/models/step-92160-mean-10.87'\n",
    "}\n",
    "\n",
    "envs = dict()\n",
    "for i in range(1, 4):\n",
    "    with open('../data/env_configs/pick/fourroom/fourroom.{}'.format(i), 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    print(env_config)\n",
    "    envs[i] = ScaleObsEnv(\n",
    "        PickGridWorld(\n",
    "            **env_config,\n",
    "            min_dis=1,\n",
    "            window=1,\n",
    "            task_length=1,\n",
    "            seed=0,\n",
    "        ),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "decomposer = MTNMF(n_abs, max_iter=5000, tol=0.0001)\n",
    "\n",
    "states = []\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    returns = []\n",
    "    experts[goal_idx] = get_expert(weight_path, action_dim)\n",
    "#     for _ in range(n_trajs):\n",
    "#         rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, experts[goal_idx], horizon=horizon)\n",
    "#         states.append(rollout_states)\n",
    "#         returns.append(rollout_returns)\n",
    "    for _ in range(n_trajs // 2):\n",
    "        rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, experts[goal_idx], horizon=horizon)\n",
    "        states.append(rollout_states)\n",
    "        returns.append(rollout_returns)\n",
    "    for _ in range(n_trajs - (n_trajs // 2)):\n",
    "        rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, None, horizon=horizon)\n",
    "        states.append(rollout_states)\n",
    "    if returns: print('goal: {}, mean return: {}'.format(goal_idx, np.mean(returns)))\n",
    "states = np.concatenate(states)\n",
    "print('states shape:', states.shape)\n",
    "\n",
    "pvs = []\n",
    "\n",
    "for goal_idx in expert_dict:\n",
    "    cur_infos = {'task_id': [goal_idx] * len(states)}\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, cur_infos), dim=-1).cpu().detach().numpy()\n",
    "    print(pv.shape)\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.stack(pvs, 0)\n",
    "A, S, info = MTNMF(n_abs, max_iter=5000, l1_ratio=l1_ratio).fit(pvs.transpose(0, 2, 1))\n",
    "print(pvs.shape)\n",
    "save_path = '../data/nmf_sample/pick/fourroom/split.eps.{}-{}'.format(n_trajs, n_abs)\n",
    "print('save: {}'.format(save_path))\n",
    "\n",
    "fsave(\n",
    "    dict(\n",
    "        abs=S.T,\n",
    "        policies=list(pvs),\n",
    "        states=[states for _ in range(len(pvs))],\n",
    "        infos=list([[{'task_id': i} for _ in range(len(states))] for i in experts.keys()]),\n",
    "    ),\n",
    "    save_path,\n",
    "    'pkl',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTNMF (16x16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 1)], 'test_combos': [(0, 0)], 'num_obj_types': 5, 'obj_pos': [[(13, 6), (4, 13), (12, 2), (7, 4), (10, 14)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',))]\n",
      "train: [(0, 1)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 2)], 'test_combos': [(0, 0)], 'num_obj_types': 5, 'obj_pos': [[(13, 6), (4, 13), (12, 2), (7, 4), (10, 14)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',))]\n",
      "train: [(0, 2)]\n",
      "test: [(0, 0)]\n",
      "{'map_names': ['map49'], 'train_combos': [(0, 3)], 'test_combos': [(0, 0)], 'num_obj_types': 5, 'obj_pos': [[(13, 6), (4, 13), (12, 2), (7, 4), (10, 14)]]}\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',))]\n",
      "train: [(0, 3)]\n",
      "test: [(0, 0)]\n",
      "goal: 1, mean return: 10.825\n",
      "goal: 2, mean return: 10.729\n",
      "goal: 3, mean return: 10.750499999999999\n",
      "states shape: (1386, 7, 32, 32)\n",
      "(1386, 5)\n",
      "(1386, 5)\n",
      "(1386, 5)\n",
      "NMF loss: 1104.8571246345532\n",
      "NMF loss: 23.12595219799843\n",
      "NMF loss: 22.184904303321844\n",
      "NMF loss: 21.32048805388361\n",
      "NMF loss: 19.76810116572497\n",
      "NMF loss: 16.648377347860286\n",
      "NMF loss: 7.78037957804346\n",
      "NMF loss: 7.5439797820258425\n",
      "NMF loss: 7.460257348741382\n",
      "NMF loss: 7.420814346402271\n",
      "NMF loss: 7.395461485713542\n",
      "NMF loss: 7.346009176010723\n",
      "NMF loss: 7.270553708720518\n",
      "NMF loss: 7.258510736870807\n",
      "(3, 1386, 5)\n"
     ]
    }
   ],
   "source": [
    "%pdb on\n",
    "n_abs = 20\n",
    "l1_ratio = 0.0 # this is currently not working... since alpha is not set\n",
    "feat_dim = 512\n",
    "action_dim = 5\n",
    "horizon = 100\n",
    "n_trajs = 20\n",
    "scale=2\n",
    "\n",
    "def get_expert(weight_path, action_dim):\n",
    "    visual_body = TSAMiniConvBody(\n",
    "        7, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale)\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        5,\n",
    "        0, # state_dim\n",
    "        action_dim,\n",
    "        visual_body,\n",
    "    )\n",
    "    # load weight\n",
    "    weight_dict = expert.state_dict()\n",
    "    loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "        weight_path,\n",
    "        map_location=lambda storage, loc: storage)['network'].items()\n",
    "        if k in weight_dict}\n",
    "    weight_dict.update(loaded_weight_dict)\n",
    "    expert.load_state_dict(weight_dict)\n",
    "    return expert\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "expert_dict = {\n",
    "    1: '../log/pick.mask.map49.5-1.min_dis-1/tsa.baseline.n_abs-512/_/0.190323-000115/models/step-1945600-mean-10.81',\n",
    "    2: '../log/pick.mask.map49.5-2.min_dis-1/tsa.baseline.n_abs-512/_/0.190323-002744/models/step-1945600-mean-10.72',\n",
    "    3: '../log/pick.mask.map49.5-3.min_dis-1/tsa.baseline.n_abs-512/_/0.190323-005347/models/step-1945600-mean-10.78',\n",
    "}\n",
    "\n",
    "envs = dict()\n",
    "for i in range(1, 4):\n",
    "    with open('../data/env_configs/pick/nmf/map49.5-{}'.format(i), 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    print(env_config)\n",
    "    envs[i] = ScaleObsEnv(\n",
    "        PickGridWorld(\n",
    "            **env_config,\n",
    "            min_dis=1,\n",
    "            window=1,\n",
    "            task_length=1,\n",
    "            seed=0,\n",
    "        ),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "decomposer = MTNMF(n_abs, max_iter=5000, tol=0.0001)\n",
    "\n",
    "states = []\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    returns = []\n",
    "    experts[goal_idx] = get_expert(weight_path, action_dim)\n",
    "    for _ in range(n_trajs):\n",
    "        rollout_states, rollout_returns = rollout(envs[goal_idx], goal_idx, experts[goal_idx], horizon=horizon)\n",
    "        states.append(rollout_states)\n",
    "        returns.append(rollout_returns)\n",
    "    #for _ in range(n_trajs // 2):\n",
    "    #    states.append(rollout(envs[goal_idx], experts[goal_idx], horizon=horizon))\n",
    "    #for _ in range(n_trajs - (n_trajs // 2)):\n",
    "    #    states.append(rollout(envs[goal_idx-1], None, horizon=horizon))\n",
    "    print('goal: {}, mean return: {}'.format(goal_idx, np.mean(returns)))\n",
    "states = np.concatenate(states)\n",
    "print('states shape:', states.shape)\n",
    "\n",
    "pvs = []\n",
    "\n",
    "for goal_idx in expert_dict:\n",
    "    cur_infos = {'task_id': [goal_idx] * len(states)}\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, cur_infos), dim=-1).cpu().detach().numpy()\n",
    "    print(pv.shape)\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.stack(pvs, 0)\n",
    "A, S, info = MTNMF(n_abs, max_iter=5000, l1_ratio=l1_ratio).fit(pvs.transpose(0, 2, 1))\n",
    "print(pvs.shape)\n",
    "\n",
    "fsave(\n",
    "    dict(\n",
    "        abs=S.T,\n",
    "        policies=list(pvs),\n",
    "        states=[states for _ in range(len(pvs))],\n",
    "        infos=list([[{'task_id': i} for _ in range(len(states))] for i in experts.keys()]),\n",
    "    ),\n",
    "    '../data/nmf_sample/pick/split.{}'.format(n_abs),\n",
    "    'pkl',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "for i in range(9):\n",
    "    base_dir = '../log/pick.mask.nineroom.{}.min_dis-1/tsa.baseline.n_abs-512'.format(i)\n",
    "    os.rename(Path(base_dir, '_'), Path(base_dir, 'relu'))\n",
    "    os.rename(Path(base_dir, '20'), Path(base_dir, '20_relu'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
