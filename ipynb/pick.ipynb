{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from deep_rl.gridworld import ReachGridWorld, PickGridWorld, PORGBEnv, GoalManager\n",
    "from deep_rl.network import *\n",
    "from deep_rl.utils import *\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import dill\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from collections import Counter, namedtuple\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "def seed(s):\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "\n",
    "seed(0) # set seed \n",
    "\n",
    "def fload(fn, ftype):\n",
    "    if ftype == 'json':\n",
    "        with open(fn) as f:\n",
    "            return json.load(f)\n",
    "    elif ftype == 'pkl':\n",
    "        with open(fn, 'rb') as f:\n",
    "            return dill.load(f)\n",
    "    elif ftype == 'png':\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        raise Exception('cannot read this data type: {}'.format(ftype))\n",
    "    \n",
    "def fsave(data, fn, ftype):\n",
    "    dirname = os.path.dirname(fn)\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    if ftype == 'json':\n",
    "        with open(fn, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "    elif ftype == 'pkl':\n",
    "        with open(fn, 'wb') as f:\n",
    "            dill.dump(data, f)    \n",
    "    elif ftype == 'png':\n",
    "        Image.fromarray(data).save(fn)\n",
    "    else:\n",
    "        raise Exception('unsupported file type: {}'.format(ftype))\n",
    "        \n",
    "GoalConfig = namedtuple('GoalConfig', ['map_name', 'n_goal', 'min_dis'])  \n",
    "\n",
    "# multitask NMF from: https://ieeexplore.ieee.org/document/6939673\n",
    "class MTNMF:\n",
    "    def __init__(self, n_components, l1_ratio=0.0, max_iter=200, tol=0.0001):\n",
    "        self.n_components = n_components\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "\n",
    "    def loss(self, X, A, S):\n",
    "        return 0.5 * ((X - np.matmul(A, S)) ** 2).sum() + self.l1_ratio * S.sum()\n",
    "        \n",
    "    # input: a stack of observed data X_1, ..., X_K\n",
    "    # output: S, A_1, ..., A_K\n",
    "    def fit(self, X):\n",
    "        K, N, M = X.shape\n",
    "        A = np.random.rand(K, N, self.n_components)\n",
    "        S = np.random.rand(self.n_components, M)\n",
    "        prev_loss = np.inf\n",
    "        cur_loss = None\n",
    "        for i in range(self.max_iter):\n",
    "            A_T = A.transpose(0, 2, 1)\n",
    "            new_S = S * (np.matmul(A_T, X).sum(0)) / (np.matmul(np.matmul(A_T, A), S).sum(0) + K * self.l1_ratio * np.ones((self.n_components, M)))\n",
    "            S = new_S\n",
    "            new_A = A * np.matmul(X, S.T) / np.matmul(np.matmul(A, S), S.T)\n",
    "            A = new_A\n",
    "            cur_loss = self.loss(X, A, S)\n",
    "            if i % 100 == 0: print('NMF loss:', cur_loss)\n",
    "            if abs(cur_loss - prev_loss) < self.tol: break\n",
    "            prev_loss = cur_loss # update loss\n",
    "        return A, S, {'loss': cur_loss, 'iter': i}\n",
    "    \n",
    "def rollout(env, policy=None, horizon=100):\n",
    "    states = []\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    info = dict(task_id=[0])\n",
    "    for _ in range(horizon):\n",
    "        states.append(state)\n",
    "        if policy is None:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = policy([state], info)['a'][0].cpu().detach().numpy()\n",
    "        state, _, _, _ = env.step(action) # note that info is not used\n",
    "    return states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_abs = 100\n",
    "l1_ratio = 0.0 # this is currently not working... since alpha is not set\n",
    "feat_dim = 512\n",
    "action_dim = 5\n",
    "horizon = 100\n",
    "n_trajs = 10\n",
    "scale=2\n",
    "\n",
    "def get_expert(weight_path, state_dim, action_dim):\n",
    "    visual_body = TSAMiniConvBody(\n",
    "        7, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale)\n",
    "    expert = CategoricalActorCriticNet(\n",
    "        2,\n",
    "        0, # state_dim\n",
    "        5,\n",
    "        visual_body,\n",
    "    )\n",
    "    # load weight\n",
    "    weight_dict = expert.state_dict()\n",
    "    loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "        weight_path,\n",
    "        map_location=lambda storage, loc: storage)['network'].items()\n",
    "        if k in weight_dict}\n",
    "    weight_dict.update(loaded_weight_dict)\n",
    "    expert.load_state_dict(weight_dict)\n",
    "    return expert\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "expert_dict = {\n",
    "    1: '../log/reacher.1_corner/fc_discrete.baseline/split/0.190315-202731/models/step-704000-mean--6.36',\n",
    "    2: '../log/reacher.2_corner/fc_discrete.baseline/split/0.190315-203310/models/step-704000-mean--17.16',\n",
    "    3: '../log/reacher.3_corner/fc_discrete.baseline/split/0.190315-203532/models/step-704000-mean--11.25',\n",
    "}\n",
    "\n",
    "envs = [DiscretizeActionEnv(\n",
    "    MultiGoalReacherEnv(\n",
    "        [\n",
    "            [0.15, 0.0],\n",
    "            [-0.15, 0.0],\n",
    "            [0.0, 0.15],\n",
    "            [0.0, -0.15],\n",
    "        ],\n",
    "        sample_indices=[i],\n",
    "        with_goal_pos=True,\n",
    "    ),\n",
    "    n_bins=[5, 5],\n",
    ") for i in range(3)]\n",
    "decomposer = MTNMF(n_abs, max_iter=5000, tol=0.0001)\n",
    "\n",
    "states = []\n",
    "experts = dict()\n",
    "\n",
    "for goal_idx, weight_path in expert_dict.items():\n",
    "    experts[goal_idx] = get_expert(weight_path, state_dim, action_dim)\n",
    "    for _ in range(n_trajs // 2):\n",
    "        states.append(rollout(envs[goal_idx-1], experts[goal_idx], horizon=horizon))\n",
    "    for _ in range(n_trajs - (n_trajs // 2)):\n",
    "        states.append(rollout(envs[goal_idx-1], None, horizon=horizon))\n",
    "states = np.concatenate(states)\n",
    "print('states shape:', states.shape)\n",
    "    \n",
    "pvs = []\n",
    "    \n",
    "for goal_idx in expert_dict:\n",
    "    infos = {'task_id': [goal_idx-1] * len(states)}\n",
    "    pv = F.softmax(experts[goal_idx].get_logits(states, infos), dim=-1).cpu().detach().numpy()\n",
    "    print(pv.shape)\n",
    "    pv = pv.reshape(pv.shape[0], -1)\n",
    "    pvs.append(pv)\n",
    "\n",
    "pvs = np.stack(pvs, 0)\n",
    "A, S, info = MTNMF(n_abs, max_iter=5000, l1_ratio=l1_ratio).fit(pvs.transpose(0, 2, 1))\n",
    "print(pvs.shape)\n",
    "\n",
    "fsave(\n",
    "    dict(\n",
    "        abs=S.T,\n",
    "        policies=list(pvs.reshape(pvs.shape[0], pvs.shape[1], 2, -1)),\n",
    "        states=[states for _ in range(len(pvs))],\n",
    "        infos=list([[{'task_id': i} for _ in range(len(states))] for i in range(3)]),\n",
    "    ),\n",
    "    '../data/nmf_sample/reacher/split.mix.{}'.format(n_abs),\n",
    "    'pkl',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate EnvConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map_names': ['map49'], 'train_combos': [(0, 1), (0, 2), (0, 3)], 'test_combos': [(0, 0)], 'num_obj_types': 5, 'obj_pos': [[(13, 6), (4, 13), (12, 2), (7, 4), (10, 14)]]}\n"
     ]
    }
   ],
   "source": [
    "seed(0) # set seed \n",
    "\n",
    "def get_pick_config(goal_config, train_combos=None):\n",
    "    MAX_OBJ_NUM = 15\n",
    "    goal_manager = GoalManager(goal_config.map_name)\n",
    "    obj_pos = goal_manager.gen_goals(MAX_OBJ_NUM + 1, min_dis=goal_config.min_dis)\n",
    "    obj_pos = [obj_pos[-1:] + obj_pos[:goal_config.n_goal-1]] # always the same test\n",
    "    if train_combos is None:\n",
    "        train_combos = [(0, i) for i in range(1, goal_config.n_goal)]\n",
    "    env_config = dict(\n",
    "        map_names = [goal_config.map_name],\n",
    "        train_combos = train_combos,\n",
    "        test_combos = [(0, 0)],\n",
    "        num_obj_types=goal_config.n_goal,\n",
    "        obj_pos=obj_pos,\n",
    "    )\n",
    "    return env_config \n",
    "\n",
    "map_name = 'map49'\n",
    "n_goal = 5\n",
    "train_idx = 4\n",
    "\n",
    "\n",
    "env_config = get_pick_config(\n",
    "    GoalConfig(\n",
    "        map_name=map_name,\n",
    "        n_goal=n_goal,\n",
    "        min_dis=4,\n",
    "    ),\n",
    "    #train_combos=[(0, train_idx)],\n",
    "    train_combos=[(0, 1), (0, 2), (0, 3)],\n",
    ")\n",
    "\n",
    "print(env_config)\n",
    "fsave(env_config, \n",
    "      #'../data/env_configs/pick/nmf/{}.{}-{}'.format(map_name, n_goal, train_idx), \n",
    "      '../data/env_configs/pick/nmf/{}.{}-f3'.format(map_name, n_goal),\n",
    "      ftype='pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
