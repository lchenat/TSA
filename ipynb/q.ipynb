{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from deep_rl.gridworld import ReachGridWorld, PickGridWorld, PORGBEnv, GoalManager, ScaleObsEnv\n",
    "from deep_rl.network import *\n",
    "from deep_rl.utils import *\n",
    "from train import _exp_parser, get_visual_body, get_network, get_env_config, PickGridWorldTask\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import dill\n",
    "import json\n",
    "import copy\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from collections import Counter, namedtuple\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import Tracer\n",
    "from tqdm import tqdm\n",
    "\n",
    "def set_seed(s):\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "    torch.manual_seed(s)\n",
    "\n",
    "set_seed(0) # set seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Fitted Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_objs = 4\n",
    "action_dim = 5\n",
    "feat_dim = 512\n",
    "scale = 2\n",
    "discount = 0.99\n",
    "\n",
    "def get_expert(weight_path):\n",
    "    visual_body = TSAMiniConvBody(\n",
    "        2 + n_objs, \n",
    "        feature_dim=feat_dim,\n",
    "        scale=scale,\n",
    "    )\n",
    "    expert = VanillaNet(action_dim, visual_body)\n",
    "    # load weight\n",
    "    weight_dict = expert.state_dict()\n",
    "    loaded_weight_dict = {k: v for k, v in torch.load(\n",
    "        weight_path,\n",
    "        map_location=lambda storage, loc: storage)['network'].items()\n",
    "        if k in weight_dict}\n",
    "    weight_dict.update(loaded_weight_dict)\n",
    "    expert.load_state_dict(weight_dict)\n",
    "    return expert\n",
    "\n",
    "def get_env(env_config):\n",
    "    states = []\n",
    "    positions = []\n",
    "    qs = []\n",
    "    reward_config = {'wall_penalty': -0.01, 'time_penalty': -0.01, 'complete_sub_task': 0.1, 'complete_all': 1, 'fail': -1}\n",
    "    with open(env_config, 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    env = ScaleObsEnv(\n",
    "        PickGridWorld(\n",
    "                **env_config,\n",
    "                min_dis=1,\n",
    "                window=1,\n",
    "                task_length=1,\n",
    "                reward_config=reward_config,\n",
    "                seed=0,\n",
    "        ),\n",
    "        2,\n",
    "    )\n",
    "    env.reset(sample_obj_pos=False)\n",
    "    positions = env.unwrapped.pos_candidates\n",
    "    for pos in positions:\n",
    "        o, _, _, _ = env.teleport(*pos)\n",
    "        states.append(o)\n",
    "        qs.append(env.get_q(discount))\n",
    "    return env, states, positions, qs\n",
    "\n",
    "def rollout(env, q, horizon=100, epsilon=0.0, feat_state=False):\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    next_states = []\n",
    "    terminals = []\n",
    "    qs = []\n",
    "    returns = 0.0\n",
    "    done = False\n",
    "    state = env.reset(sample_obj_pos=False) # very important!\n",
    "    for _ in range(horizon):\n",
    "        if feat_state:\n",
    "            states.append(q.body(tensor([state])).cpu().detach().numpy()[0])\n",
    "        else:\n",
    "            states.append(state)\n",
    "        qval = q([state]).cpu().detach().numpy().flatten()\n",
    "        qs.append(qval)\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = qval.argmax()\n",
    "        state, r, done, _ = env.step(action) # note that info is not used\n",
    "        actions.append(action)\n",
    "        if feat_state:\n",
    "            next_states.append(q.body(tensor([state])).cpu().detach().numpy()[0])\n",
    "        else:\n",
    "            next_states.append(state)\n",
    "        rewards.append(r)\n",
    "        terminals.append(done)\n",
    "        returns += r\n",
    "        if done: break\n",
    "    return states, actions, next_states, rewards, terminals, qs, returns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'fourroom-16')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',))]\n",
      "train: [(0, 0)]\n",
      "test: [(0, 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 2/20 [00:00<00:00, 18.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 4/20 [00:00<00:00, 17.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 6/20 [00:00<00:00, 16.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|████▌     | 9/20 [00:00<00:00, 17.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 11/20 [00:00<00:00, 18.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 14/20 [00:00<00:00, 19.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 16/20 [00:00<00:00, 18.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████ | 18/20 [00:00<00:00, 18.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 20/20 [00:01<00:00, 19.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/291 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|▏         | 4/291 [00:00<00:07, 36.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of transitions: 291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 8/291 [00:00<00:08, 35.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 12/291 [00:00<00:08, 34.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 16/291 [00:00<00:08, 33.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 20/291 [00:00<00:08, 33.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 24/291 [00:00<00:08, 32.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|▉         | 28/291 [00:00<00:08, 32.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 11%|█         | 32/291 [00:00<00:07, 32.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 36/291 [00:01<00:07, 32.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14%|█▎        | 40/291 [00:01<00:07, 32.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 44/291 [00:01<00:07, 32.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|█▋        | 48/291 [00:01<00:07, 32.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|█▊        | 52/291 [00:01<00:07, 31.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|█▉        | 56/291 [00:01<00:07, 31.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|██        | 60/291 [00:01<00:07, 31.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|██▏       | 64/291 [00:01<00:07, 31.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|██▎       | 68/291 [00:02<00:06, 32.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▍       | 72/291 [00:02<00:06, 33.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▌       | 76/291 [00:02<00:06, 34.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|██▋       | 80/291 [00:02<00:05, 35.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|██▉       | 84/291 [00:02<00:05, 35.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 88/291 [00:02<00:05, 36.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|███▏      | 92/291 [00:02<00:05, 36.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 96/291 [00:02<00:05, 36.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 34%|███▍      | 100/291 [00:02<00:05, 36.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 104/291 [00:03<00:05, 36.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 37%|███▋      | 108/291 [00:03<00:04, 36.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 112/291 [00:03<00:04, 36.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|███▉      | 116/291 [00:03<00:04, 37.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|████      | 120/291 [00:03<00:04, 36.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|████▎     | 124/291 [00:03<00:04, 36.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|████▍     | 128/291 [00:03<00:04, 36.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|████▌     | 132/291 [00:03<00:04, 36.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 47%|████▋     | 136/291 [00:03<00:04, 36.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 48%|████▊     | 140/291 [00:04<00:04, 36.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|████▉     | 144/291 [00:04<00:04, 36.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|█████     | 148/291 [00:04<00:03, 36.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|█████▏    | 152/291 [00:04<00:03, 36.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████▎    | 156/291 [00:04<00:03, 36.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▍    | 160/291 [00:04<00:03, 36.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████▋    | 164/291 [00:04<00:03, 36.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 58%|█████▊    | 168/291 [00:04<00:03, 36.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|█████▉    | 172/291 [00:04<00:03, 36.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 176/291 [00:05<00:03, 36.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████▏   | 180/291 [00:05<00:03, 36.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|██████▎   | 184/291 [00:05<00:02, 36.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▍   | 188/291 [00:05<00:02, 36.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████▌   | 192/291 [00:05<00:02, 36.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 196/291 [00:05<00:02, 36.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████▊   | 200/291 [00:05<00:02, 36.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 204/291 [00:05<00:02, 36.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████▏  | 208/291 [00:05<00:02, 36.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████▎  | 212/291 [00:06<00:02, 36.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 216/291 [00:06<00:02, 36.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 76%|███████▌  | 220/291 [00:06<00:01, 36.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 77%|███████▋  | 224/291 [00:06<00:01, 36.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 78%|███████▊  | 228/291 [00:06<00:01, 36.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|███████▉  | 232/291 [00:06<00:01, 36.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|████████  | 236/291 [00:06<00:01, 36.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|████████▏ | 240/291 [00:06<00:01, 36.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 244/291 [00:06<00:01, 36.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████▌ | 248/291 [00:07<00:01, 36.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████▋ | 252/291 [00:07<00:01, 36.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 256/291 [00:07<00:00, 36.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 89%|████████▉ | 260/291 [00:07<00:00, 34.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 91%|█████████ | 264/291 [00:07<00:00, 33.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|█████████▏| 268/291 [00:07<00:00, 33.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 93%|█████████▎| 272/291 [00:07<00:00, 34.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████▍| 276/291 [00:07<00:00, 34.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████▌| 280/291 [00:07<00:00, 35.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████▊| 284/291 [00:08<00:00, 35.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████▉| 288/291 [00:08<00:00, 36.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 291/291 [00:08<00:00, 35.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/liyuc/anaconda3/envs/tsa/lib/python3.6/site-packages/ipykernel_launcher.py:65: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04808895173094181\n",
      "difference between argmax: 113\n"
     ]
    }
   ],
   "source": [
    "%pdb on\n",
    "n_expert_trajs = 20\n",
    "epsilon = 0.0\n",
    "feat_state = False\n",
    "\n",
    "weight_path = '../log/pick.mask.fourroom-16.0.min_dis-1/dqn/double_q/0.190425-220424/models/step-3000000-mean-0.96'\n",
    "env_config_path = '../data/env_configs/pick/fourroom-16.0'\n",
    "\n",
    "expert = get_expert(weight_path)\n",
    "env, all_states, positions, optimal_q = get_env(env_config_path)\n",
    "\n",
    "states = []\n",
    "actions = []\n",
    "next_states = []\n",
    "rewards = []\n",
    "terminals = []\n",
    "qs = []\n",
    "\n",
    "for _ in tqdm(range(n_expert_trajs)):\n",
    "    states_, actions_, next_states_, rewards_, terminals_, qs_, returns = rollout(env, expert, epsilon=epsilon, feat_state=feat_state)\n",
    "    #print('expert returns:', returns)\n",
    "    states.append(states_)\n",
    "    actions.append(actions_)\n",
    "    next_states.append(next_states_)\n",
    "    rewards.append(rewards_)\n",
    "    terminals.append(terminals_)\n",
    "    qs.append(qs_)\n",
    "\n",
    "data = dict(\n",
    "    states=np.concatenate(states),\n",
    "    actions=np.concatenate(actions),\n",
    "    next_states=np.concatenate(next_states),\n",
    "    rewards=np.concatenate(rewards),\n",
    "    terminals=np.concatenate(terminals),\n",
    "    expert_q=np.concatenate(qs),\n",
    ")\n",
    "print('num of transitions:', len(data['states']))\n",
    "\n",
    "# input: experiences, feature extractor\n",
    "# output: linear layer\n",
    "def fitted_q(data, body, feat_dim, action_dim):\n",
    "    A = np.zeros((feat_dim * action_dim + action_dim, feat_dim * action_dim + action_dim))\n",
    "    b = np.zeros(feat_dim * action_dim + action_dim)\n",
    "    N = len(data['states'])\n",
    "\n",
    "    pbar = tqdm(total=N)\n",
    "    for i, transition in enumerate(zip(data['states'], data['actions'], data['next_states'], data['rewards'], data['terminals'])):\n",
    "        state, action, next_state, reward, terminal = transition\n",
    "        phi = np.zeros(feat_dim * action_dim + action_dim)\n",
    "        phi[feat_dim * action: feat_dim * (action + 1)] = body(tensor([state])).detach().cpu().numpy()[0]\n",
    "        phi[feat_dim * action_dim + action] = 1\n",
    "        b += reward * phi / N\n",
    "        if terminal:\n",
    "            A += np.outer(phi, phi) / N\n",
    "        else:\n",
    "            next_phi = np.zeros(feat_dim * action_dim + action_dim)\n",
    "            s_idx = feat_dim * data['actions'][i+1] # assume trajectories is contiguous\n",
    "            next_phi[s_idx: s_idx + feat_dim] = body(tensor([next_state])).detach().cpu().numpy()[0]\n",
    "            next_phi[feat_dim * action_dim + data['actions'][i+1]] = 1\n",
    "            A += np.outer(phi, phi - discount * next_phi) / N\n",
    "        pbar.update(1)\n",
    "    pbar.close() \n",
    "\n",
    "    # update weight\n",
    "    total_weight = np.linalg.lstsq(A, b)[0]\n",
    "    weight = total_weight[:-action_dim].reshape(-1, feat_dim).T\n",
    "    bias = total_weight[-action_dim:]\n",
    "    return weight, bias\n",
    "    \n",
    "\n",
    "weight, bias = fitted_q(data, expert.body, feat_dim, action_dim)\n",
    "estimate_q = expert.body(tensor(data['states'])).detach().cpu().numpy() @ weight + bias\n",
    "print(((estimate_q - data['expert_q']) ** 2).mean())\n",
    "print('difference between argmax:', (estimate_q.argmax(1) != data['expert_q'].argmax(1)).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Linear Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'fourroom-16')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',))]\n",
      "train: [(0, 0)]\n",
      "test: [(0, 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 29.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of transitions: 420\n",
      "tensor(0, dtype=torch.uint8)\n",
      "0-th loss: 0.036114257\n",
      "tensor(0, dtype=torch.uint8)\n",
      "1-th loss: 0.034457173\n",
      "tensor(0, dtype=torch.uint8)\n",
      "2-th loss: 0.03245506\n",
      "tensor(0, dtype=torch.uint8)\n",
      "3-th loss: 0.031068215\n",
      "tensor(0, dtype=torch.uint8)\n",
      "4-th loss: 0.029790074\n",
      "tensor(0, dtype=torch.uint8)\n",
      "5-th loss: 0.02801595\n",
      "tensor(0, dtype=torch.uint8)\n",
      "6-th loss: 0.026512412\n",
      "tensor(0, dtype=torch.uint8)\n",
      "7-th loss: 0.02571906\n",
      "tensor(0, dtype=torch.uint8)\n",
      "8-th loss: 0.024330597\n",
      "tensor(0, dtype=torch.uint8)\n",
      "9-th loss: 0.023701595\n",
      "tensor(0, dtype=torch.uint8)\n",
      "10-th loss: 0.022562206\n",
      "tensor(0, dtype=torch.uint8)\n",
      "11-th loss: 0.021584546\n",
      "tensor(0, dtype=torch.uint8)\n",
      "12-th loss: 0.02064554\n",
      "tensor(0, dtype=torch.uint8)\n",
      "13-th loss: 0.020065848\n",
      "tensor(0, dtype=torch.uint8)\n",
      "14-th loss: 0.019391432\n",
      "tensor(0, dtype=torch.uint8)\n",
      "15-th loss: 0.018746924\n",
      "tensor(0, dtype=torch.uint8)\n",
      "16-th loss: 0.018230017\n",
      "tensor(0, dtype=torch.uint8)\n",
      "17-th loss: 0.017486038\n",
      "tensor(0, dtype=torch.uint8)\n",
      "18-th loss: 0.017787684\n",
      "tensor(0, dtype=torch.uint8)\n",
      "19-th loss: 0.016404698\n",
      "tensor(0, dtype=torch.uint8)\n",
      "20-th loss: 0.01595877\n",
      "tensor(0, dtype=torch.uint8)\n",
      "21-th loss: 0.015484773\n",
      "tensor(0, dtype=torch.uint8)\n",
      "22-th loss: 0.015114944\n",
      "tensor(0, dtype=torch.uint8)\n",
      "23-th loss: 0.014751176\n",
      "tensor(0, dtype=torch.uint8)\n",
      "24-th loss: 0.014269297\n",
      "tensor(0, dtype=torch.uint8)\n",
      "25-th loss: 0.013828299\n",
      "tensor(0, dtype=torch.uint8)\n",
      "26-th loss: 0.01362552\n",
      "tensor(0, dtype=torch.uint8)\n",
      "27-th loss: 0.013282936\n",
      "tensor(0, dtype=torch.uint8)\n",
      "28-th loss: 0.012994926\n",
      "tensor(0, dtype=torch.uint8)\n",
      "29-th loss: 0.0127928145\n",
      "tensor(0, dtype=torch.uint8)\n",
      "30-th loss: 0.01247297\n",
      "tensor(0, dtype=torch.uint8)\n",
      "31-th loss: 0.012241512\n",
      "tensor(0, dtype=torch.uint8)\n",
      "32-th loss: 0.01201513\n",
      "tensor(0, dtype=torch.uint8)\n",
      "33-th loss: 0.01182821\n",
      "tensor(0, dtype=torch.uint8)\n",
      "34-th loss: 0.011608304\n",
      "tensor(0, dtype=torch.uint8)\n",
      "35-th loss: 0.011573251\n",
      "tensor(0, dtype=torch.uint8)\n",
      "36-th loss: 0.011591595\n",
      "tensor(0, dtype=torch.uint8)\n",
      "37-th loss: 0.011154551\n",
      "tensor(0, dtype=torch.uint8)\n",
      "38-th loss: 0.010694314\n",
      "tensor(0, dtype=torch.uint8)\n",
      "39-th loss: 0.010807973\n",
      "tensor(0, dtype=torch.uint8)\n",
      "40-th loss: 0.010664066\n",
      "tensor(0, dtype=torch.uint8)\n",
      "41-th loss: 0.010547539\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ca3117fa0875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m#weight, bias = torch.randn(feat_dim, action_dim), torch.randn(action_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitted_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ca3117fa0875>\u001b[0m in \u001b[0;36mfitted_q\u001b[0;34m(data, body, feat_dim, action_dim)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'states'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'states'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0ma_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'actions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mphis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeats\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_vec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pj/tsa/tsa/deep_rl/utils/torch_utils.py\u001b[0m in \u001b[0;36mtensor\u001b[0;34m(x, dtype)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# D_1, ..., D_n\n",
    "# D, body / \\phi -> A, b -> w(\\phi)\n",
    "# Q(\\phi) - Q_E as loss\n",
    "\n",
    "n_expert_trajs = 30\n",
    "epsilon = 0.0\n",
    "\n",
    "weight_path = '../log/pick.mask.fourroom-16.0.min_dis-1/dqn/double_q/0.190425-220424/models/step-3000000-mean-0.96'\n",
    "env_config_path = '../data/env_configs/pick/fourroom-16.0'\n",
    "\n",
    "expert = get_expert(weight_path)\n",
    "env, all_states, positions, optimal_q = get_env(env_config_path)\n",
    "\n",
    "states = []\n",
    "actions = []\n",
    "next_states = []\n",
    "rewards = []\n",
    "terminals = []\n",
    "qs = []\n",
    "\n",
    "for _ in tqdm(range(n_expert_trajs)):\n",
    "    states_, actions_, next_states_, rewards_, terminals_, qs_, returns = rollout(env, expert, epsilon=epsilon)\n",
    "    #print('expert returns:', returns)\n",
    "    states.append(states_)\n",
    "    actions.append(actions_)\n",
    "    next_states.append(next_states_)\n",
    "    rewards.append(rewards_)\n",
    "    terminals.append(terminals_)\n",
    "    qs.append(qs_)\n",
    "\n",
    "data = dict(\n",
    "    states=np.concatenate(states),\n",
    "    actions=np.concatenate(actions),\n",
    "    next_states=np.concatenate(next_states),\n",
    "    rewards=np.concatenate(rewards),\n",
    "    terminals=np.concatenate(terminals),\n",
    "    expert_q=np.concatenate(qs),\n",
    ")\n",
    "print('num of transitions:', len(data['states']))\n",
    "\n",
    "def fitted_q(data, body, feat_dim, action_dim):\n",
    "    A = torch.zeros(feat_dim * action_dim + action_dim, feat_dim * action_dim + action_dim)\n",
    "    b = torch.zeros(feat_dim * action_dim + action_dim)\n",
    "    N = len(data['states'])\n",
    "\n",
    "    feats = body(tensor(data['states'])).repeat(1, action_dim)\n",
    "    a_vec = one_hot.encode(tensor(data['actions'], torch.long), action_dim)\n",
    "    phis = torch.cat([feats * a_vec.repeat_interleave(feat_dim, 1), a_vec], 1)\n",
    "    \n",
    "    A = torch.matmul(phis.t(), phis - discount * tensor(1 - data['terminals']).unsqueeze(1) * phis.roll(-1, 0)) / N\n",
    "    b = torch.matmul(phis.t(), tensor(data['rewards'])) / N\n",
    "    \n",
    "    # update weight\n",
    "    print(torch.isnan(A).any())\n",
    "    total_weight = torch.matmul(torch.inverse(A + 1e-4 * torch.eye(A.shape[0])), b)\n",
    "    weight = total_weight[:-action_dim].view(-1, feat_dim).t()\n",
    "    bias = total_weight[-action_dim:]\n",
    "    return weight, bias\n",
    "\n",
    "\n",
    "model = copy.deepcopy(expert)\n",
    "optim = torch.optim.RMSprop(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()), lr=0.00025, alpha=0.95, eps=0.01, centered=True)\n",
    "#weight, bias = torch.randn(feat_dim, action_dim), torch.randn(action_dim)\n",
    "for i in range(100):\n",
    "    weight, bias = fitted_q(data, model.body, feat_dim, action_dim)\n",
    "    model.fc_head.weight.data.copy_(weight.t())\n",
    "    model.fc_head.bias.data.copy_(bias)\n",
    "    estimate_q = model(data['states'])\n",
    "    #estimate_q = torch.matmul(model.body(tensor(data['states'])), weight) + bias\n",
    "    loss = F.mse_loss(estimate_q, tensor(data['expert_q']))\n",
    "    print('{}-th loss:'.format(i), loss.detach().cpu().numpy())\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# print(torch.__version__)\n",
    "\n",
    "# class DummyModule(torch.nn.Module):\n",
    "#     def forward(self, x):\n",
    "#         V = torch.Tensor(2, 2)\n",
    "#         V[0, 0] = x\n",
    "#         return torch.sum(V * 3)\n",
    "\n",
    "\n",
    "# x = torch.tensor([1], requires_grad=True)\n",
    "# r = DummyModule()(x)\n",
    "# r.backward()\n",
    "# print(x.grad)\n",
    "\n",
    "\n",
    "print(torch.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
