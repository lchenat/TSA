{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todos\n",
    "- [x] add todo (jupyter notebook tutorial)\n",
    "- [x] ipdb on exception\n",
    "- [ ] clean code: remove argparse, run by calling function with suitable arguments\n",
    "- [ ] write evaluation of upper bound performance of an abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect argument. Use on/1, off/0, or nothing for a toggle.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-769bd40e7a35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# set seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hi' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-13-769bd40e7a35>\u001b[0m(20)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     18 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# set seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 20 \u001b[0;31m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     21 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     22 \u001b[0;31m\u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pdb on # works for all cell\n",
    "\n",
    "from deep_rl.gridworld import ReachGridWorld, PORGBEnv, ReachGoalManager\n",
    "import gym\n",
    "import sys \n",
    "from random import shuffle\n",
    "from collections import Counter, namedtuple\n",
    "import random\n",
    "import argparse\n",
    "import dill\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "def seed(s):\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "\n",
    "seed(0) # set seed \n",
    "\n",
    "class FiniteHorizonEnv(gym.Wrapper):\n",
    "    def __init__(self, env, T=100000000):\n",
    "        super().__init__(env)\n",
    "        self.T = T \n",
    "\n",
    "    def reset(self, *args, **kwargs):\n",
    "        self.t = 0 \n",
    "        return self.env.reset(*args, **kwargs)\n",
    "\n",
    "    def step(self, action):\n",
    "        o, r, done, info = self.env.step(action)\n",
    "        self.t += 1\n",
    "        if self.t >= self.T:\n",
    "            done = True\n",
    "        return o, r, done, info\n",
    "\n",
    "class one_hot:\n",
    "    # 1 or 2 dim\n",
    "    @staticmethod\n",
    "    def encode(indices, dim):\n",
    "        if len(indices.shape) > 1:\n",
    "            indices = indices.squeeze(axis=1)\n",
    "        assert len(indices.shape) == 1, 'shape error'\n",
    "        return np.eye(dim)[indices]\n",
    "\n",
    "    # 2-dim\n",
    "    @staticmethod\n",
    "    def decode(vs):\n",
    "        return np.argmax(vs, 1)\n",
    "\n",
    "class GridDrawer:                           \n",
    "    def __init__(self, color_list):\n",
    "        self.color_list = np.asarray(color_list)\n",
    "\n",
    "    # input: a 2-d index matrix\n",
    "    # output: a 2-d rgb matrix\n",
    "    def draw(self, indices, repeat=16):\n",
    "        return np.uint8(255 * np.array(self.color_list[indices, :]).repeat(repeat, 0).repeat(repeat, 1))\n",
    "    \n",
    "# this is my color list\n",
    "color_map = dict([\n",
    "    #*[('grey-{}'.format(v), plt.cm.Greys(0.1 * v)) for v in range(1, 10)],\n",
    "    *[('purple-{}'.format(v), plt.cm.Purples(0.1 * v)) for v in range(1, 10)],\n",
    "    *[('blue-{}'.format(v), plt.cm.Blues(0.1 * v)) for v in range(1, 10)],\n",
    "    *[('green-{}'.format(v), plt.cm.Greens(0.1 * v)) for v in range(1, 10)],\n",
    "    *[('orange-{}'.format(v), plt.cm.Oranges(0.1 * v)) for v in range(1, 10)],\n",
    "    *[('red-{}'.format(v), plt.cm.Reds(0.1 * v)) for v in range(1, 10)],\n",
    "])\n",
    "\n",
    "color_list = list(color_map.values())\n",
    "shuffle(color_list)\n",
    "color_list = [plt.cm.Greys(0.9)] + [plt.cm.Greys(0.5)] + color_list\n",
    "visualization_map = dict([\n",
    "    ('G', 0),\n",
    "    ('#', 1),\n",
    "    *[(str(i), i + 2) for i in range(0, 45)],\n",
    "])\n",
    "\n",
    "def cluster_abstraction(env, n_abs):\n",
    "    from sklearn.cluster import KMeans\n",
    "    n_action = env.action_space.n\n",
    "    env.reset()\n",
    "    states = get_states(env)\n",
    "    m = [[] for _ in range(len(states))]\n",
    "    for combo in env.train_combos:\n",
    "        env.reset(index=combo)\n",
    "        for i, s in enumerate(states):\n",
    "            env.teleport(*s)\n",
    "            qs = np.array(env.get_q(0.99))\n",
    "            best_actions = (qs == qs.max()).astype(int)\n",
    "            sample_action = one_hot.encode(np.random.choice(np.argwhere(best_actions).squeeze(1), size=1), n_action)[0]\n",
    "            #print('{}: {}, {}'.format(s, best_actions, sample_action))\n",
    "            m[i].append(sample_action)\n",
    "            #m[i].append(best_actions)\n",
    "    m = np.array([np.concatenate(row) for row in m])\n",
    "    kmeans = KMeans(n_clusters=n_abs, random_state=0).fit(m)\n",
    "    return {s: label for s, label in zip(states, kmeans.labels_)}\n",
    "    \n",
    "GoalConfig = namedtuple('GoalConfig', ['map_name', 'n_goal', 'min_dis'])\n",
    "def gen_multigoal_env(goal_config):\n",
    "    goal_manager = ReachGoalManager(goal_config.map_name)\n",
    "    # min_dis between goals (approximation of corelation)\n",
    "    goals = goal_manager.gen_goals(goal_config.n_goal + 1, min_dis=goal_config.min_dis) \n",
    "    train_combos = [(0,) + goal for goal in goals[:goal_config.n_goal]]\n",
    "    test_combos = [(0,) + goal for goal in goals[goal_config.n_goal:]]\n",
    "    return ReachGridWorld([goal_config.map_name], train_combos, test_combos)\n",
    "\n",
    "def visualize_abs(abs_map, env):\n",
    "    m = env.get_map(0)\n",
    "    print('labels:', set(abs_map.values()))\n",
    "    print('count on labels:', Counter(abs_map.values()))\n",
    "    for i in range(len(m)):\n",
    "        for j in range(len(m[i])):\n",
    "            if m[i][j] == '#': continue\n",
    "            elif (i, j) in abs_map:\n",
    "                m[i][j] = str(abs_map[(i, j)])\n",
    "            else:\n",
    "                m[i][j] = 'G'\n",
    "    #for row in m:\n",
    "    #    print(' '.join(row))\n",
    "    drawer = GridDrawer(color_list)\n",
    "    img = drawer.draw([[visualization_map[m[i][j]] for j in range(len(m[i]))] for i in range(len(m))])\n",
    "    display(Image.fromarray(img))\n",
    "    \n",
    "def save_abs(abs_dict, fn):\n",
    "    with open(fn, 'wb') as f:\n",
    "        dill.dump(abs_dict, f)\n",
    "    \n",
    "def load_abs(fn):\n",
    "    with open(fn, 'rb') as f:\n",
    "        return dill.load(fn)\n",
    "    \n",
    "# get all goals in train_combos\n",
    "def get_goals(env, train=True):\n",
    "    combos = env.unwrapped.train_combos if train else env.unwrapped.test_combos\n",
    "    return [env.unwrapped.i2g[combo[1]] for combo in combos]\n",
    "    \n",
    "# input: an single map multigoal environment\n",
    "# output: position of all states that are not goal states\n",
    "def get_states(env):\n",
    "    goals = get_goals(env)\n",
    "    return [s for s in env.unwrapped.pos_candidates if s not in goals]\n",
    "\n",
    "# iterate over all possible policy under given abstraction, and return the best average return\n",
    "# The environment should have max_len wrapper to ensure it is evaluable\n",
    "def evaluate_env_with_goal(env, abs_map, goal):\n",
    "    best_return = -np.inf\n",
    "    for policy in itertools.product(*[range(env.action_space.n) for _ in len(abs_map)]):\n",
    "        returns = dict() # s: return\n",
    "        for s in get_states(env):\n",
    "            if s in returns: continue\n",
    "            env.reset(index=(0, env.unwrapped.g2i[goal]))\n",
    "            env.teleport(*s)\n",
    "            os = []\n",
    "            rs = []\n",
    "            o = s\n",
    "            done = False\n",
    "            while not done:\n",
    "                if o in returns:\n",
    "                    os.append(o)\n",
    "                    rs.append(returns[o])\n",
    "                    break\n",
    "                a = policy[abs_map[o]]\n",
    "                _, r, done, info = env.step(o)\n",
    "                os.append(o)\n",
    "                rs.append(r)\n",
    "                if done: break\n",
    "                o = info['pos']\n",
    "        best_return = np.max(best_return, np.mean(returns))\n",
    "    return best_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: an environment and the corresponding index (map_id, gx, gy)\n",
    "# output: an identity map of this map_id and task\n",
    "def get_identity_map():\n",
    "    map_names = ['map49']\n",
    "    train_combos = [(0, 1, 1)]\n",
    "    test_combos = [(0, 2, 2)]\n",
    "    env = ReachGridWorld(map_names, train_combos, test_combos)\n",
    "    env.reset()\n",
    "    goal = (env.unwrapped.gx, env.unwrapped.gy)\n",
    "    states = [s for s in env.pos_candidates if s != goal]\n",
    "    n_states = len(states)\n",
    "    id_map = dict([(s, i) for i, s in enumerate(states)])\n",
    "    #print(id_map)\n",
    "    return id_map\n",
    "\n",
    "# get abstraction map by a chosen method\n",
    "# specify the number of abstract states, number of goals and the minimum distance between goal states\n",
    "def get_abs_map(goal_config, n_abs=40, method='cluster'):\n",
    "    env = gen_multigoal_env(goal_config)\n",
    "    if method == 'cluster':\n",
    "        # abs_map {(x, y): abstract state index}\n",
    "        abs_map = cluster_abstraction(env, args.n_abs)\n",
    "    else:\n",
    "        raise Exception('no such method')\n",
    "    visualize_abs(abs_map, env)\n",
    "    save_abs({0: abs_map}, 'abs/{}-n_goal-{}-n_abs-{}.pkl'.format(method, n_goal, n_abs))\n",
    "\n",
    "# given an environment and its corresponding abstraction, evaluate the mean return if we sample the initial state\n",
    "def evaluate_abs(goal_config, abs_fn, max_len=100):\n",
    "    env = gen_multigoal_env(goal_config)\n",
    "    env = FiniteHorizonEnv(env, max_len)\n",
    "    abs_map = load_abs(abs_fn)\n",
    "    goals = get_goals(env)\n",
    "    states = get_states(env)\n",
    "    qs = []\n",
    "    for goal in goals:\n",
    "        qs.append(evaluate_abs_with_goal(env, abs_map, goal))\n",
    "    print(qs, np.mean(qs))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    seed(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of colors: 47\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAACACAYAAAB6D7CqAAAC0ElEQVR4nO3Wv4sXdBzH8e9FOWSLcfiTEwtPThAVBB0EJxNKXQsOskVoUJxEbnISBAfhHAURAmlws3JxaGoJjoYgIjDkEP+EpuD8M97D8/H4B17v4cOTz9LKysrOYtDGxsbk/OLqlfXR/e3vPh3d/+Pe69H9ayf2j+5//Pj26P6Tr46P7h9efD26//zmi9H9D0bXAQYJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBA1tKr5QM7kwecPX1gcn7xyd310f1XR1ZH9x/9sn90f+337dH95c/2jO7/dvLZ6P721uz7/+H6udF9P0AgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLKW/l79fGfygNWfNifnF+/2fjG6f+i/N6P7i4/+H51/+uWp0f0b+x6O7v+z+87o/sFv7o/uLw4fG533AwSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIOvDfzdfjh7w65nzo/u7Hv48un/525XR/e/Xfhzdf3750uj+1sWLo/ube2+N7j94++fo/l9HL4zu+wECWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJD1Hr6/NAiZzxfmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=320x128 at 0x7FD0501A5D68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drawer = GridDrawer(color_list=color_list)\n",
    "print('# of colors:', len(drawer.color_list))\n",
    "img = Image.fromarray(drawer.draw(np.arange(40).reshape((4, 10)), repeat=32))\n",
    "#img = Image.fromarray(drawer.draw([[0, 1], [2,3]], repeat=32))\n",
    "display(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
