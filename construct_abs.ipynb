{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todos\n",
    "- [x] add todo (jupyter notebook tutorial)\n",
    "- [x] ipdb on exception\n",
    "- [x] clean code: remove argparse, run by calling function with suitable arguments\n",
    "-  ~~write evaluation of upper bound performance of an abstraction~~ (This is useless since when there are 40 abstraction states, the number of policy is $4^{40}$, impossible to find out the best one)\n",
    "- [x] generate abstractions with different n_goal and n_abs, select some of them to do multi-task training and transfer\n",
    "    - run 12 tasks on identity map\n",
    "    - run 12 tasks on 12-44 pos abstract map\n",
    "    - run 1 task on 12-44 pos abstract map\n",
    "- [x] vanilla alternative training for prob and vq\n",
    "- [x] try window size = 1 (otherwise it is impossible to visualize abs)\n",
    "    - [ ] why it does not work?\n",
    "- [x] try to log text on the config: including git code\n",
    "- [x] visualization of abs at each step\n",
    "- [x] try nonlinear actor for vq (does not work)\n",
    "- [x] change critic to abstract state critic (does not work)\n",
    "- [ ] implement sampling abs_encoder\n",
    "- [ ] try I2A modeling\n",
    "- [ ] get rid of the time stamp in tf_log\n",
    "- [ ] make plots for all log with same attrubites\n",
    "- [ ] offline encoder training? (For VQ)\n",
    "- [x] run 12 tasks for feature baseline\n",
    "- [ ] centralized and resumable experiment\n",
    "    - looking at the structure of the train.py, you see that you need args, setup_fn which takes args and return agent, and train_fn which task agent and config\n",
    "    - need a way to archive experiments been ran, even though the result is not good, at least know what is not working\n",
    "    - combine log and model\n",
    "    - argparse as a tree\n",
    "    - manage model and loss by a dictionary\n",
    "    - do not overlap model and log!\n",
    "    \n",
    "# Readings\n",
    "- [ ] POMDP\n",
    "- [ ] soft actor-critic\n",
    "- [ ] Representation learning for RL (alternative training, meta-learning for $\\phi$?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "# of shown colors: 95/97\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmAAAACgCAYAAACrHNBNAAAFRElEQVR4nO3Y3WvWdRzH4fvWAjNnJk2MWmSBkVLYAxFiq7OKbEFEQpHVRkFGSR3UipBaB24pNQrRiFQ0mEEbzQiLCHqYRQdhUHPMeRCkYcEkSxbsjtZ/8f4cdF3/wPvL7+T34tPs6OiYaxTq7e2tnG9ctHRt6X7bBeeV7t94wyWl+wPH+kr3t618uHS//+1Tpftj7W2l+wP3zy/d/3P6itL94a2fl+5vf/Wa0v037lhduv/j60+U7s/+1lO6v/Puq0r3G/etK50/PHiodH9e6ToAwP+QAAMACBNgAABhAgwAIEyAAQCECTAAgDABBgAQJsAAAMIEGABAmAADAAgTYAAAYQIMACBMgAEAhAkwAIAwAQYAECbAAADCBBgAQJgAAwAIE2AAAGECDAAgTIABAIQJMACAMAEGABAmwAAAwgQYAECYAAMACBNgAABhAgwAIEyAAQCECTAAgDABBgAQ1pw+25qrfMD4kROV841fL/66dP/3g5eX7g/+01e6P9lYWbr/04b+0v3WTatK968/uKt0f+H7L5Xu/715R+n++Q9+Urp/bPlrpfuXvjNZuv/ysjWl+1t2PFm6f3zbUOn+m/0fle4PHzpauu8CBgAQJsAAAMIEGABAmAADAAgTYAAAYQIMACBMgAEAhAkwAIAwAQYAECbAAADCBBgAQJgAAwAIE2AAAGECDAAgTIABAIQJMACAMAEGABAmwAAAwgQYAECYAAMACBNgAABhAgwAIEyAAQCECTAAgDABBgAQJsAAAMIEGABAmAADAAgTYAAAYQIMACBMgAEAhDXHbmvOVT7g7L4PK+cbo0+fKd1/a9O/pft/HNhcuj/9/FTp/sL2xaX7W+7dX7rfO/RA6X73e9+X7n9xemfp/rx1HaX7cxOHS/enPvumdL/noQ2l+2N3bi/dP/Bz6e+/caZzTen+6S+fKd13AQMACBNgAABhAgwAIEyAAQCECTAAgDABBgAQJsAAAMIEGABAmAADAAgTYAAAYQIMACBMgAEAhAkwAIAwAQYAECbAAADCBBgAQJgAAwAIE2AAAGECDAAgTIABAIQJMACAMAEGABAmwAAAwgQYAECYAAMACBNgAABhAgwAIEyAAQCECTAAgDABBgAQJsAAAMKaHyxZNlf5gLtO/lI532jvHirdnzreX7rfGvm2dP+5rv2l+z0nt5bu37Jpaen+gvGZ0v2ZczpK9999am/p/vprW6X7K569p3R/9twVpfsf//Bp6X7XntHS/e+WLCrdnxhdULr/yK3N0n0XMACAMAEGABAmwAAAwgQYAECYAAMACBNgAABhAgwAIEyAAQCECTAAgDABBgAQJsAAAMIEGABAmAADAAgTYAAAYQIMACBMgAEAhAkwAIAwAQYAECbAAADCBBgAQJgAAwAIE2AAAGECDAAgTIABAIQJMACAMAEGABAmwAAAwgQYAECYAAMACBNgAABhAgwAIKx5aubEXOUDNi7fUznfGO7eVbq/tm1v6X7XzGzp/is3T5buL9o9v3T/9vHa7z8ycLR0v+/CF0r3L3vx6tL91r7B0v3HWotL9/9atb50v3P3o6X7R1Z3lu43Jr4qnb9y4vHS/ZGN15Xuu4ABAIQJMACAMAEGABAmwAAAwgQYAECYAAMACBNgAABhAgwAIEyAAQCECTAAgDABBgAQJsAAAMIEGABAmAADAAgTYAAAYQIMACBMgAEAhAkwAIAwAQYAECbAAADCBBgAQJgAAwAIE2AAAGECDAAgTIABAIQJMACAMAEGABAmwAAAwgQYAECYAAMACBNgAABh/wH+85bD72U/xwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=608x160 at 0x7FE0F8EC2668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pdb on\n",
    "\n",
    "from deep_rl.gridworld import ReachGridWorld, PickGridWorld, PORGBEnv, GoalManager\n",
    "import os\n",
    "import sys \n",
    "import random\n",
    "import argparse\n",
    "import dill\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from collections import Counter, namedtuple\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "\n",
    "def seed(s):\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "\n",
    "seed(0) # set seed \n",
    "\n",
    "class one_hot:\n",
    "    # 1 or 2 dim\n",
    "    @staticmethod\n",
    "    def encode(indices, dim):\n",
    "        if len(indices.shape) > 1:\n",
    "            indices = indices.squeeze(axis=1)\n",
    "        assert len(indices.shape) == 1, 'shape error'\n",
    "        return np.eye(dim)[indices]\n",
    "\n",
    "    # 2-dim\n",
    "    @staticmethod\n",
    "    def decode(vs):\n",
    "        return np.argmax(vs, 1)\n",
    "\n",
    "def fload(fn, ftype):\n",
    "    if ftype == 'json':\n",
    "        with open(fn) as f:\n",
    "            return json.load(f)\n",
    "    elif ftype == 'pkl':\n",
    "        with open(fn, 'rb') as f:\n",
    "            return dill.load(f)\n",
    "    elif ftype == 'png':\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        raise Exception('cannot read this data type: {}'.format(ftype))\n",
    "    \n",
    "def fsave(data, fn, ftype):\n",
    "    dirname = os.path.dirname(fn)\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    if ftype == 'json':\n",
    "        with open(fn, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "    elif ftype == 'pkl':\n",
    "        with open(fn, 'wb') as f:\n",
    "            dill.dump(data, f)    \n",
    "    elif ftype == 'png':\n",
    "        Image.fromarray(data).save(fn)\n",
    "    else:\n",
    "        raise Exception('unsupported file type: {}'.format(ftype))\n",
    "\n",
    "def index_dict(l):\n",
    "    l = list(enumerate(set(l)))\n",
    "    i2e = dict(l)\n",
    "    e2i = dict([(e, i) for i, e in l])\n",
    "    return i2e, e2i\n",
    "        \n",
    "# input: a index map\n",
    "# output: a new index map such that the index are contiguous\n",
    "def index_reduce(index_map):\n",
    "    _, i2i = index_dict(index_map.values())\n",
    "    return {k: i2i[i] for k, i in index_map.items()}\n",
    "\n",
    "# given a 2d list, concatenate each row by dim 1, and each column by dim 0\n",
    "def concat2d(arr2d):\n",
    "    return np.concatenate([np.concatenate(arr, axis=1) for arr in arr2d])\n",
    "\n",
    "def imshow(img):\n",
    "    display(Image.fromarray(np.asarray(img)))\n",
    "\n",
    "class GridDrawer:                           \n",
    "    def __init__(self, color_list):\n",
    "        self.color_list = np.asarray(color_list)\n",
    "\n",
    "    # input: a 2-d index matrix\n",
    "    # output: a 2-d rgb matrix\n",
    "    def draw(self, indices, repeat=16):\n",
    "        return np.uint8(255 * np.array(self.color_list[indices, :]).repeat(repeat, 0).repeat(repeat, 1))\n",
    "    \n",
    "# this is my color list\n",
    "color_map = dict([\n",
    "    #*[('grey-{}'.format(v), plt.cm.Greys(0.1 * v)) for v in range(1, 10)],\n",
    "    *[('purple-{}'.format(v), plt.cm.Purples(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('blue-{}'.format(v), plt.cm.Blues(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('green-{}'.format(v), plt.cm.Greens(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('orange-{}'.format(v), plt.cm.Oranges(0.05 * v)) for v in range(1, 20)],\n",
    "    *[('red-{}'.format(v), plt.cm.Reds(0.05 * v)) for v in range(1, 20)],\n",
    "])\n",
    "\n",
    "color_list = list(color_map.values())\n",
    "shuffle(color_list)\n",
    "color_list = [plt.cm.Greys(0.9)] + [plt.cm.Greys(0.5)] + color_list\n",
    "visualization_map = dict([\n",
    "    ('G', 0),\n",
    "    ('#', 1),\n",
    "    *[(str(i), i + 2) for i in range(0, 100)],\n",
    "])\n",
    "\n",
    "def display_color_list(color_list):\n",
    "    drawer = GridDrawer(color_list=color_list)\n",
    "    n_shown_color = 95\n",
    "    n_row = 5\n",
    "    print('# of shown colors: {}/{}'.format(n_shown_color, len(drawer.color_list)))\n",
    "    grid = np.arange(n_shown_color).reshape((n_row, n_shown_color // n_row))\n",
    "    img = Image.fromarray(drawer.draw(grid, repeat=32))\n",
    "    display(img)\n",
    "\n",
    "display_color_list(color_list)\n",
    "    \n",
    "def cluster_abstraction(env, n_abs, feature_type='whole', reset_kws=dict()):\n",
    "    print('n_abs:', n_abs)\n",
    "    from sklearn.cluster import KMeans\n",
    "    n_action = env.action_space.n\n",
    "    env.reset(**reset_kws)\n",
    "    states = get_states(env)\n",
    "    m = [[] for _ in range(len(states))]\n",
    "    for combo in env.train_combos: # do not include test_combos!\n",
    "        env.reset(index=combo, **reset_kws)\n",
    "        for i, s in enumerate(states):\n",
    "            env.teleport(*s)\n",
    "            qs = np.array(env.get_q(0.99))\n",
    "            best_actions = (qs == qs.max()).astype(int)\n",
    "            if feature_type == 'whole':\n",
    "                m[i].append(best_actions)\n",
    "            elif feature_type == 'sample':\n",
    "                sample_action = np.random.choice(np.argwhere(best_actions).squeeze(1), size=1)\n",
    "                sample_action = one_hot.encode(sample_action, n_action)[0]\n",
    "                m[i].append(sample_action)\n",
    "            else:\n",
    "                raise Exception('invalid feature type')\n",
    "    m = np.array([np.concatenate(row) for row in m])\n",
    "    kmeans = KMeans(n_clusters=n_abs, random_state=0).fit(m)\n",
    "    abs_map = {s: label for s, label in zip(states, kmeans.labels_)}\n",
    "    return abs_map\n",
    "\n",
    "def get_abs_map(env, n_abs=40, method='cluster', method_config=dict()):\n",
    "    # abs_map {(x, y): abstract state index}\n",
    "    if method == 'cluster':\n",
    "        abs_map = cluster_abstraction(env, n_abs, **method_config)\n",
    "    else:\n",
    "        raise Exception('no such method')\n",
    "    return abs_map\n",
    "\n",
    "GoalConfig = namedtuple('GoalConfig', ['map_name', 'n_goal', 'min_dis'])  \n",
    "    \n",
    "def save_abs(abs_dict, fn):\n",
    "    with open(os.path.join('data/abs', fn), 'wb') as f:\n",
    "        dill.dump(abs_dict, f)\n",
    "    \n",
    "def load_abs(fn):\n",
    "    with open(os.path.join('data/abs', fn), 'rb') as f:\n",
    "        return dill.load(fn)\n",
    "    \n",
    "# input: an single map multigoal environment\n",
    "# output: position of all states that are not goal states\n",
    "def get_states(env):\n",
    "    if isinstance(env, ReachGridWorld):\n",
    "        goals = get_goals(env)\n",
    "        return [s for s in env.unwrapped.pos_candidates if s not in goals]\n",
    "    elif isinstance(env, PickGridWorld):\n",
    "        return env.unwrapped.pos_candidates\n",
    "    else:\n",
    "        raise Exception('unsupported env type')\n",
    "\n",
    "def kv2str(items, is_dict=True):\n",
    "    if is_dict:\n",
    "        items = list(items.items())\n",
    "    return '-'.join(['{}-{}'.format(*item) for item in items])\n",
    "\n",
    "def get_abs_fn(method, method_config, n_goal, n_abs):\n",
    "    return '{}-{}-n_goal-{}-n_abs-{}.pkl'.format(\n",
    "                                            method,\n",
    "                                            kv2str(method_config),\n",
    "                                            n_goal,\n",
    "                                            n_abs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReachEnv Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all goals in train_combos\n",
    "def get_goals(env, train=True):\n",
    "    combos = env.unwrapped.train_combos if train else env.unwrapped.test_combos\n",
    "    return [env.unwrapped.i2g[combo[1]] for combo in combos]\n",
    "\n",
    "def gen_multigoal_combos(goal_config):\n",
    "    MAX_GOAL_NUM = 15\n",
    "    goal_manager = GoalManager(goal_config.map_name)\n",
    "    # min_dis between goals (approximation of corelation)\n",
    "    goals = goal_manager.gen_goals(MAX_GOAL_NUM + 1, min_dis=goal_config.min_dis) \n",
    "    train_combos = [(0,) + goal for goal in goals[:goal_config.n_goal]]\n",
    "    test_combos = [(0,) + goals[-1]]\n",
    "    return train_combos, test_combos\n",
    "\n",
    "def gen_multigoal_env(goal_config):\n",
    "    train_combos, test_combos = gen_multigoal_combos(goal_config)\n",
    "    return ReachGridWorld([goal_config.map_name], train_combos, test_combos)  \n",
    "\n",
    "def get_abs_img(abs_map, env): # ???\n",
    "    n_tasks = len(set([index[1] for index in env.unwrapped.train_combos + env.unwrapped.test_combos]))\n",
    "    imgs = [[None] * n_tasks for _ in range(len(env.unwrapped.maps))]\n",
    "    for index in abs_map:\n",
    "        m = env.get_map(index[0])\n",
    "        print('labels:', set(abs_map[index].values()))\n",
    "        print('count on labels:', Counter(abs_map[index].values()))\n",
    "        for i in range(len(m)):\n",
    "            for j in range(len(m[i])):\n",
    "                if m[i][j] == '#': continue\n",
    "                elif (i, j) in abs_map[index]:\n",
    "                    m[i][j] = str(abs_map[index][(i, j)])\n",
    "                else:\n",
    "                    m[i][j] = 'G'\n",
    "        drawer = GridDrawer(color_list)\n",
    "        imgs[index[0]][index[1]] = drawer.draw([[visualization_map[m[i][j]] for j in range(len(m[i]))] for i in range(len(m))])\n",
    "    for i, row in enumerate(imgs):\n",
    "        for j, img in enumerate(row):\n",
    "            if img is None:\n",
    "                imgs[i][j] = np.zeros((256, 256, 4), dtype=np.uint8)\n",
    "    return concat2d(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReachEnv Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: an environment and the corresponding index (map_id, gx, gy)\n",
    "# output: an identity map of this map_id and task\n",
    "def gen_identity_map(map_name):\n",
    "    train_combos = [(0, 1, 1)]\n",
    "    test_combos = [(0, 2, 2)]\n",
    "    env = ReachGridWorld([map_name], train_combos, test_combos)\n",
    "    env.reset()\n",
    "    states = [s for s in env.pos_candidates] + list(env.train_pos)\n",
    "    print(states)\n",
    "    n_states = len(states)\n",
    "    id_map = dict([(s, i) for i, s in enumerate(states)])\n",
    "    save_abs({0: id_map}, '{}-id.pkl'.format(map_name))\n",
    "\n",
    "def gen_reach_config(goal_config, min_dis):\n",
    "    train_combos, test_combos = gen_multigoal_combos(goal_config)\n",
    "    env_config = dict(\n",
    "        map_names=[goal_config.map_name],\n",
    "        train_combos=train_combos,\n",
    "        test_combos=test_combos,\n",
    "        min_dis=min_dis,\n",
    "    )\n",
    "    fn = '{}-n_goal-{}-min_dis-{}'.format(goal_config.map_name, goal_config.n_goal, goal_config.min_dis)\n",
    "    with open('data/env_configs/{}'.format(fn), 'wb') as f:\n",
    "        dill.dump(env_config, f)\n",
    "        print('generate env_config: {}'.format(fn))\n",
    "        \n",
    "# add more attributes to env_config for all env_config in env_configs\n",
    "def modify_env_configs():\n",
    "    for fn in os.listdir('data/env_configs'):\n",
    "        env_config = fload(fn, ftype='pkl')\n",
    "        # env_config['window'] = 1 # example\n",
    "        fsave(env_config, fn, ftype='pkl')\n",
    "        \n",
    "def gen_single_env_config(map_name, goal):\n",
    "    train_combos = [(0,) + goal]\n",
    "    test_combos = [(0, 1, 1)]\n",
    "    env_config = dict(\n",
    "        map_names=[map_name],\n",
    "        train_combos=train_combos,\n",
    "        test_combos=test_combos,\n",
    "        min_dis=10,\n",
    "    )\n",
    "    fn = 'data/env_configs/map49-{}-{}'.format(*goal)\n",
    "    fsave(env_config, fn, ftype='pkl')\n",
    "    print('{} saved'.format(fn))\n",
    "    \n",
    "# given a directory of pkl of abs_map, output the img of the abs\n",
    "def gen_abs_imgs(dirname, redo=False):\n",
    "    env_config = fload(os.path.join(dirname, 'env_config'), ftype='pkl')\n",
    "    env = ReachGridWorld(**env_config)\n",
    "    n_tasks = len(set([index[1] for index in env_config['train_combos']]))\n",
    "    for fn in os.listdir(Path(dirname, 'abs_map')):\n",
    "        save_fp = Path(dirname, 'abs_img', Path(fn).with_suffix('.png'))\n",
    "        if save_fp.exists() and not redo: continue\n",
    "        print(fn)\n",
    "        abs_map = fload(Path(dirname, 'abs_map', fn), ftype='pkl')\n",
    "        img = get_abs_img(abs_map, env)\n",
    "        fsave(img, save_fp, ftype='png')\n",
    "        \n",
    "def gen_abs_maps(n_goal_range, n_abs_range, method, method_config=dict()):\n",
    "    abs_maps = [[] for _ in n_goal_range] # n_goal x n_abs\n",
    "    for i, n_goal in enumerate(n_goal_range):\n",
    "        goal_config = GoalConfig('map49', n_goal=n_goal, min_dis=4)\n",
    "        env = gen_multigoal_env(goal_config)\n",
    "        for n_abs in n_abs_range:\n",
    "            goal_map = {g: n_abs + i for i, g in enumerate(env.unwrapped.train_pos)}\n",
    "            abs_map = get_abs_map(env, n_abs=n_abs, method=method, method_config=method_config)\n",
    "            abs_maps[i].append(abs_map)\n",
    "            saved_map = {**abs_map, **goal_map}\n",
    "            fn = get_abs_fn(method, method_config, n_goal, n_abs)\n",
    "            save_abs({0: saved_map}, fn)\n",
    "            print('saved to {}'.format(fn))\n",
    "    abs_maps = concat2d([[get_abs_img(abs_map, env) for abs_map in row] for row in abs_maps])\n",
    "    imshow(abs_maps)\n",
    "    Image.fromarray(abs_maps).save('data/abs/abs_mat.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PickEnv Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pick_config(goal_config):\n",
    "    MAX_OBJ_NUM = 15\n",
    "    goal_manager = GoalManager(goal_config.map_name)\n",
    "    obj_pos = goal_manager.gen_goals(MAX_OBJ_NUM + 1, min_dis=goal_config.min_dis)\n",
    "    obj_pos = [obj_pos[-1:] + obj_pos[:goal_config.n_goal-1]] # always the same test\n",
    "    env_config = dict(\n",
    "        map_names = [goal_config.map_name],\n",
    "        train_combos = [(0, i) for i in range(1, goal_config.n_goal)],\n",
    "        test_combos = [(0, 0)],\n",
    "        num_obj_types=goal_config.n_goal,\n",
    "        obj_pos=obj_pos,\n",
    "    )\n",
    "    return env_config \n",
    "\n",
    "def get_pick_img(abs_map, env, show_goal=True):\n",
    "    m = env.get_map(0)\n",
    "    for i in range(len(m)):\n",
    "        for j in range(len(m[i])):\n",
    "            if m[i][j] == '#': continue\n",
    "            elif (i, j) in env.default_obj_pos[0] and show_goal:\n",
    "                m[i][j] = 'G'\n",
    "            elif (i, j) in abs_map:\n",
    "                m[i][j] = str(abs_map[(i, j)])\n",
    "            else:\n",
    "                raise Exception('correspondence not found')\n",
    "    drawer = GridDrawer(color_list)\n",
    "    img = drawer.draw([[visualization_map[m[i][j]] for j in range(len(m[i]))] for i in range(len(m))])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PickEnv Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# get abstraction map by a chosen method\n",
    "# specify the number of abstract states, number of goals and the minimum distance between goal states\n",
    "def gen_abs_map(goal_config, n_abs=40, method='cluster', method_config=dict()):\n",
    "    env = gen_multigoal_env(goal_config)\n",
    "    abs_map = get_abs_map(env, n_abs=n_abs, method=method, method_config=method_config)\n",
    "    # imshow(gen_abs_img(abs_map, env))\n",
    "    save_abs({0: abs_map}, get_abs_fn(method, method_config, goal_config.n_goal, n_abs))\n",
    "    print('save abs_map to {}'.format(abs_fn))\n",
    "\n",
    "# this is a new way to generate config, so that the test set are all the same\n",
    "def gen_pick_config(goal_config, inv=False):\n",
    "    env_config = get_pick_config(goal_config)\n",
    "    if inv:\n",
    "        env_config['train_combos'], env_config['test_combos'] = env_config['test_combos'], env_config['train_combos']\n",
    "    print(goal_config)\n",
    "    fn = '{}-{}-{}-min_dis-{}'.format(\n",
    "        goal_config.map_name + ('-inv' if inv else ''),\n",
    "        len(env_config['train_combos']), \n",
    "        len(env_config['test_combos']), \n",
    "        goal_config.min_dis,\n",
    "    )\n",
    "    print(fn)\n",
    "    save_path = Path('data/env_configs/pick', fn)\n",
    "    fsave(env_config, save_path, ftype='pkl')\n",
    "    print('saved to {}'.format(save_path))\n",
    "    \n",
    "def gen_pick_abs(goal_config, inv=False, n_abs=44, method='cluster', method_config=dict()):\n",
    "    env_config = get_pick_config(goal_config)\n",
    "    if inv:\n",
    "        env_config['train_combos'], env_config['test_combos'] = env_config['test_combos'], env_config['train_combos']\n",
    "    env = PickGridWorld(**env_config, task_length=1, seed=0)\n",
    "    obj_map = {o: n_abs + i for i, o in enumerate(env.unwrapped.default_obj_pos[0])}\n",
    "    abs_map = get_abs_map(env, n_abs=n_abs, method=method, method_config=method_config)\n",
    "    imshow(np.concatenate([get_pick_img(abs_map, env), get_pick_img(abs_map, env, show_goal=False)], axis=1))\n",
    "    abs_p = Path(\n",
    "        'data/abs/pick', \n",
    "         '{}-{}-{}-n_goal-{}-n_abs-{}'.format(\n",
    "             goal_config.map_name + ('-inv' if inv else ''),\n",
    "             method, method_config['feature_type'],\n",
    "             goal_config.n_goal,\n",
    "             n_abs,\n",
    "         ),\n",
    "    )\n",
    "    save_map = index_reduce({**abs_map, **obj_map})\n",
    "    print(save_map)\n",
    "    fsave({0: save_map}, abs_p, ftype='pkl')\n",
    "    print('save abs_map to {}'.format(abs_p))\n",
    "    \n",
    "def gen_single_env_config(map_name, obj_pos):\n",
    "    train_combos = [(0, 0)]\n",
    "    test_combos = [(0, 1)]\n",
    "    env_config = dict(\n",
    "        map_names=[map_name],\n",
    "        train_combos=train_combos,\n",
    "        test_combos=test_combos,\n",
    "        num_obj_types=2,\n",
    "        obj_pos=[[obj_pos, (1, 1)]],\n",
    "    )\n",
    "    fn = 'data/env_configs/pick/map49-{}-{}'.format(*obj_pos)\n",
    "    fsave(env_config, fn, ftype='pkl')\n",
    "    print('{} saved'.format(fn))\n",
    "    \n",
    "# input: map name and the corresponding obj_pos (map_id, x, y)\n",
    "# output: an identity map of this map_id and task\n",
    "def gen_identity_map(map_name):\n",
    "    train_combos = [(0, 0)]\n",
    "    test_combos = [(0, 1)]\n",
    "    obj_pos = [(4, 7), (1, 1)]\n",
    "    env_config = dict(\n",
    "        map_names = [map_name],\n",
    "        train_combos = train_combos,\n",
    "        test_combos = test_combos,\n",
    "        num_obj_types=2,\n",
    "        obj_pos=[obj_pos],\n",
    "    ) \n",
    "    env = PickGridWorld(**env_config, task_length=1, seed=0)\n",
    "    env.reset()\n",
    "    states = [s for s in env.pos_candidates]\n",
    "    n_states = len(states)\n",
    "    id_map = dict([(s, i) for i, s in enumerate(states)])\n",
    "    save_abs({0: id_map}, 'pick/{}-{}-{}-id.pkl'.format(map_name, *obj_pos[0]))\n",
    "    \n",
    "def visualize_save_abs(abs_path, env_config_path):\n",
    "    with open(env_config_path, 'rb') as f:\n",
    "        env_config = dill.load(f)\n",
    "    env = PickGridWorld(**env_config, task_length=1, seed=0)\n",
    "    with open(abs_path, 'rb') as f:\n",
    "        abs_map = dill.load(f)\n",
    "    img = get_pick_img(abs_map, env, show_goal=True)\n",
    "    imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "maps: [(0, 'map49')]\n",
      "tasks: [(0, ('A',)), (1, ('B',)), (2, ('C',)), (3, ('D',)), (4, ('E',)), (5, ('F',)), (6, ('G',)), (7, ('H',)), (8, ('I',)), (9, ('J',))]\n",
      "train: [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8)]\n",
      "test: [(0, 9)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=256x256 at 0x7FE1BC818D30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed(0)\n",
    "\n",
    "visualize_save_abs(\n",
    "    'log/pick.map49-9-1-min_dis-4.min_dis-10/imitation.bernoulli.n_abs-20/bernoulli-nonlinear/0.190216-190932/models/gen_abs_map/step-29900800-mean-10.78.pkl',\n",
    "    'data/env_configs/pick/map49-9-1-min_dis-4',\n",
    ")\n",
    "\n",
    "# for i in range(3, 13):\n",
    "#     gen_pick_config(\n",
    "#         GoalConfig(\n",
    "#             map_name='map49',\n",
    "#             n_goal=i,\n",
    "#             min_dis=4,\n",
    "#         ),\n",
    "#         inv=True,\n",
    "#     )\n",
    "\n",
    "# gen_identity_map('map49')\n",
    "\n",
    "# gen_single_env_config('map49', (4, 7))\n",
    "\n",
    "# gen_pick_abs(\n",
    "#     GoalConfig(\n",
    "#         map_name='map49',\n",
    "#         n_goal=12,\n",
    "#         min_dis=4,\n",
    "#     ),\n",
    "#     inv=True,\n",
    "#     n_abs=5,\n",
    "#     method_config=dict(\n",
    "#         feature_type='sample',\n",
    "#         reset_kws=dict(\n",
    "#             sample_obj_pos=False,\n",
    "#         ),\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# gen_pick_config(\n",
    "#     GoalConfig(\n",
    "#         map_name='large/map0',\n",
    "#         n_goal=2,\n",
    "#         min_dis=4,\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# gen_abs_imgs('tf_log/supervised-sample-map49-n_goal-12-min_dis-4-n_abs-16-label-action-all-190118-142809')\n",
    "# modify_env_configs()\n",
    "# gen_single_env_config('map49', (1, 14))\n",
    "\n",
    "# gen_identity_map('map49')\n",
    "\n",
    "# gen_env_config(\n",
    "#     GoalConfig(\n",
    "#         map_name='map49',\n",
    "#         n_goal=12,\n",
    "#         min_dis=4,\n",
    "#     ),\n",
    "#     min_dis=10,\n",
    "# )\n",
    "\n",
    "# gen_abs_maps(\n",
    "#     n_goal_range=list(range(1, 16)),\n",
    "#     n_abs_range=[4 * i for i in range(1, 12)],\n",
    "#     method='cluster',\n",
    "#     method_config=dict(feature_type='whole'),\n",
    "# )\n",
    "\n",
    "# gen_abs_map(\n",
    "#     GoalConfig(\n",
    "#         map_name='map49',\n",
    "#         n_goal=10,\n",
    "#         min_dis=4,\n",
    "#     ),\n",
    "#     n_abs=10,\n",
    "#     method='cluster',\n",
    "#     method_config=dict(feature_type='whole'),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sobol_seq\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def tensor(x, dtype=torch.float32):\n",
    "    if torch.is_tensor(x):\n",
    "        return x.type(dtype)\n",
    "    x = torch.tensor(x, dtype=dtype)\n",
    "    return x\n",
    "\n",
    "class SobolCategorical:\n",
    "    seed = 0 \n",
    "    def __init__(self, probs=None, logits=None):\n",
    "        if probs is not None:\n",
    "            self.probs = probs\n",
    "            self.log_probs = torch.log(self.probs)\n",
    "        else:\n",
    "            assert logits is not None\n",
    "            self.probs = F.softmax(logits, dim=1)\n",
    "            self.log_probs = F.log_softmax(logits, dim=1)\n",
    "        self.cumsum = torch.cumsum(self.probs, dim=1)\n",
    "\n",
    "    def sample(self):\n",
    "        v = torch.zeros(self.probs.size(0))\n",
    "        for i in range(self.probs.size(0)):\n",
    "            u, self.__class__.seed = sobol_seq.i4_sobol(1, self.__class__.seed)\n",
    "            v[i] = (self.cumsum[i] >= tensor(u)).argmax()\n",
    "        return tensor(v)\n",
    "\n",
    "    def log_prob(self, action):\n",
    "        return self.log_prob[tensor(np.arange(action.size(0)), dtype=torch.int64), action]\n",
    "\n",
    "    def set_seed(seed=0):\n",
    "        self.__class__.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2500,  0.4000,  0.5000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.Tensor([1, 2, 3])\n",
    "b = torch.Tensor([4, 5, 6])\n",
    "a /= b\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
